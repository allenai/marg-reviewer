[
    {
        "doc_id": "B1x8anVFPr",
        "method": "gpt_bare_independent_chunk",
        "reference_comments": [
            [
                "The authors should have performed multiple runs of their experiments and shown the standard deviations across runs to make their results more convincing.",
                "The authors claim that using Pre-LN rather than Post-LN transformers leads to faster convergence, but the models converge to the same result. This work is incremental as Wang et al. have already shown the benefits of Pre-LN rather than Post-LN transformers for machine translation.",
                "The paper is very long for an incremental improvement.",
                "It would be good to see repeats for Figure 2 and the standard deviations for Figure 3.",
                "Without reading the appendix it is not clear where the assumption that W^Q and W^K are zero is used. Making some connection with how this assumption relates to the lemmas would be useful.",
                "In Lemma two, the authors are comparing the magnitudes for the input in the Pre-LN and the output in the Post-LN transformer according to how x_{l,i}^post and x_{l, i}^pre are defined in Table 1.",
                "In Figure 3(b) the gradients are clearly decreasing with the number of layers, are there any comments on this? In the limit this could cause vanishing gradients?",
                "Figure 2 and 4 appear to contradict. Is the difference a result of using RAdam? If so, this should be made very clear. If not, why are the results contradictory?"
            ],
            [
                "The novelty of the paper is limited as Pre-LN placement has been used in prior work.",
                "There are concerns about the relation between the analytic investigation of the gradient norms and the empirical results that are presented.",
                "The theoretical results do not clearly demonstrate that there is a problem with Post-LN and that this problem is fixed by switching to Pre-LN.",
                "The paper does not clearly explain the relationship between the theoretical results and the empirical study.",
                "The paper does not adequately explain the scaling of the gradient changes throughout the layers, which is examined in appendix section F.",
                "The connection between the expression that scales in the upper bound and the actual gradient norm is tenuous and there are multiple places where the argument could break down.",
                "The paper does not verify the sqrt(2/3) scaling on the data from the empirical study that is shown.",
                "The paper does not explain where the expectation near the bottom of page 20, which is approximately 2/3, comes from."
            ]
        ],
        "generated_comments": {
            "all": [
                "Include a brief mention of the results obtained from the experiments conducted in the abstract to give readers an immediate understanding of the impact of the findings.",
                "Provide a brief overview of the structure of the paper at the end of the introduction to guide the reader through the paper.",
                "Provide a more detailed comparison between the current work and previous works, highlighting the unique contributions of the current study in the Related Work section.",
                "Consider including a figure or diagram to visually represent the Transformer Architecture with Post-Layer Normalization.",
                "Provide more context or background information on why the warm-up stage is typically used in training neural networks in the section discussing the Importance of the Warm-Up Stage in Training the Post-LN Transformer.",
                "Ensure that each equation is clearly explained and that its relevance to the discussion is clear. Include more explanations or intuitive interpretations of complex mathematical proofs to make them more accessible to a broader audience.",
                "Include a section dedicated to the experimental setup, results, and discussion. Provide more context or explanation about the choice of hyperparameters and the rationale behind the chosen experimental settings. Also, provide more details about the specific methods used and the rationale behind them.",
                "Ensure that all references are correctly formatted according to the chosen citation style. Move references that are not directly related to the conclusion or future work to a separate 'REFERENCES' section for clarity.",
                "Improve the wording in a few instances for clarity. The paper could benefit from a thorough proofreading to correct minor typographical errors and improve readability.",
                "Add a conclusion section to summarize the main findings of the paper and their implications. Include a discussion on the limitations of the study and potential avenues for future research.",
                "Provide a brief explanation or rationale for the chosen lr max values in the experiments.",
                "Specify which details are being referred to when mentioning that all other details can be found in the Appendix.",
                "Provide more context or explanation about why the undesirably significant variance in Adam in the early stage of model training is undesirable.",
                "Clarify why a certain setting is considered simpler for theoretical analysis.",
                "Provide a brief summary of the key differences between the Post-LN Transformer and the Pre-LN Transformer.",
                "Include a brief summary or key points from the formal proof on the gradients of the last FFN sub-layer in the main text.",
                "Provide a brief explanation of why specific tasks were chosen for the experiments.",
                "Provide more details about the pre-training process, such as the specific methods used and the rationale behind them.",
                "Discuss the discrepancy between the validation loss and the BLEU score and provide more details on why this discrepancy occurs and how it affects the results of the study.",
                "Provide more information on the choice of specific experimental settings and how they impact the results.",
                "Discuss or analyze how different seeds affect the results and why this might be the case.",
                "Ensure consistency in notation and correct minor typographical errors in equations.",
                "Provide a more detailed introduction and background section, providing more context and motivation for the study."
            ]
        },
        "alignments": {
            "all": []
        },
        "metrics": {
            "all": {
                "n_reference": 16,
                "n_generated": 23,
                "n_total_aligns": 0,
                "recall": 0.0,
                "precision": 0.0,
                "pseudo_jaccard": 0.0,
                "specificity_more": NaN,
                "specificity_less": NaN,
                "specificity_same": NaN
            }
        },
        "metrics_for_reviews": {
            "all": [
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 8
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 8
                }
            ]
        }
    },
    {
        "doc_id": "o2UwRc8fbXI",
        "method": "gpt_bare_independent_chunk",
        "reference_comments": [
            [
                "The paper does not clearly state the main claims. The proposed method does not demonstrate a speed advantage or a clear performance boost.",
                "The reason for coupling the proposed method with CapsGCN is unclear, especially if the RL module is intended to tune the depth and width of convolutional layers.",
                "The paper does not clearly differentiate the proposed method from Neural Architecture Search (NAS).",
                "The motivations and experimental results presented in the paper are weak."
            ],
            [
                "The use of Reinforcement Learning (RL) during the training process to search for and modify the neural structures may create stability issues. The paper should provide some theoretical justifications or 'proofs' of convergence, or at the minimum, provide some empirical analysis on the stability of the training process.",
                "The evaluation of the proposed Adaptive Graph Capsule Convolutional Networks (AdaGCCN) could be more thorough. The paper should include ablation studies to show how effective the RL is in adapting the network structure, and discuss the runtime complexity, among other things."
            ],
            [
                "The motivations for the paper are not well discussed.",
                "The experimental methodology used in the paper is not well detailed, making it difficult to reproduce the reported results.",
                "The authors' claims are not always supported by the experimental evidence.",
                "The authors do not provide information about how the models considered during the experiments were validated. The policy used to validate the hyperparameters of a model highly impacts the model's performance.",
                "The authors do not report the standard deviation of the accuracies in table 5. This is crucial to correctly assess the model performance.",
                "The results in Table 5 suggest that using the AM to optimize the D and W does not justify the increase of complexity due to the use of this external model.",
                "The results reported in Table 5 are outperformed by results published in the literature for Enzymes datasets and in NCI.",
                "The performance of the model in terms of memory consumption is not completely discussed. Using AM seems to significantly impact the memory consumption and/or the training time of the model.",
                "The authors state that adjusting the model structure through an RL-based searching process improves the explainability of the model. This point should be further discussed with empirical results."
            ],
            [
                "The capsule graph neural network section (2.2) is somewhat shallow and could benefit from a more detailed introduction to the topics discussed to make the paper more self-contained.",
                "The paper lacks ablation experiments on the epoch sliding window size and choice of search space for D and W. It's also unclear how the method would perform without the capsule components, i.e. is the assistant module strategy practically useful for other architectures.",
                "There are concerns about reporting test accuracy throughout training in figure 3, as models could be overfit to the test set, rendering the results potentially incomparable to previous works.",
                "No standard deviations are reported in the results in table 2, and generally only marginal improvements are observed despite the increase in runtime complexity of the proposed method.",
                "The paper lacks meaningful runtime comparisons between the proposed method and the various previous works without the assistant module. For example, a comparison to a parallel cross validation version of CapsGNN in figure 4 is suggested.",
                "In the discussion, the authors claim the proposed approach improves the explainability of the model, but it's not clear how that is the case. The authors should either elaborate on this or exclude it from the paper.",
                "The purpose of using dynamic routing in capsule networks is to adaptively modify the network connectivity based on the input. Therefore, it might be possible to reduce the search space by only considering depth D and not width W, since dynamic routing already takes care of 'pruning' W. The authors should address this point."
            ]
        ],
        "generated_comments": {
            "all": [
                "The abstract provides a good overview of the paper. However, it would be beneficial to include a brief explanation of the key terms such as Graph Convolutional Networks (GCNs), Reinforcement Learning (RL), and CapsGNN for readers who may not be familiar with these concepts.",
                "The introduction is well-written and provides a good background for the study. However, it would be helpful to provide more context on why the limitations of GCNs are significant and how they impact the performance of these networks in real-world applications.",
                "The methodology section is detailed and provides a good explanation of the proposed AdaGCCN model. However, the authors could consider providing more details on the RL-based assistant module, specifically how it selects the optimal modification to the model structure.",
                "In the 'Adaptive D-W Tuning' section, the algorithm is presented without sufficient explanation. It would be beneficial to provide a more detailed explanation of the algorithm, including the meaning of the variables and the logic behind the steps.",
                "The transition between the 'Adaptive D-W Tuning' and 'Parallel Processing' sections is abrupt. It would be helpful to provide a brief summary or conclusion of the previous section before moving on to the next topic.",
                "In the 'Parallel Processing' section, the authors mention a scheduling strategy (Algorithm 2), but it is not clearly explained or presented in the text. It would be beneficial to include a detailed explanation or a pseudocode representation of this algorithm.",
                "The authors mention that AdaGCCN achieves state-of-the-art accuracy results and outperforms CapsGNN on all datasets in both bioinformatics and social fields. However, the specific results, such as the accuracy percentages or error rates, are not mentioned in the provided text. Including these details would strengthen the paper.",
                "The 'AdaGCCN Performance' section presents the results of the experiments, but it lacks a thorough analysis. The authors should discuss the implications of the results and how they support the claims made in the paper.",
                "The authors could consider including a discussion section where they interpret the results, discuss the implications of their findings, and suggest future research directions.",
                "In the 'Discussion' section, the authors mention potential directions for future work. It would be beneficial to expand on these ideas and discuss how they could improve the current model.",
                "The 'Evaluation' section could be improved by providing more details about the experimental setup. For example, how were the benchmark datasets chosen? What were the specific parameters used in the experiments?",
                "In the 'Preparations for Experiments' section, the authors mention several baseline models and datasets. It would be helpful to provide a brief description of these models and datasets for readers who may not be familiar with them.",
                "The 'Related Work' section provides a good overview of the existing literature. However, it would be helpful to provide a more direct comparison between the proposed model and the models discussed in this section.",
                "The authors refer to figures and tables in the text, but these are not included in the provided text. Including these would help readers better understand the methodology and results.",
                "The authors should ensure that all references are correctly cited in the text and listed in the reference section.",
                "A conclusion section summarizing the main findings, their implications, and potential future work would be a valuable addition to the paper. The conclusion could be improved by summarizing the main findings of the paper and discussing their implications. It would also be beneficial to reiterate the potential directions for future work mentioned in the 'Discussion' section.",
                "Lastly, the paper could benefit from a thorough proofreading to correct minor typographical errors and improve readability."
            ]
        },
        "alignments": {
            "all": [
                {
                    "reference_id": 2,
                    "predicted_id": 7,
                    "relative_specificity": "more",
                    "relatedness": "high",
                    "pairwise_result": {
                        "relatedness": "high",
                        "relative_specificity": "more",
                        "same_meaning": true
                    },
                    "count": 4,
                    "score": 0.8,
                    "reference_comment": "The authors' claims are not always supported by the experimental evidence.",
                    "predicted_comment": "The 'AdaGCCN Performance' section presents the results of the experiments, but it lacks a thorough analysis. The authors should discuss the implications of the results and how they support the claims made in the paper."
                },
                {
                    "reference_id": 1,
                    "predicted_id": 10,
                    "relative_specificity": "more",
                    "relatedness": "high",
                    "pairwise_result": {
                        "relatedness": "high",
                        "relative_specificity": "more",
                        "same_meaning": true
                    },
                    "count": 4,
                    "score": 0.8,
                    "reference_comment": "The experimental methodology used in the paper is not well detailed, making it difficult to reproduce the reported results.",
                    "predicted_comment": "The 'Evaluation' section could be improved by providing more details about the experimental setup. For example, how were the benchmark datasets chosen? What were the specific parameters used in the experiments?"
                }
            ]
        },
        "metrics": {
            "all": {
                "n_reference": 22,
                "n_generated": 17,
                "n_total_aligns": 2,
                "recall": 0.05555555555555555,
                "precision": 0.029411764705882353,
                "pseudo_jaccard": 0.020833333333333332,
                "specificity_more": 1.0,
                "specificity_less": 0.0,
                "specificity_same": 0.0
            }
        },
        "metrics_for_reviews": {
            "all": [
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 4
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 2
                },
                {
                    "recall": 0.2222222222222222,
                    "precision": 0.11764705882352941,
                    "pseudo_jaccard": 0.08333333333333333,
                    "n_real": 9
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 7
                }
            ]
        }
    },
    {
        "doc_id": "tJCwZBHm-jW",
        "method": "gpt_bare_independent_chunk",
        "reference_comments": [
            [
                "The novelty of the paper is limited as the idea of transforming a 2D image pre-train backbone into a 3D version has already been used in other 2D-3D domains. The paper needs to place extra emphasis on discussing why it works and conducting ablation studies.",
                "The discussion section provides some experiments, but the results seem quite random (figure 4). The explanation for why 'shape representation' are better transferred is not convincing.",
                "The paper does not discuss if there is a difference on which axis to inflate (x, y, or z) when designing inflation. This is different to video since 3 axis is symmetric.",
                "The paper does not compare the parameter size in section 4.1. This raises concerns about the fairness of the comparison with the baseline, as the performance gain could be solely due to the increase in parameters.",
                "In section 4.2, there is a possibility that the ResNet structure is not a good structure to train on point cloud, making it quite bad on scratch training. The training method for pointnet++ is also questionable."
            ],
            [
                "The paper's visualizations do not adequately explain why the transfer works or what information can be transferred.",
                "The conclusion on page 8 that 'shape representations are better transferred from image to point-cloud' cannot be inferred from overall dataset performances. The term 'shape representations' is also not clearly defined."
            ],
            [
                "The paper lacks comparisons between results from datasets of different sizes in Table 1. It is unclear whether a larger dataset would lead to better performance.",
                "The paper does not include results of state-of-the-art task specific methods for comparison. It would be beneficial to compare with different self-supervised learning methods, such as Foldingnet and Pointcontrast.",
                "The paper does not provide a theoretical analysis to explain why inflating 2D filters to 3D is reasonable, given the significant domain gap between 2D and 3D datasets."
            ],
            [
                "The idea of inflating model weight from 2D to 3D is not new, as shown in the work of Carreira and Zisserman.",
                "The effectiveness of pretrained weight would be more convincing if the author could do further ablation study to initialize new model with expanding subsets of layers and exploring the effect on model performance. This would indicate which part of the pretrained model is really useful in this transferred learning setting."
            ],
            [
                "The paper is missing detailed information, making it difficult to follow the process. For example, in Table 1, the performances of pointnet++ and the performances are listed, but it's unclear how the inflation in point net++ is performed.",
                "The authors only perform experiments on classification and segmentation tasks. The performance on detection tasks should also be evaluated.",
                "The paper does not clearly address why the proposed method of inflating 2D CNN of image for 3D pointcloud works."
            ]
        ],
        "generated_comments": {
            "all": [
                "The abstract provides a good overview of the paper's content. However, it would be beneficial to include a brief mention of the specific neural network architecture used in the study. This would give readers a clearer understanding of the methods used.",
                "The introduction is well-written and provides a clear context for the study. However, it would be helpful if the authors could provide more specific examples of the 'variety of tricks' used by other point-cloud models. This would help readers understand the novelty and significance of the proposed approach.",
                "The methodology is explained in detail, which is commendable. However, the authors could consider providing a visual representation of the process of converting a 2D ConvNet to a 3D ConvNet. This would help readers better understand the process. More details on the methodology used for the experiments, such as the selection of baselines, the use of ResNet-series models, the use of SGD optimizer, and the use of pretrained models from open sources, should be provided.",
                "The authors should provide more details about the datasets used, the version of Pytorch used, the computational resources used, and the preprocessing and post-processing steps. They should also provide more details about the implementation of the ViT models, the PointNet++ pretraining, and the ResNet architecture.",
                "The results section is comprehensive and well-structured. However, it would be beneficial if the authors could provide more detailed statistical analysis of the results. This would strengthen the validity of the findings. The authors should consider including more visual aids, such as graphs or diagrams, to help illustrate the results and make the paper more engaging for readers.",
                "The authors have done a good job of discussing the implications of their findings. However, it would be beneficial if they could discuss potential limitations of their approach and suggest areas for future research. The authors should consider providing more explanation or hypothesis for unexpected findings, such as the clustering of similar objects by pretrained units.",
                "The conclusion section seems to be cluttered with details that might be better suited for the methods or results sections. It would be beneficial to streamline the conclusion to focus on summarizing the main findings and their implications.",
                "The authors have cited a wide range of relevant literature, which strengthens the credibility of their work. However, they should ensure that all citations are formatted consistently.",
                "The paper is generally well-written and easy to follow. However, there are a few instances where the wording could be clarified. For example, in the sentence 'We discover that, surprisingly, models with minimal finetuning efforts -only on input, output, and optionally batch normalization layers, can achieve competitive performance on 3D point-cloud classification', it is unclear what is meant by 'minimal finetuning efforts'. The authors should consider rephrasing this for clarity. The paper could benefit from a more thorough proofreading to correct minor typographical errors and improve readability.",
                "The authors have provided a detailed description of their methodology, which should allow other researchers to replicate their study. However, they should consider providing a link to their code and data, if possible. This would further enhance the reproducibility of their study.",
                "The authors should consider including a section on the practical implications of their findings. This would help readers understand the real-world significance of the research."
            ]
        },
        "alignments": {
            "all": [
                {
                    "reference_id": 2,
                    "predicted_id": 2,
                    "relative_specificity": "more",
                    "relatedness": "medium",
                    "pairwise_result": {
                        "relatedness": "medium",
                        "relative_specificity": "more",
                        "same_meaning": true
                    },
                    "count": 4,
                    "score": 0.8,
                    "reference_comment": "The paper does not clearly address why the proposed method of inflating 2D CNN of image for 3D pointcloud works.",
                    "predicted_comment": "The methodology is explained in detail, which is commendable. However, the authors could consider providing a visual representation of the process of converting a 2D ConvNet to a 3D ConvNet. This would help readers better understand the process. More details on the methodology used for the experiments, such as the selection of baselines, the use of ResNet-series models, the use of SGD optimizer, and the use of pretrained models from open sources, should be provided."
                },
                {
                    "reference_id": 0,
                    "predicted_id": 3,
                    "relative_specificity": "more",
                    "relatedness": "medium",
                    "pairwise_result": {
                        "relatedness": "medium",
                        "relative_specificity": "more",
                        "same_meaning": true
                    },
                    "count": 4,
                    "score": 0.8,
                    "reference_comment": "The paper is missing detailed information, making it difficult to follow the process. For example, in Table 1, the performances of pointnet++ and the performances are listed, but it's unclear how the inflation in point net++ is performed.",
                    "predicted_comment": "The authors should provide more details about the datasets used, the version of Pytorch used, the computational resources used, and the preprocessing and post-processing steps. They should also provide more details about the implementation of the ViT models, the PointNet++ pretraining, and the ResNet architecture."
                }
            ]
        },
        "metrics": {
            "all": {
                "n_reference": 15,
                "n_generated": 11,
                "n_total_aligns": 2,
                "recall": 0.13333333333333333,
                "precision": 0.03636363636363636,
                "pseudo_jaccard": 0.03333333333333333,
                "specificity_more": 1.0,
                "specificity_less": 0.0,
                "specificity_same": 0.0
            }
        },
        "metrics_for_reviews": {
            "all": [
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 5
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 2
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 3
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 2
                },
                {
                    "recall": 0.6666666666666666,
                    "precision": 0.18181818181818182,
                    "pseudo_jaccard": 0.16666666666666666,
                    "n_real": 3
                }
            ]
        }
    },
    {
        "doc_id": "H1enKkrFDB",
        "method": "gpt_bare_independent_chunk",
        "reference_comments": [
            [
                "The role of the partitioning index in the proposed algorithm is unclear, as it does not appear to be used in the experiments. The authors should clarify its importance and usage.",
                "The empirical evaluation of the normalization technique is insufficient to demonstrate its practical usefulness. The authors should focus more on showing how their regularization can improve generalization in practice.",
                "The authors should provide experiments on at least one additional dataset, such as CIFAR10 or ImageNet, to strengthen their empirical results.",
                "The reported accuracies for ResNet and DenseNet on the CIFAR100 dataset are significantly lower than what is reported in the literature. This issue needs to be resolved.",
                "The current results are based on training with a fixed number of epochs. Instead, the authors should train with a stopping criterion based on the cross-entropy loss on the training set and use the same stopping criterion for all models. They should also add plots showing training and test errors based on the number of epochs."
            ],
            [
                "The paper should characterize the runtime difference between SRN and SN. It is presently unclear how computationally intensive the method is. What is the difference in time per training iteration? The authors should also indicate their hardware setup and overall training time.",
                "Table 1 is confusing as it lacks the test error. If there is a difference in testing error, then this table is misleading. If the test errors are approximately the same, then why should I care if the training error is higher? This would just be a way to decrease the stated \u201cgeneralization gap,\u201d which is not necessarily indicative of a better model.",
                "The paper does not explain what \u201cStable-50\u201d, \u201cSRN-50\u201d, and \u201cSRN-50%\u201d are. This should be explicitly stated so that the reader knows which model corresponds to which settings."
            ],
            [
                "The paper could mention some related older introductory approaches, such as representing linear layers as 'bottlenecks' to enforce low rank explicitly, or solving in the manifold of reduced-rank matrices directly.",
                "The authors target the same stable rank (srank) r=c*min(m,n) for all layers, even though only the sum of sranks is important. It would be interesting to see if there is any observable difference for CNNs with only a few linear layers by lightly deviating from this.",
                "The paper could explore whether the first linear layer typically contributes the majority to the sum of sranks.",
                "The paper could discuss how 'stable rank' concepts might be extended to the convolutional layers. As a starting point, spectral values of the block-circulant matrices corresponding to convolutions have been described in previous work."
            ]
        ],
        "generated_comments": {
            "all": [
                "Abstract: Include a brief explanation of the term 'shattering experiments' for readers who may not be familiar with it.",
                "Introduction: Provide a clearer explanation of the stable rank and its importance in the context of NNs.",
                "Throughout the paper, ensure that all equations and mathematical notations are clearly explained and formatted for clarity.",
                "In paragraph 2, provide some intuition or a brief explanation as to why SRN is optimal and unique even in non-convex situations.",
                "The definition of stable rank seems to be split across multiple paragraphs. Consolidate this into a single paragraph or section for better readability.",
                "In the section 'WHY STABLE RANK NORMALIZATION?', provide more concrete examples or case studies to illustrate the points being made.",
                "In the section 'STABLE RANK NORMALIZATION', provide more details on how the proposed problem is planned to be solved.",
                "In paragraph 43, provide a brief explanation or reference as to why the problem (4) is non-convex at k = 0 and convex otherwise.",
                "Provide a brief explanation of the power method mentioned in paragraph 57 and the significance of the algorithm not requiring prior knowledge of the rank of the matrix (paragraph 61).",
                "Improve the transition from the Stable Rank Normalization section to the Experiments section with a brief introductory paragraph.",
                "In the Experiments section, provide more details about the experimental setup, such as the hardware used, the duration of the experiments, and any preprocessing steps applied to the datasets.",
                "The Result Overview section could be improved by providing more specific results, such as numerical values or percentages, rather than general statements.",
                "Ensure all referenced figures and tables are included in the final version of the paper.",
                "The Shattering Experiments section is quite dense and could benefit from further explanation or simplification.",
                "Provide a more detailed explanation of the SRN-GAN model, the empirical Lipschitz constant (eLhist), and how it is used in the analysis.",
                "Provide more detailed explanations of the tables and figures presented in the paper, the mathematical proofs, the results and their implications, and the limitations of the study and potential areas for future research.",
                "Improve the organization and formatting of the paper to enhance its readability. For example, consider using subheadings to break up the text and make it easier to follow.",
                "Provide a more detailed conclusion that summarizes the key findings of the study and their implications, as well as potential future work.",
                "Ensure that all references are correctly cited and formatted.",
                "In the 'Uniqueness' section, provide a brief explanation of the introduced mathematical symbols and equations. Similarly, provide a clear statement of the problem being addressed at the beginning of this section.",
                "Provide a clear explanation of the significance of each section in the context of the overall paper.",
                "In Section B.2, provide a more intuitive explanation or a simple example to help readers understand the effect of rank on the empirical Lipschitz constants.",
                "Improve the transition from Section B.2 to Section C with a brief summary of the findings in Section B.2 and a short introduction to the topic of Section C.",
                "In the Experimental Details section, provide a brief explanation of why the specific models were chosen and how they contribute to the research.",
                "In paragraph 218, provide a more detailed explanation or analysis of the observation that having a weight decay actually hurts generalization error while it has a slightly positive effect on test error.",
                "In the GAN objective functions section, provide a brief explanation of why the hinge loss version of the adversarial loss was chosen and why it was not used in the experiments with WGAN-GP.",
                "Provide a brief explanation of the notations introduced in the paper and how they are used.",
                "Provide a brief explanation of the Frobenius inner product of two matrices for readers who may not be familiar with it."
            ]
        },
        "alignments": {
            "all": [
                {
                    "reference_id": 0,
                    "predicted_id": 10,
                    "relative_specificity": "same",
                    "relatedness": "medium",
                    "pairwise_result": {
                        "relatedness": "medium",
                        "relative_specificity": "same",
                        "same_meaning": true
                    },
                    "count": 2,
                    "score": 0.4,
                    "reference_comment": "The paper should characterize the runtime difference between SRN and SN. It is presently unclear how computationally intensive the method is. What is the difference in time per training iteration? The authors should also indicate their hardware setup and overall training time.",
                    "predicted_comment": "In the Experiments section, provide more details about the experimental setup, such as the hardware used, the duration of the experiments, and any preprocessing steps applied to the datasets."
                }
            ]
        },
        "metrics": {
            "all": {
                "n_reference": 12,
                "n_generated": 28,
                "n_total_aligns": 1,
                "recall": 0.1111111111111111,
                "precision": 0.011904761904761904,
                "pseudo_jaccard": 0.011111111111111112,
                "specificity_more": 0.0,
                "specificity_less": 0.0,
                "specificity_same": 1.0
            }
        },
        "metrics_for_reviews": {
            "all": [
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 5
                },
                {
                    "recall": 0.3333333333333333,
                    "precision": 0.03571428571428571,
                    "pseudo_jaccard": 0.03333333333333333,
                    "n_real": 3
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 4
                }
            ]
        }
    },
    {
        "doc_id": "Qm7R_SdqTpT",
        "method": "gpt_bare_independent_chunk",
        "reference_comments": [
            [
                "The paper should provide insights on why switching actions at some fixed number of frames beats using the Gaussian variance for FVD.",
                "The paper should discuss the importance of the heuristic of changing states when using GP, and how the performance would be affected if a different threshold is used."
            ],
            [
                "The experimental section could be improved. More details about how the comparison to some baselines was made would be appreciated.",
                "The results for the VRNN model in Figure 4 and 5 do not follow the results in the literature, where it outperforms SVG and SAVP. It's unclear whether this is due to an architectural change, suboptimal hyperparameters, or a different reimplementation.",
                "The VRNN model is missing from some other comparisons such as Table 1.",
                "For SAVP, the results for Figure 4 seem much worse than those reported in the original paper."
            ],
            [
                "The application of Gaussian Processes (GP) in this work is straightforward and naive. Dynamical modeling with GP has been widely investigated since the introduction of Gaussian Process Dynamical Model in NIPs 2005.",
                "The modules of LSTM Frame Generation and GP Frame Generation in Equation (4) are not clearly explained or depicted in Figure 3. It is unclear if these modules correspond to 'D' in Stage 3.",
                "The use of GP to generate images is questionable as GP is more suitable for working in the latent space.",
                "The datasets used in the study are not representative due to their simplicity and experimental nature.",
                "The paper does not demonstrate the utility of the proposed method for high-level research topics such as large-scale action recognition, video captioning, etc."
            ]
        ],
        "generated_comments": {
            "all": [
                "The abstract could be more explicit about the novelty of the proposed approach and highlight the unique aspects of the Diverse Video Generator in comparison to existing methods.",
                "The introduction could benefit from a clearer statement of the paper's contributions earlier on.",
                "Provide a more explicit comparison between the proposed method and the existing methods discussed to highlight the unique contributions of the paper.",
                "Consider providing more intuitive explanations or visual aids for the more complex aspects of the approach, such as the use of Gaussian Processes and the triggering mechanism for diverse future states.",
                "Provide more details on how the evaluations will be conducted and discuss why the proposed alternative evaluation strategy for diversity is appropriate and how it compares to other potential evaluation strategies.",
                "Provide more details on why the SVGP approach was chosen over the other methods discussed for making Gaussian Processes more scalable.",
                "Include a conclusion summarizing the main findings, contributions, and potential future work.",
                "Ensure that all referred figures are included in the paper to aid understanding of the proposed method and its results.",
                "Ensure that all citations are correctly formatted and consistent throughout the paper.",
                "Ensure that all technical terms and acronyms are clearly defined when first introduced.",
                "Provide a brief explanation of why specific architectures were chosen and how they contribute to the overall performance of the model.",
                "Provide more details about the choice of LSTM layers and the specific activation function used.",
                "Discuss how the hyperparameters were tuned and why specific values resulted in better training.",
                "Provide more details about how this trigger switch is implemented and how it contributes to the overall performance of the model.",
                "Provide more details about the specific parameters used for training the models.",
                "Provide more discussion on the implications of these results and how they compare to the state-of-the-art.",
                "Consider adding a section to discuss potential improvements or extensions to the approach.",
                "Consider adding a section to discuss any potential drawbacks or limitations of the approach.",
                "Improve the presentation of the ablation study results with a more structured comparison of the performance of the different models on the different datasets.",
                "Provide more context or explanation for the statement about the community's reliance on reconstruction metrics for video prediction and suggest alternative metrics if applicable.",
                "Include information about the performance of the classifier on the BAIR dataset for a more complete picture of its performance."
            ]
        },
        "alignments": {
            "all": [
                {
                    "reference_id": 1,
                    "predicted_id": 13,
                    "relative_specificity": "same",
                    "relatedness": "medium",
                    "pairwise_result": {
                        "relatedness": "medium",
                        "relative_specificity": "same",
                        "same_meaning": true
                    },
                    "count": 3,
                    "score": 0.6,
                    "reference_comment": "The paper should discuss the importance of the heuristic of changing states when using GP, and how the performance would be affected if a different threshold is used.",
                    "predicted_comment": "Provide more details about how this trigger switch is implemented and how it contributes to the overall performance of the model."
                },
                {
                    "reference_id": 0,
                    "predicted_id": 13,
                    "relative_specificity": "same",
                    "relatedness": "medium",
                    "pairwise_result": {
                        "relatedness": "medium",
                        "relative_specificity": "same",
                        "same_meaning": true
                    },
                    "count": 2,
                    "score": 0.4,
                    "reference_comment": "The paper should provide insights on why switching actions at some fixed number of frames beats using the Gaussian variance for FVD.",
                    "predicted_comment": "Provide more details about how this trigger switch is implemented and how it contributes to the overall performance of the model."
                }
            ]
        },
        "metrics": {
            "all": {
                "n_reference": 11,
                "n_generated": 21,
                "n_total_aligns": 2,
                "recall": 0.3333333333333333,
                "precision": 0.015873015873015872,
                "pseudo_jaccard": 0.023255813953488372,
                "specificity_more": 0.0,
                "specificity_less": 0.0,
                "specificity_same": 1.0
            }
        },
        "metrics_for_reviews": {
            "all": [
                {
                    "recall": 1.0,
                    "precision": 0.047619047619047616,
                    "pseudo_jaccard": 0.06976744186046512,
                    "n_real": 2
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 4
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 5
                }
            ]
        }
    },
    {
        "doc_id": "K5j7D81ABvt",
        "method": "gpt_bare_independent_chunk",
        "reference_comments": [
            [
                "The paper does not clarify whether 'S_F = S_sTEX' refers to exact string equality or after white space normalization. The authors should specify the exact normalizations and provide the success rate before and after them.",
                "The paper does not discuss the potential impact of using larger GPT models.",
                "The paper does not explore the potential usefulness of unsupervised learning methods, which have recently seen significant improvements.",
                "The term 'fully disambiguated' is used in definition 4.1 without considering the types of variables. In systems with subtypes, the meaning and provability of a statement can change depending on the quantification over different types of numbers."
            ],
            [
                "The current benchmark lacks sufficient training and evaluation data. The lack of training corpora may be addressed by pretraining and building synthetic data.",
                "A larger and high-quality evaluation set is needed to validate any actual progress on this problem. The current evaluation set is too small and covers limited math topics.",
                "The evaluation protocol is unclear. The best evaluation protocol should be checking if S_F belongs to STEX(S_STEX), which is not used in this work. The authors should consider implementing this protocol.",
                "An ablation study on the corresponding contributions of pretraining and synthetic data is needed for the proposed approach."
            ],
            [
                "The paper does not compare the proposed method against other systems listed in section 4 that also aim to automate the formalization process.",
                "The choice of phrasing the task as a translation problem is questionable, as it seems to set up the NMT baselines to perform poorly due to the identity transformation required for much of the document.",
                "The evaluation methodology is confusing, particularly the use of automated procedures to generate some of the data. This raises questions about why these automated methods are not sufficient for the end task.",
                "The results section does not present the results of the baselines, making it difficult to assess their performance relative to the proposed method.",
                "The paper does not provide a clear understanding of the problem setting, what is being learned, and what is failing. This makes it difficult to assess the importance and difficulty of the targeted problem.",
                "The experimental section is short and lacks important comparisons to other work in this area.",
                "The model is used in a very off-the-shelf way and does not treat the problem setting any differently than a standard translation task, which raises questions about the novelty of the modeling contribution.",
                "The paper uses a lot of domain-specific terminology that may be difficult for a general ML audience to understand. For example, the terms 'formal' and 'informal' are used in a way that is not immediately clear.",
                "The paper needs major restructuring and refocusing, more experiments, and more analysis to be considered for acceptance."
            ],
            [
                "The problem definition was not clear. A concrete example demonstrating what exactly an algorithm for the problem gets as input and what is its output is missing.",
                "The description of the dataset was unclear. While there is a formal description, the lack of examples leaves the description at a very abstract level, making it difficult to understand what exactly should be expected in the dataset.",
                "The authors do not show awareness of work in semantic parsing and in style transfer. These works are very important both for the algorithmic approach and for understanding the challenges of evaluation. For example, there is lots of semantic parsing research on transferring text into SQL queries or on solving textual mathematical problems. The connection to relevant ideas and approaches should be part of the introduction of the task."
            ]
        ],
        "generated_comments": {
            "all": [
                "The abstract provides a good overview of the paper. However, it would be beneficial to include a brief mention of the key findings or results from the study to give readers a clear understanding of the paper's contributions.",
                "The introduction is comprehensive and provides a good background for the study. However, it might be beneficial to provide a more explicit statement of the research problem and the paper's objectives early in the introduction. This would help to guide the reader through the rest of the paper. Additionally, it would be helpful to provide some examples or case studies to illustrate the challenges faced by traditional mathematicians when using formal systems. The authors should also elaborate on how these issues extend beyond pure mathematics to other STEM fields.",
                "The authors do a good job of explaining why disambiguating expressions is not a straightforward task. However, it would be beneficial to provide more concrete examples to illustrate this point.",
                "The methodology section could benefit from more detailed explanations. For instance, the authors mention that they used transformer models pretrained on generic L A T E X documents, but they do not provide sufficient details about the pretraining process, such as the size of the pretraining corpus, the duration of pretraining, or the specific architecture of the transformer model used. The authors should also provide a more detailed explanation of how the function f : L \u2192 L works and what it represents in the context of the study.",
                "The authors have done a commendable job in describing the datasets used. However, it would be beneficial to provide more information about the process of data synthesis, specifically how the MMT integration was exploited to synthesize additional training data.",
                "The authors mention that traditional evaluation metrics are difficult to apply in their situation, and hence they opted for a plurality of evaluation strategies. However, it would be helpful if the authors could provide more justification for their choice of evaluation metrics and explain why traditional metrics such as BLEU are not suitable for their task.",
                "The paper could benefit from a more thorough discussion of the results and their implications. This would help readers understand the significance of the study and its contributions to the field. The authors mention that their model failed in some interesting ways, but they do not provide a detailed analysis of these failures. Understanding why the model failed in these specific instances could provide valuable insights for future work.",
                "The authors should consider including a section on the limitations of their study and potential avenues for future research. This would provide a more balanced view of the research and indicate areas where further work is needed. The authors briefly mention their plans for future work, but it would be beneficial to elaborate on this. For instance, how do they plan to integrate the proposed symbolic disambiguation approach with an autoformalization framework? What specific improvements do they anticipate this integration will bring?",
                "The authors have provided a link to the code and data relevant to the paper. However, it would be helpful if they could provide more details about what exactly is included in this repository, such as specific scripts, preprocessed data, or pretrained models.",
                "The authors should consider adding a dedicated related work section to provide context and demonstrate how their work fits into the larger research landscape. This would help readers understand the novelty and significance of the authors' contributions.",
                "The paper could benefit from a more thorough proofreading to correct minor typographical errors and ensure consistency in the use of terms and abbreviations."
            ]
        },
        "alignments": {
            "all": [
                {
                    "reference_id": 0,
                    "predicted_id": 1,
                    "relative_specificity": "more",
                    "relatedness": "medium",
                    "pairwise_result": {
                        "relatedness": "medium",
                        "relative_specificity": "more",
                        "same_meaning": true
                    },
                    "count": 5,
                    "score": 1.0,
                    "reference_comment": "The problem definition was not clear. A concrete example demonstrating what exactly an algorithm for the problem gets as input and what is its output is missing.",
                    "predicted_comment": "The introduction is comprehensive and provides a good background for the study. However, it might be beneficial to provide a more explicit statement of the research problem and the paper's objectives early in the introduction. This would help to guide the reader through the rest of the paper. Additionally, it would be helpful to provide some examples or case studies to illustrate the challenges faced by traditional mathematicians when using formal systems. The authors should also elaborate on how these issues extend beyond pure mathematics to other STEM fields."
                }
            ]
        },
        "metrics": {
            "all": {
                "n_reference": 20,
                "n_generated": 11,
                "n_total_aligns": 1,
                "recall": 0.08333333333333333,
                "precision": 0.022727272727272728,
                "pseudo_jaccard": 0.019230769230769232,
                "specificity_more": 1.0,
                "specificity_less": 0.0,
                "specificity_same": 0.0
            }
        },
        "metrics_for_reviews": {
            "all": [
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 4
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 4
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 9
                },
                {
                    "recall": 0.3333333333333333,
                    "precision": 0.09090909090909091,
                    "pseudo_jaccard": 0.07692307692307693,
                    "n_real": 3
                }
            ]
        }
    },
    {
        "doc_id": "rkxZCJrtwS",
        "method": "gpt_bare_independent_chunk",
        "reference_comments": [
            [
                "The paper should include an argument explaining that accurately estimating Q using Q_phi does not necessarily mean that the gradients of Q_phi will be good approximations of the true gradients of Q. The reviewer suggests referring to Fig 1 of arxiv.org/pdf/1705.07107.pdf for an informative example.",
                "The choice of Euclidean norm in line 10 needs justification. The reviewer suggests considering the importance of the direction of the gradient over the norm and proposes the use of cosine similarity instead.",
                "The paper argues that Deep Reinforcement Learning (DRL) is superior to Model Predictive Control (MPC) due to better exploration. The reviewer suggests exploring the possibility of using simulator gradients to further improve exploration in DRL."
            ],
            [
                "The paper's contribution is empirical in nature, and a promising future direction would be to add derivative information to and evaluate similar variants of newer actor-critic methods such as TD3 and SAC."
            ],
            [
                "The form of gradient given in equation (2) might contain an error. In DDPG, the action is given by a deterministic policy, thus we have $a_t = \\pi(s_t)$ for all $t\\geq 0$. For critic estimation, it seems you are basing on the Bellman equation $ Q(s,a) = r(s,a) + Q(s', \\pi(s'))$, where $s'$ is the next state following $(s,a)$. Then, it seems that Equation (2) is obtained by taking gradient with respect to $(s,a)$. However, I cannot understand what $\\nabla_{\\pi} Q$ stands for. If it is $\\nabla_a Q(s_{i+1}, a_{i+1}) \\cdot \\nabla_s \\pi(s_{i+1}) $, then that makes sense.",
                "Based on the experiments, the proposed method does not always outperform MPC or DDPG, even in a small-scale control problem Mountaincar. Moreover, it seems that the performance is similar to that of the DDPG.",
                "The model-based gradient in equation (2) is defined by only unroll one-step forward by going from $s_i, a_i$ to $s_{i+1}$. It would be interesting to see how the number of unroll steps affect the algorithm, which is a gradient version of TD($\\lambda$)."
            ]
        ],
        "generated_comments": {
            "all": [
                "The abstract provides a good overview of the paper. However, it would be beneficial to include a brief mention of the key results or findings from the experiments conducted.",
                "The introduction is well-structured and provides a clear context for the study. However, it would be helpful to provide a brief overview of the structure of the rest of the paper at the end of the introduction.",
                "The authors have done a good job of discussing the relevant literature. However, it would be beneficial to provide a more explicit comparison of the proposed method with existing methods.",
                "The algorithm section is detailed and provides a good explanation of the proposed method. However, the authors should consider providing a more intuitive explanation of the algorithm for readers who may not be familiar with the technical details.",
                "The authors should consider providing more details about the differentiable simulators used in the study.",
                "The authors should consider including a separate section for results and discussion.",
                "In the 'Simulation with impulse-based collision responses' section, the authors mention that they follow Popovi\u0107 et al., 2000 for simulating systems with contacts. It would be beneficial to provide a brief summary of the methods used in this reference.",
                "In the 'Simulation with constraint-based collision responses' section, the authors mention that they were inspired by the work of Amos & Kolter (2017). It would be helpful to elaborate on how this work influenced the current study.",
                "In the 'THE HYBRID ALGORITHM' section, the authors mention that actions are scaled by a constant such that they fall in the range [\u22121, 1]. It would be helpful to provide a justification for this specific range.",
                "In the 'ENVIRONMENTS' section, the authors mention that they present seven 2D control tasks. It would be beneficial to provide a brief description of each task.",
                "In the 'EVALUATION' section, the authors compare their method with three baselines. It would be helpful to provide a brief summary of these baseline methods.",
                "In the 'EVALUATION' section, the authors mention that they seed each algorithm with the same network models. It would be beneficial to provide more details about these network models.",
                "In the 'EVALUATION' section, the authors mention that their hybrid algorithm universally converges faster or to higher returns. It would be helpful to provide some quantitative data or a graph to support this claim.",
                "In the 'EVALUATION' section, the authors mention that their algorithm is applicable to a wider range of reward structures. It would be beneficial to provide examples of these reward structures.",
                "The authors should consider including a conclusion section that summarizes the key findings of the study, discusses the implications of these findings, and suggests directions for future research.",
                "The authors should ensure that all references are correctly formatted and consistent throughout the paper.",
                "The authors should ensure that all figures and tables are clearly labeled and referenced in the text."
            ]
        },
        "alignments": {
            "all": []
        },
        "metrics": {
            "all": {
                "n_reference": 7,
                "n_generated": 17,
                "n_total_aligns": 0,
                "recall": 0.0,
                "precision": 0.0,
                "pseudo_jaccard": 0.0,
                "specificity_more": NaN,
                "specificity_less": NaN,
                "specificity_same": NaN
            }
        },
        "metrics_for_reviews": {
            "all": [
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 3
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 1
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 3
                }
            ]
        }
    },
    {
        "doc_id": "xP37gkVKa_0",
        "method": "gpt_bare_independent_chunk",
        "reference_comments": [
            [
                "The paper's proposed method, LBS, only supports one agent in a two-player game.",
                "The authors mention learning a centralized reward function using VDN, while other agent\u2019s q-value functions are unavailable. It's unclear how this is achieved.",
                "The method for using the total reward expectation to avoid having to unroll episodes until the end of the game is not clear."
            ],
            [
                "The paper needs to address how overestimation is handled when using argmax of $Q(a^i|\\tau^i)$ in n-step rollout, especially considering the large variance in rollout. The use of any variance reduction technique should be clarified.",
                "The experiments are only evaluated on Hanabi, raising concerns about the generalizability of the method. The paper should include at least one experiment evaluated on a different game, such as Leduc, to demonstrate its applicability to different imperfect information games.",
                "The paper needs to provide clear definitions and explanations for terms and concepts used, such as 'BP' on page 1, 'blueprint policies' in section 2.1, and the belief definition in section 3.",
                "Equations 2, 3, and 4 are confusing and need further explanation, as they are crucial to the paper."
            ],
            [
                "The motivation of why Learned Belief Search (LBS) can be challenging and useful for DEC-POMDP or the multi-agent game domains is not convincingly explained.",
                "The experiment settings, problem description, and discussions need more elaboration.",
                "The results in Table 1 and 3 are not discussed in the main text, making it hard to understand the reported numbers. The authors should elaborate on these in their response.",
                "A brief description of the Hanabi game should be included in the Appendix.",
                "Comparisons of different design/hyperparameter choices should be included to help judge the benefit of using learning for belief representation."
            ],
            [
                "The paper's proposed method, LBS, is highly dependent on the well-trained Blue Policy (BP). The importance of BP's contribution to the final performance is unclear.",
                "It is not clear how LBS would perform when based on a broken or flawed BP policy.",
                "The paper does not provide clarity on how LBS would perform when using an unconverging learned belief model or value model.",
                "The choice of the number of factorized private features in the belief model is not clear.",
                "The efficacy of LBS, especially in more complex environments like Contract Bridge, is not convincingly demonstrated despite the provided ablation studies."
            ],
            [
                "More detail is required to explain why multi-agent search is not theoretically sound. If the trained model is only accurate for single agent search, is it not possible to train a model that is compatible with multi-agent search under different settings for max range?",
                "The authors focus on 2-player Hanabi and claim it to be straightforward to extend to any number of players. However, SPARTA itself was computationally limited to single-agent search for these 3-player and up variants. Applying your approach in these experiments would make a stronger case for elevation of the state-of-the-art than the 6-card variant.",
                "The experimental setup requires significantly more details on the hardware used for training, testing and validating.",
                "Have you examined how this would look for more general partially observable settings? In particular, work on POSGs with public observations [Hor\u00e1k, K.; and Bosansk\u00fd, B. 2019. Solving Partially Observable Stochastic Games with Public Observations. In AAAI Conf. on Artificial Intelligence, 2029\u20132036. AAAI Press.]",
                "Are there any other DEC-POMDP settings that you considered? It may be insightful to compare the effects of different feature spaces."
            ]
        ],
        "generated_comments": {
            "all": [
                "The abstract provides a good overview of the paper. However, it would be beneficial to include a brief mention of the key results or findings of the paper to give readers a sense of the impact and significance of the work.",
                "The introduction does a good job of setting the context and explaining the motivation for the work. However, it could be improved by providing a clearer statement of the problem that the paper addresses.",
                "The methodology section is detailed and provides a good explanation of the Learned Belief Search (LBS) method. However, it would be helpful to include a more explicit comparison of LBS with other existing methods, highlighting the unique features and advantages of LBS.",
                "The paper mentions the results of applying LBS to the benchmark problem of two-player Hanabi self-play. However, it would be beneficial to include more detailed discussion of these results, including any limitations or potential areas for future work.",
                "Please ensure that all figures and equations are included in the final version of the paper and that they are clearly labeled and referenced in the text.",
                "The paper cites a number of previous works. However, it would be helpful to provide a more detailed discussion of how this work builds on or differs from these previous studies.",
                "The paper could benefit from a conclusion section that summarizes the main findings, discusses the implications of the work, and suggests directions for future research. It would also be beneficial to provide a brief discussion on the potential challenges and benefits of these future directions.",
                "The paper uses a number of technical terms and acronyms. It would be helpful to define these terms when they are first introduced to make the paper more accessible to a broader audience.",
                "In some sections, the writing is dense and could be clarified. For example, in the section 'P1 private observation history', the explanation of the RNN architecture could be simplified or broken down into more manageable parts. The 'A DEFINITION OF GROUNDED BELIEF AND EXACT BELIEF' section could also benefit from further explanation or examples.",
                "To enhance the reproducibility of the study, it would be beneficial to provide more details about the experimental setup, including any parameters used in the LBS method.",
                "In the section 'P1 private observation history', it would be beneficial to provide a brief explanation or reference as to why the trained belief model would no longer be accurate if more than one player was considered.",
                "In the 'EXPERIMENTAL SETUP' section, it would be helpful to provide a brief explanation of why Hanabi was chosen as the game for this experiment.",
                "In the 'BLUEPRINT TRAINING' section, it would be beneficial to provide a brief discussion on why other designs were not as successful.",
                "In the 'BELIEF LEARNING' section, it would be helpful to provide a brief explanation or reference as to why a setup similar to that of reinforcement learning was chosen to train the belief model.",
                "In the 'RESULTS' section, it would be beneficial to provide a brief explanation or reference as to why the LBS-k method may naturally avoid certain situations.",
                "The paper could benefit from a more detailed discussion on the limitations of the current study and potential implications for future research.",
                "The authors should consider adding a section discussing the broader impacts of their work, including potential applications and implications for the field."
            ]
        },
        "alignments": {
            "all": [
                {
                    "reference_id": 4,
                    "predicted_id": 12,
                    "relative_specificity": "same",
                    "relatedness": "medium",
                    "pairwise_result": {
                        "relatedness": "medium",
                        "relative_specificity": "same",
                        "same_meaning": true
                    },
                    "count": 4,
                    "score": 0.8,
                    "reference_comment": "Comparisons of different design/hyperparameter choices should be included to help judge the benefit of using learning for belief representation.",
                    "predicted_comment": "In the 'BLUEPRINT TRAINING' section, it would be beneficial to provide a brief discussion on why other designs were not as successful."
                },
                {
                    "reference_id": 1,
                    "predicted_id": 9,
                    "relative_specificity": "more",
                    "relatedness": "medium",
                    "pairwise_result": {
                        "relatedness": "medium",
                        "relative_specificity": "more",
                        "same_meaning": true
                    },
                    "count": 4,
                    "score": 0.8,
                    "reference_comment": "The experiment settings, problem description, and discussions need more elaboration.",
                    "predicted_comment": "To enhance the reproducibility of the study, it would be beneficial to provide more details about the experimental setup, including any parameters used in the LBS method."
                },
                {
                    "reference_id": 2,
                    "predicted_id": 9,
                    "relative_specificity": "same",
                    "relatedness": "medium",
                    "pairwise_result": {
                        "relatedness": "medium",
                        "relative_specificity": "same",
                        "same_meaning": true
                    },
                    "count": 5,
                    "score": 1.0,
                    "reference_comment": "The experimental setup requires significantly more details on the hardware used for training, testing and validating.",
                    "predicted_comment": "To enhance the reproducibility of the study, it would be beneficial to provide more details about the experimental setup, including any parameters used in the LBS method."
                },
                {
                    "reference_id": 0,
                    "predicted_id": 10,
                    "relative_specificity": "more",
                    "relatedness": "high",
                    "pairwise_result": {
                        "relatedness": "high",
                        "relative_specificity": "more",
                        "same_meaning": true
                    },
                    "count": 5,
                    "score": 1.0,
                    "reference_comment": "More detail is required to explain why multi-agent search is not theoretically sound. If the trained model is only accurate for single agent search, is it not possible to train a model that is compatible with multi-agent search under different settings for max range?",
                    "predicted_comment": "In the section 'P1 private observation history', it would be beneficial to provide a brief explanation or reference as to why the trained belief model would no longer be accurate if more than one player was considered."
                }
            ]
        },
        "metrics": {
            "all": {
                "n_reference": 22,
                "n_generated": 17,
                "n_total_aligns": 4,
                "recall": 0.16,
                "precision": 0.047058823529411764,
                "pseudo_jaccard": 0.04,
                "specificity_more": 0.5,
                "specificity_less": 0.0,
                "specificity_same": 0.5
            }
        },
        "metrics_for_reviews": {
            "all": [
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 3
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 4
                },
                {
                    "recall": 0.4,
                    "precision": 0.11764705882352941,
                    "pseudo_jaccard": 0.1,
                    "n_real": 5
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 5
                },
                {
                    "recall": 0.4,
                    "precision": 0.11764705882352941,
                    "pseudo_jaccard": 0.1,
                    "n_real": 5
                }
            ]
        }
    },
    {
        "doc_id": "-qB7ZgRNRq",
        "method": "gpt_bare_independent_chunk",
        "reference_comments": [
            [
                "The motivation for the new task proposed in the paper is not clear.",
                "The paper does not compare the proposed model, DDNet, to any other baselines that incorporate the audio information in a different way.",
                "The paper incorrectly claims that the method from Serdyuk et al. (2018) was 'concurrent', despite it being published in 2018.",
                "It is unclear why the Spoken-CoQA dataset includes text transcripts as well as the audio. It would make more sense for the text transcripts to be part of the model solving the dataset."
            ],
            [
                "The work is limited in its scope and is not yet ready to be published at ICLR due to lack of comparisons made to prior approaches, making it hard to assess the merits of the proposed approach.",
                "The authors do not mention any plans of releasing the new dataset described in this work, which is a concern.",
                "It would be interesting to show how F1 scores vary on the test instances as a function of the number of turns in the conversation, and how test F1 scores vary as a function of ASR accuracy of the spoken documents/questions.",
                "The error rate of the ASR system on the spoken documents and spoken questions should be provided to give the reader an idea of the accuracy of the transcriptions fed as input to the student model.",
                "In Table 4, the F1 scores using SDNet are higher for S-CoQA compared to CoQA which is unexpected. The authors should provide an explanation for this.",
                "The reliance of the proposed system on clean text is a significant issue that needs to be addressed."
            ],
            [
                "The paper's contributions and novelty are unclear, and it's uncertain if they warrant acceptance.",
                "The paper's methods, including the cross attention mechanism for speech and text embedding fusion and knowledge distillation for combatting ASR errors, are existing, well-studied methods.",
                "The Spoken-CoQA dataset, which is a significant contribution of the paper, is not made available.",
                "The paper should clarify whether the knowledge distillation and cross attention mechanisms can be combined for better performance.",
                "The paper should address whether the textual input is more useful than the audio input in the Spoken-CoQA dataset, especially considering the audio input is larger and more difficult to process."
            ],
            [
                "The biggest weakness of this paper is in its data construction. When the ASR output is noisy, the spans refer to ghost token positions based on the clean text. This makes the data difficult to learn from and may result in models predicting the wrong span.",
                "The paper falls short of delivering a usable dataset for speech-based conversational QA. The authors should consider returning the audio segments as answers instead of using text-based spans. This might require additional annotation but could make the dataset more meaningful and usable.",
                "The use of a knowledge distillation (KD) layer to address the issue of noisy ASR text is questionable. The KD layer shows the model the gold clean transcription (original passage), which could defeat the purpose of speech-based conversational QA as motivated in this paper."
            ]
        ],
        "generated_comments": {
            "all": [
                "The abstract provides a good overview of the paper. However, it would be beneficial to include a brief mention of the results obtained from the experiments. This would give readers an immediate understanding of the effectiveness of the proposed method.",
                "The introduction provides a good background of the research area. However, the authors could further emphasize the novelty and significance of their work. For instance, it would be helpful to clarify why incorporating spoken content into machine comprehension is important and what potential applications it could have.",
                "The authors have done a good job of explaining the dataset used for their experiments. However, it would be beneficial to provide more details about the dataset, such as the nature of the questions and answers, the length of the conversations, and the types of topics covered.",
                "The methodology section is well-written and detailed. However, the authors could provide more explanation about the intuition behind their novel knowledge distillation (KD) method. It would also be helpful to include a discussion on the limitations of their method and potential ways to overcome these limitations.",
                "The authors should provide more details about the Encoding Layer, Attention Layer, and Output Layer. For instance, what specific techniques are used for encoding and attention? How are the start and end indices computed in the Output Layer?",
                "The authors should provide more details about the teacher and student models. What specific models are used? How are they trained?",
                "The authors mention that their proposed method achieves superior performance, but they do not provide any specific results or comparisons with other methods. Including this information would strengthen their claims and provide readers with a clearer understanding of the effectiveness of their method.",
                "The authors should provide more details about the baselines and the experiments conducted. What specific models are used? How are they trained? What specific experiments were conducted? What were the results?",
                "The authors should provide more details about the fusion mechanisms. What specific mechanisms are used? How are they implemented?",
                "The authors have done a good job of discussing related work. However, they could provide a more detailed comparison of their work with existing methods, highlighting the advantages and disadvantages of each. If not already present, a 'Related Work' section should be included to provide context for their research and to highlight how their work contributes to the existing body of knowledge.",
                "The paper lacks a conclusion section. A conclusion summarizing the main findings, contributions, and potential future work would be beneficial. In the 'Conclusion' section, the authors should provide more details about the future work. What specific research questions will be investigated? What methods will be used?",
                "The authors refer to several figures and tables in the text, but these are not included in the provided paper chunk. Including these would provide valuable visual aids to help readers understand the proposed method and the results of the experiments.",
                "The authors have cited relevant literature throughout the paper. However, the references are not included in the provided paper chunk. Including these would allow readers to explore the cited works in more detail. The authors should ensure that all references are correctly formatted and complete.",
                "The paper is generally well-written, but there are some instances of awkward phrasing and unclear sentences. For example, in the sentence 'Our first intuition is speech utterances and text contents share the dual nature property...', it is unclear what the authors mean by 'dual nature property'. Clarifying or rephrasing such sentences would improve the readability of the paper. The authors should consider having a native English speaker proofread the paper to correct any grammatical or syntactical errors.",
                "The authors should consider including a 'Limitations' section to discuss any potential weaknesses or limitations of their study. This will help readers to understand the scope and applicability of the research findings.",
                "In the 'Appendix' section, the authors should provide more details about the speech features. What specific features are used? How are they computed?"
            ]
        },
        "alignments": {
            "all": [
                {
                    "reference_id": 0,
                    "predicted_id": 1,
                    "relative_specificity": "more",
                    "relatedness": "high",
                    "pairwise_result": {
                        "relatedness": "high",
                        "relative_specificity": "more",
                        "same_meaning": true
                    },
                    "count": 2,
                    "score": 0.4,
                    "reference_comment": "The motivation for the new task proposed in the paper is not clear.",
                    "predicted_comment": "The introduction provides a good background of the research area. However, the authors could further emphasize the novelty and significance of their work. For instance, it would be helpful to clarify why incorporating spoken content into machine comprehension is important and what potential applications it could have."
                },
                {
                    "reference_id": 0,
                    "predicted_id": 9,
                    "relative_specificity": "more",
                    "relatedness": "high",
                    "pairwise_result": {
                        "relatedness": "high",
                        "relative_specificity": "more",
                        "same_meaning": true
                    },
                    "count": 2,
                    "score": 0.4,
                    "reference_comment": "The work is limited in its scope and is not yet ready to be published at ICLR due to lack of comparisons made to prior approaches, making it hard to assess the merits of the proposed approach.",
                    "predicted_comment": "The authors have done a good job of discussing related work. However, they could provide a more detailed comparison of their work with existing methods, highlighting the advantages and disadvantages of each. If not already present, a 'Related Work' section should be included to provide context for their research and to highlight how their work contributes to the existing body of knowledge."
                },
                {
                    "reference_id": 0,
                    "predicted_id": 1,
                    "relative_specificity": "more",
                    "relatedness": "medium",
                    "pairwise_result": {
                        "relatedness": "medium",
                        "relative_specificity": "more",
                        "same_meaning": true
                    },
                    "count": 2,
                    "score": 0.4,
                    "reference_comment": "The paper's contributions and novelty are unclear, and it's uncertain if they warrant acceptance.",
                    "predicted_comment": "The introduction provides a good background of the research area. However, the authors could further emphasize the novelty and significance of their work. For instance, it would be helpful to clarify why incorporating spoken content into machine comprehension is important and what potential applications it could have."
                }
            ]
        },
        "metrics": {
            "all": {
                "n_reference": 18,
                "n_generated": 16,
                "n_total_aligns": 3,
                "recall": 0.15416666666666667,
                "precision": 0.046875,
                "pseudo_jaccard": 0.037562656641604006,
                "specificity_more": 1.0,
                "specificity_less": 0.0,
                "specificity_same": 0.0
            }
        },
        "metrics_for_reviews": {
            "all": [
                {
                    "recall": 0.25,
                    "precision": 0.0625,
                    "pseudo_jaccard": 0.05263157894736842,
                    "n_real": 4
                },
                {
                    "recall": 0.16666666666666666,
                    "precision": 0.0625,
                    "pseudo_jaccard": 0.047619047619047616,
                    "n_real": 6
                },
                {
                    "recall": 0.2,
                    "precision": 0.0625,
                    "pseudo_jaccard": 0.05,
                    "n_real": 5
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 3
                }
            ]
        }
    },
    {
        "doc_id": "0NQdxInFWT_",
        "method": "gpt_bare_independent_chunk",
        "reference_comments": [
            [
                "The method is a small extension to the DPS method where the network that selects which rows to samples is conditioned on the existing measurements.",
                "The paper did not compare to any other active sampling strategies. The authors made no effort to replicate existing methods.",
                "The Markov chain example in section 4.1 was hard to follow and more distracting than informative.",
                "The results with active sampling were only marginally better than results with a fixed (learned) sampling strategy.",
                "The method is applicable only to true subsampling problems, not general sensing. That is, one isn't designing the rows of a measurement matrix on the fly but rather selecting which row from an existing matrix (identity in most of the examples) that one would like to sample from.",
                "Because of the nonlinearity in the forward model, equation (9) is not actually proximal gradient descent. There's a sign(F^HD\\circFX) term missing from the (sub) gradient.",
                "The expression A^H(Ax-Y\\circ sign(A(x))) is a subgradient of 1/2|| Y - |A(X)|||^2 but A^H(|Ax|-Y) is not. I would avoid calling (9) projected gradient descent as the 'gradient' isn't really a gradient."
            ],
            [
                "The proposed approach appears to be incremental: ADPS adds a simple sequential update structure (of a context vector) to DPS, which can be described by only two equations (6 and 7). The simplicity of the changes proposed (over DPS) is not a limitation, but it could be accompanied by an in-depth theoretical analysis, a convincing qualitative discussion or extensive experiments demonstrating the practical relevance of the proposed approach.",
                "The paper contributes by extending DPS into an active/sequential learning framework achieving significant performance gains over DPS, mainly on toy problems. However, there is room for more extensive experimental validation, perhaps beyond MRI."
            ],
            [
                "The paper lacks comparison to other active sub-sampling schemes, such as those proposed by Zhang et al., 2019 and Jin et al., 2019. It would be beneficial to see if the proposed method produces better results than these existing methods.",
                "The toy example provided is overly constructed and difficult to understand, which does not improve the quality of the paper.",
                "It is unclear what happens when the MNIST sampling ratio in Figure 3a is further increased. It would be helpful to know if A-DPS consistently outperforms DPS in low sampling ratio regimes."
            ]
        ],
        "generated_comments": {
            "all": [
                "The abstract provides a good overview of the paper, but it could be improved by providing a brief explanation of the problem that A-DPS is designed to solve. This would help to set the context for the rest of the paper.",
                "The authors do a good job of explaining the background and motivation for their work. However, it would be helpful if they could provide a clearer explanation of the limitations of the existing methods, such as DPS, and how A-DPS addresses these limitations.",
                "The authors provide a detailed explanation of their method, but some parts of it may be difficult to understand for readers who are not familiar with the field. It would be helpful if the authors could provide a more intuitive explanation of their method, perhaps with the help of diagrams or examples.",
                "The authors have mentioned several parameters without providing a clear explanation of their roles in the model. Providing such explanations would help readers understand the model better.",
                "The authors have made several choices in their model architecture and training process. It would be beneficial to provide justifications or references for these choices to demonstrate their necessity or effectiveness.",
                "There seems to be some repetition in the training details. It would be helpful to consolidate this information to avoid redundancy and improve the flow of the paper.",
                "The authors present a number of experiments to validate their method, but they do not provide a detailed discussion of the results. It would be helpful if the authors could provide a more thorough analysis of the results, including a discussion of any limitations or potential sources of error.",
                "The authors provide a good overview of the related work and have compared the performance of A-DPS with other methods. However, it would be helpful if they could provide a more detailed comparison, discussing the strengths and weaknesses of each method and why A-DPS outperforms them.",
                "The paper could benefit from additional figures and tables to illustrate the method and results. The authors frequently refer to figures and tables in the text. It would be helpful to ensure that these figures and tables are clearly labeled and explained, and that they effectively illustrate the points being made in the text.",
                "The paper does not include a conclusion section. It would be beneficial to include a conclusion that summarizes the main findings of the paper, discusses the implications of these findings, and suggests directions for future research. The conclusion could be strengthened by more clearly highlighting the implications of the findings and their significance in the broader context of the field.",
                "The authors have briefly mentioned potential future applications and improvements for A-DPS. It would be interesting to see a more detailed discussion on these points, outlining specific challenges that might be encountered and how they could be addressed.",
                "The authors should ensure that all references are correctly formatted and consistent. Some references appear to be incomplete or incorrectly formatted."
            ]
        },
        "alignments": {
            "all": [
                {
                    "reference_id": 0,
                    "predicted_id": 6,
                    "relative_specificity": "same",
                    "relatedness": "medium",
                    "pairwise_result": {
                        "relatedness": "medium",
                        "relative_specificity": "same",
                        "same_meaning": true
                    },
                    "count": 2,
                    "score": 0.4,
                    "reference_comment": "The proposed approach appears to be incremental: ADPS adds a simple sequential update structure (of a context vector) to DPS, which can be described by only two equations (6 and 7). The simplicity of the changes proposed (over DPS) is not a limitation, but it could be accompanied by an in-depth theoretical analysis, a convincing qualitative discussion or extensive experiments demonstrating the practical relevance of the proposed approach.",
                    "predicted_comment": "The authors present a number of experiments to validate their method, but they do not provide a detailed discussion of the results. It would be helpful if the authors could provide a more thorough analysis of the results, including a discussion of any limitations or potential sources of error."
                }
            ]
        },
        "metrics": {
            "all": {
                "n_reference": 12,
                "n_generated": 12,
                "n_total_aligns": 1,
                "recall": 0.16666666666666666,
                "precision": 0.027777777777777776,
                "pseudo_jaccard": 0.025641025641025644,
                "specificity_more": 0.0,
                "specificity_less": 0.0,
                "specificity_same": 1.0
            }
        },
        "metrics_for_reviews": {
            "all": [
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 7
                },
                {
                    "recall": 0.5,
                    "precision": 0.08333333333333333,
                    "pseudo_jaccard": 0.07692307692307693,
                    "n_real": 2
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 3
                }
            ]
        }
    },
    {
        "doc_id": "-spj8FZD4y2",
        "method": "gpt_bare_independent_chunk",
        "reference_comments": [
            [
                "The paper lacks a complete theoretical analysis, such as the upper bound/lower bound on the regret of the algorithm.",
                "The algorithm should be explicitly written out with its pseudocode.",
                "The paper states that the communication is one-way from the decision-maker towards the controller, but it is strange not to consider the realization history observed by the decision-maker as communication. The goal of this work and how it differs from existing papers is unclear.",
                "The problem setup is unclear: it is not specified whether the state is i.i.d. sampled from the distribution $P_S$ or not.",
                "The relation between the constraint quantities $(\\rho,R)$ and the discussions in Section 3 is unclear.",
                "The constraints seem to be placed in the posterior probabilities involved in the TS algorithms. It is not clear what would happen if we consider UCB-class algorithms.",
                "The definitions of $D_\\alpha$ and reverse KL divergence $D_{KL}$ are missing. Usually, the original KL divergence is denoted by $D_{KL}$.",
                "In Section 3.3, it states ''If $S$ and $A$ are independent...'', which is not a common assumption in contextual bandits."
            ],
            [
                "There are inconsistencies and imprecisions in the writing, particularly in Section 2, which defines quantities, regrets, and gains that are not analyzed afterwards. Clarification is needed on the definitions and usage of G, \\rho, and R.",
                "The paper does not provide regret bounds. While it may be out of the scope of the paper, some commentary on this would be beneficial.",
                "The algorithm needs to be clearly outlined. While detailed explanations are provided, a pseudo-code would greatly improve readability and understanding.",
                "The paper could be better connected with existing literature on contextual bandit, such as contextual bandits with context uncertainties or Partially Observable MDPs."
            ],
            [
                "The results in the paper are largely adapted from known information-theoretic results, which limits the overall novelty of the work.",
                "The assumption that each agent's state is observed by the decision-maker, but not the agent itself, is unusual. The authors should clarify why they make this assumption.",
                "The practical coding scheme is about sending the state to the corresponding agent, which may not be necessary in practice.",
                "The controller 'decoder' function should have the joint states of all agents as an input to enhance the decoder design."
            ],
            [
                "The paper lacks theoretical performance guarantees for the clustering coding scheme. A characterization of how regret depends on the number of states, the rate constraint, number of actions, etc. would provide a more in depth understanding of the performances of the clustering scheme in various scenarios.",
                "The paper does not discuss how the proposed clustering schemes\u2019 performance decays as the total number of states grows. More states would induce larger clusters and hence larger distortion in the policy defined over the compressed states (compared to the target policy). This is particularly relevant as the paper uses personalized ad placements as a motivating example, where the content owner\u2019s valuation for a user view (i.e. impression) or conversion serves as the 'context' (or state), and may take a wide range of values."
            ]
        ],
        "generated_comments": {
            "all": [
                "Include a brief mention of the key results or findings from the numerical results in the abstract to give readers an immediate understanding of the practical implications of your work.",
                "Provide a clearer statement of the research question or objective in the introduction. What specific gap in the literature does this study aim to address?",
                "More explicitly highlight how your work builds on or differs from previous studies in the related work section to further justify the need for your research.",
                "Provide more intuitive explanations or examples in the CMAB Problem and Rate-Constrained CMAB sections to help readers unfamiliar with this area of research understand the key concepts.",
                "Discuss the limitations or potential drawbacks of the proposed approach in the Solution and Thompson Sampling sections to give a more balanced view.",
                "Discuss how the optimal solution for the RC-CMAB compares to other possible solutions and the trade-offs involved in choosing this solution.",
                "Ensure that each equation is clearly explained and that its relevance to the discussion is clear.",
                "Ensure that all figures are included, clearly labeled, and referenced in the text.",
                "Add conclusions and future work sections to summarize the key findings and implications of your work, and to suggest directions for future research.",
                "Provide brief explanations or references for concepts such as the reverse KL-divergence, the Blahut-Arimoto algorithm, and the significance of corner cases in the main body of the text.",
                "Explain the choice of KL-divergence as the distortion function, the practical coding scheme, and the agents chosen for comparison.",
                "Discuss the limitations of the study and potential future work.",
                "Discuss the practical and theoretical implications of the findings to help readers understand the real-world applications and the contribution to the existing body of knowledge.",
                "The conclusion section could benefit from a more structured presentation. Break down the findings into more digestible points, perhaps using subheadings.",
                "Discuss the implications of the assumption of an infinite number of agents and how the results might differ with a finite number of agents.",
                "In the annex section, provide more context for the equations presented and explain the significance of these equations in the context of the study.",
                "Provide more context for the section titled 'A.2 UPDATE CENTROIDS' and explain how it fits into the overall study.",
                "Provide more details on the ongoing work on deriving an information theoretic converse result on the regret performance and generalizing the framework to reinforcement learning problems.",
                "Add a brief introduction to the annex section to guide the reader.",
                "Revise the last sentence of the conclusion section for improved readability."
            ]
        },
        "alignments": {
            "all": [
                {
                    "reference_id": 6,
                    "predicted_id": 9,
                    "relative_specificity": "more",
                    "relatedness": "medium",
                    "pairwise_result": {
                        "relatedness": "medium",
                        "relative_specificity": "more",
                        "same_meaning": true
                    },
                    "count": 3,
                    "score": 0.6,
                    "reference_comment": "The definitions of $D_\\alpha$ and reverse KL divergence $D_{KL}$ are missing. Usually, the original KL divergence is denoted by $D_{KL}$.",
                    "predicted_comment": "Provide brief explanations or references for concepts such as the reverse KL-divergence, the Blahut-Arimoto algorithm, and the significance of corner cases in the main body of the text."
                },
                {
                    "reference_id": 0,
                    "predicted_id": 17,
                    "relative_specificity": "more",
                    "relatedness": "medium",
                    "pairwise_result": {
                        "relatedness": "medium",
                        "relative_specificity": "more",
                        "same_meaning": true
                    },
                    "count": 2,
                    "score": 0.4,
                    "reference_comment": "The paper lacks a complete theoretical analysis, such as the upper bound/lower bound on the regret of the algorithm.",
                    "predicted_comment": "Provide more details on the ongoing work on deriving an information theoretic converse result on the regret performance and generalizing the framework to reinforcement learning problems."
                }
            ]
        },
        "metrics": {
            "all": {
                "n_reference": 18,
                "n_generated": 20,
                "n_total_aligns": 2,
                "recall": 0.0625,
                "precision": 0.025,
                "pseudo_jaccard": 0.019230769230769232,
                "specificity_more": 1.0,
                "specificity_less": 0.0,
                "specificity_same": 0.0
            }
        },
        "metrics_for_reviews": {
            "all": [
                {
                    "recall": 0.25,
                    "precision": 0.1,
                    "pseudo_jaccard": 0.07692307692307693,
                    "n_real": 8
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 4
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 4
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 2
                }
            ]
        }
    },
    {
        "doc_id": "7udZAsEzd60",
        "method": "gpt_bare_independent_chunk",
        "reference_comments": [
            [
                "The implication of Theorem 4.2 is not fully understood. The size(rho, kappa) critically depends on r, the rank of the weight matrix W. But if we decompose W=UV, where U is d*r and V=r*k, it seems like the VC dimension of HANN is still higher than the number of effective parameters, dr+rk. In this case, what benefit do HANN have over ReLU and sigmoid networks?",
                "The role of the binary activation in HANN is unclear. The critical assumption of Theorem 4.2 is that the weight matrix is low-rank. In this case, can't the layer with low-rank weight be reformulated as two layers with a small bottleneck hidden layer of dimensionality r, which has much smaller number of parameters than the equivalent network? If this is the case, the result seems to be only relevant to the low-rank assumption, not the HANN itself."
            ],
            [
                "The title and introduction of the paper suggest that a more general class of Quantized Neural Networks (QNNs) have small VC dimension, but the model studied is essentially a two-layer NN. This raises doubts about whether any non-toy quantized models will have small VC dimension. An experiment similar to Zhang et al 2017 could easily verify this.",
                "The paper's focus on studying the VC dimension of Neural Networks (NNs) is questionable. The authors should clarify what we are aiming to learn from this, as in practice VC dimensions often provide non-meaningful bounds.",
                "The title and introduction of the paper may overstate the significance of the results, and the motivation for the study may not be strong enough."
            ],
            [
                "The bound on the VC dimension for hyperplane augmented neural networks (HANNs) seems quite large: O(k^r). This seems to be a major limitation in the application of the main result of the paper.",
                "The paper could significantly benefit from a discussion on the large bound on the VC dimension, either explaining more cases where the results are useful or clarifying this limitation.",
                "Using the numbers given in the experiments, with a dataset of size 77904 and k=100, and r=3 seems to result in vacuous bounds on generalization again, which questions the effectiveness of the main result."
            ]
        ],
        "generated_comments": {
            "all": [
                "Abstract: Include a brief explanation of what hyperplane arrangement neural networks (HANNs) are, as this is a key concept in your paper.",
                "Introduction: Provide a brief explanation of what VC theory is, as not all readers may be familiar with this concept.",
                "Related Work: Provide a brief summary at the end of this section, highlighting the gaps in the existing research that this paper aims to address.",
                "Notations: Provide a brief explanation of why these specific notations are used and how they relate to the overall research.",
                "Hyperplane Arrangement Neural Networks: Include a diagram or visual representation to help readers better understand this concept.",
                "Activations: Provide a more detailed explanation of how the VC dimension is calculated and why it is important in this context.",
                "The paper could benefit from a conclusion section summarizing the main findings and their implications.",
                "Consider adding a discussion section where the limitations of the study and potential future research directions are discussed.",
                "Some of the paragraphs are quite long and could be broken down into smaller sections to improve readability.",
                "Consider adding a methodology section where the research process is explained in detail. This would increase the transparency and reproducibility of the study.",
                "Consider adding a results section where the findings are presented in a clear and concise manner.",
                "Consider adding a limitations section where the limitations of the study are acknowledged.",
                "Consider adding a future research section where potential areas for future research are suggested.",
                "Consider adding an acknowledgements section where the contributions of others to the study are acknowledged.",
                "Consider adding a references section where all the sources used in the study are listed.",
                "Consider adding an appendix section where additional information or data that is not included in the main body of the paper is provided.",
                "Consider adding a glossary section where key terms used in the study are defined.",
                "In the 'Activations' section, provide more context or explanation about why the upper bound on the VC dimension of HAC(d, r, k) is significant and how it contributes to the existing body of knowledge.",
                "Include a brief, intuitive explanation of the concept of a sample compression scheme before diving into the formal definitions and theorems.",
                "Provide a brief overview or roadmap of the proof strategy before delving into the details of the proof for Theorem 3.6.",
                "In the 'A SAMPLE COMPRESSION SCHEME' section, provide more explanation or intuition behind the steps of the proof.",
                "In the 'EMPIRICAL RESULTS' section, provide more details about the training process, such as the specific training algorithms used, the choice of hyperparameters, and how the training data was prepared.",
                "Include the results of the experiment where a HANN was applied to the MOONS synthetic dataset with two classes with the hinge loss and discuss their implications.",
                "In paragraph 76, provide more explanation or reasoning behind the observation that the optimization appears to be biased towards a topologically simpler classifier.",
                "In paragraph 77, provide a brief description of what HANNs are for readers who may not be familiar with the term.",
                "In paragraph 78, provide more context or explanation about why k is a crucial hyperparameter for HANN.",
                "In paragraph 79, provide a brief explanation of what the model names HANN15 and HANN100 represent.",
                "The reproducibility statement section seems to be mixed with mathematical proofs and equations. Separate these into different sections for clarity.",
                "The section headers 'Thus, x *' seem to be misplaced and do not provide a clear indication of the content within the section. Revise these headers to accurately reflect the content of the sections.",
                "The mathematical proofs and equations in the reproducibility statement section are quite complex and may be difficult for some readers to follow. Provide more explanation or context to help readers understand these proofs and equations.",
                "Consider including a broader impact statement to discuss the potential societal implications of the research.",
                "Section 'Thus, x *': The section title is repeated multiple times, which is confusing. Provide unique and descriptive titles for each section.",
                "Paragraph 139: Correct the typographical error in the phrase 'we have with probably at least' to 'we have with probability at least'.",
                "Paragraph 140: Provide a step-by-step breakdown of the mathematical derivation leading to the final inequality.",
                "Paragraph 142: Provide more details about why the expectation is being calculated and how it fits into the overall argument of the paper.",
                "Paragraph 144: Provide more details about the process of calculating smoothed validation accuracy.",
                "Paragraph 145: Provide more information about the SwishSign function from the Larq library and why it was chosen for this study.",
                "Paragraph 146: Specify the hyperparameters with which the model HANN15 is trained.",
                "Paragraph 150: Provide more insight into why the performance for HANN100 is slightly worse and the performance for HANN15 is slightly better when the Weston-Watkins hinge loss is used.",
                "Paragraph 152: Provide a brief description of the No-Free-Lunch Theorem and its relevance to the study.",
                "Paragraph 154: When citing a specific theorem, briefly summarize its content and relevance to the study."
            ]
        },
        "alignments": {
            "all": []
        },
        "metrics": {
            "all": {
                "n_reference": 8,
                "n_generated": 41,
                "n_total_aligns": 0,
                "recall": 0.0,
                "precision": 0.0,
                "pseudo_jaccard": 0.0,
                "specificity_more": NaN,
                "specificity_less": NaN,
                "specificity_same": NaN
            }
        },
        "metrics_for_reviews": {
            "all": [
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 2
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 3
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 3
                }
            ]
        }
    },
    {
        "doc_id": "QmKblFEgQJ",
        "method": "gpt_bare_independent_chunk",
        "reference_comments": [
            [
                "The empirical performance gains provided by the DIGRAC method are difficult to understand. In many of the ARI graphs on synthetic data, the performance of various methods seems quite close. In the real data, methods overlap in their error bars.",
                "More explanation is needed about when DIGRAC's model for clustering is appropriate for a dataset and when it is not, and how adaptive the model can be in terms of performance despite those considerations."
            ],
            [
                "The practicality of the problem and the method studied in this paper is questionable. The authors mention that 'real data sets with ground-truth flow imbalances are not available to date', so they use normalized imbalance scores to evaluate clustering performance. This approach seems to go against the typical order of how machine learning models are developed.",
                "The experiments in Section 4 do not demonstrate the practical importance of clustering with respect to flow imbalances. As this is an empirical paper, it is necessary to provide solid empirical evidence that showcases the need for clustering with respect to flow imbalances.",
                "The authors use 80% of all nodes for training in their empirical evaluations. This percentage seems too high and it is suggested to consider using a smaller percentage, such as 5%, of all nodes for training."
            ],
            [
                "The theoretical properties of the loss function defined in Eq. (2) and (3) are not clear. The paper should provide a theoretical characterization for this loss and discuss cases where it could lead to degenerate solutions.",
                "The constraints of the optimization problem need to be clearly presented.",
                "The paper should examine how the loss behaves in terms of convergence.",
                "The novelty of the DIMPA algorithm is unclear. The paper should clarify what are the novel parts of this model with respect to previous works.",
                "The baseline models used for comparison could be enhanced. The paper should consider adding models that capture information flow, including algorithms that rely on stochastic blockmodels and a model that is based on directed modularity.",
                "The paper lacks scalability experiments with the running time of the algorithm and its comparison to baseline models."
            ]
        ],
        "generated_comments": {
            "all": [
                "Include a brief mention of the key results or findings from the experiments conducted in the abstract to give readers an immediate understanding of the effectiveness of the proposed method.",
                "Provide a brief overview of the structure of the paper at the end of the introduction to guide the reader through the rest of the paper.",
                "Provide a summary table comparing the features and limitations of the discussed methods, including the proposed method. This would highlight the novelty of the proposed method.",
                "Include more intuitive explanations or visual aids to help readers not familiar with the field understand the method.",
                "This section on Self-Supervised Loss for Clustering could benefit from further explanation or examples to help the reader understand the concepts being introduced.",
                "Include more figures and tables, particularly in the sections describing the DIGRAC method and the self-supervised loss for clustering.",
                "Include a detailed discussion of the results obtained from the experiments conducted, including comparisons with existing methods, and potential implications of the findings in the Results and Discussion section.",
                "Include a conclusion section summarizing the key points of the paper, the contributions of the work, and potential future directions.",
                "Ensure that all references are correctly cited and formatted according to the chosen citation style.",
                "Consider breaking long and complex sentences into shorter, simpler sentences for clarity.",
                "Provide detailed explanations or mathematical formulations for concepts such as the global probabilistic imbalance score, the 'sort' variant to select pairs of clusters, the directed mixed path aggregation scheme, and the Directed Stochastic Block Model (DSBM).",
                "Provide brief explanations of performance measures such as the Adjusted Rand Index (ARI) and Normalized Mutual Information (NMI) for readers who may not be familiar with them.",
                "Provide a detailed explanation of the task of detecting flow imbalances and how DIGRAC addresses it.",
                "Justify the choice of splitting the nodes into 10% test nodes, 10% validation nodes, and 80% training nodes.",
                "Include a discussion section to discuss the implications of the findings, potential applications, and future work.",
                "Include a limitations section to discuss the limitations of the study and how these might be addressed in future work.",
                "Provide more context about the data sets used in the experiments, including their characteristics and the real-world scenarios they represent.",
                "Explain the choice of using the Hermitian matrix from Cucuringu et al. (2020a) to construct an input feature matrix and how it contributes to the overall methodology.",
                "Provide evidence or explanation to support the claim that adding L sort vol_sum to the loss could be beneficial.",
                "Explain the concepts of semi-supervised setting and the use of must-link and cannot-link constraints mentioned in the 'Conclusion and Future Work' section.",
                "Discuss the potential for extending the framework to detect the number of clusters and the benefits of such an extension.",
                "Provide more context about the importance of performance in the sparse regime and various regularizations for future research.",
                "Discuss the potential for adapting the pipeline for directed clustering in extremely large networks and the challenges that might be encountered.",
                "Provide more context about the use of a feature matrix generated from A if no attributes are available and how it would be implemented."
            ]
        },
        "alignments": {
            "all": []
        },
        "metrics": {
            "all": {
                "n_reference": 11,
                "n_generated": 24,
                "n_total_aligns": 0,
                "recall": 0.0,
                "precision": 0.0,
                "pseudo_jaccard": 0.0,
                "specificity_more": NaN,
                "specificity_less": NaN,
                "specificity_same": NaN
            }
        },
        "metrics_for_reviews": {
            "all": [
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 2
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 3
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 6
                }
            ]
        }
    },
    {
        "doc_id": "b-ny3x071E5",
        "method": "gpt_bare_independent_chunk",
        "reference_comments": [
            [
                "The name 'matching function' makes the presentation of the method a little bit harder to digest. Since the function is a pseudometric (i.e., the larger it is, the larger the distance from the target), it should really be called with a name that reminds the reader of this nature (e.g., 'mismatch function').",
                "The theoretical results only deal with targets of specific forms and, especially, with $L=1$ only. Ideally, theoretical result with a dependency on $L$ would shed some light on the benefits and limitations of longer bootstrapping horizons.",
                "The connection between the way the bootstrapping target is formed in the method and traditional temporal difference learning needs to be elaborated on. In particular, the grounding role of that subtracted gradient 'nudging the trajectory in a descent direction' is the same as the one of the reward in temporal difference learning; but, while the reward is at the beginning of the trajectory, the grounding is here at the end of the optimization subtrajectory. Is there any mathematical connection beyond the general shared motivation?",
                "When the underlying function is highly nonlinear, there is the risk that the bootstrapping mechanism can lead the optimization process in worse areas of the landscape. For instance, if the function in Figure 1 had a bump/plateaux where $\tilde w$ is, the bootstrapping mechanism would cause more troubles than standard meta-gradients. Why is this not happening in practice?"
            ],
            [
                "The algorithm description in section 3 is very abstract. The paper would benefit from a running example and a dedicated section and pseudo-code describing the algorithm and how it can be instantiated in different experimental settings.",
                "The theoretical analysis is limited to noiseless 1-step target updates.",
                "The experimental evaluation in the multi-task meta-learning setting is limited to only compare with MAML on computer vision applications.",
                "Some engineering / handcrafting is still required by the machine learning practitioner to select what 'target' the meta-learner is going to optimize, as well as the proper 'metric' for the meta-learner to optimize for. Could the authors comment a bit about what heuristics they used when making these decisions? and whether the automation for this process is possible or not?",
                "What would it take to extend the analysis beyond 1-step noiseless target updates?",
                "How does the performance of BMG compare to alternative meta-learning algorithms like R2D2, Meta-OPT-net and prototypical networks? Have the authors experimented with other meta-learning benchmarks beyond image classification?"
            ],
            [
                "Given that you say BMG is compatible with any update function (so long as it is differentiable in the meta-parameters), it would be nice to have some experiments on learned sequence model update rules (e.g. RNN). All current experiments use update rules with a fixed functional form.",
                "I am not putting much weight on section 4 ('Performance Guarantees') given the gap between its assumptions and results vs. what is actually implemented, and the restriction to local optimization."
            ],
            [
                "The paper could benefit from more detailed discussions in certain areas to improve clarity and understanding.",
                "The methodologies of the experiments are difficult to follow, making it hard to link the results back to intuition or interpretation. More detailed descriptions or an algorithm box in the main text could help address this.",
                "The implementation and implications of the experiment on multi-task few-shot learning (Sec 6) are unclear. The authors should clarify the intuition of why a 'hot' expert transforms more information than a 'cold' expert, and why BMG is able to use this to improve performance.",
                "The training procedure for BMG in the multi-task few-shot learning experiment should be formally described in the main text.",
                "The analysis presented in Sec 4 ('Performance Guarantees') is not especially insightful. The conclusion drawn from this section is evident from the experiments themselves."
            ]
        ],
        "generated_comments": {
            "all": [
                "The abstract provides a good overview of the paper. However, it would be beneficial to provide a brief explanation of the term 'meta-optimisation problem' for readers who are not familiar with the concept.",
                "The introduction provides a good background on the topic. However, the transition between paragraphs could be smoother. It would be helpful to provide a brief explanation of how the proposed algorithm addresses the bottlenecks mentioned.",
                "The related work section is well-structured and provides a good overview of the existing literature. However, it would be beneficial to provide a more explicit comparison of the proposed method with existing methods.",
                "The methodology is explained in detail, but it might be too technical for some readers. It would be helpful to include a more intuitive explanation of the algorithm and its components, possibly with the help of diagrams or flowcharts.",
                "The authors have done a good job in providing performance guarantees for their proposed method. However, it would be beneficial to provide a more detailed explanation of the assumptions made in this section.",
                "The figures and equations are well-presented. However, the authors should ensure that all symbols and variables used in the equations are clearly defined in the text.",
                "A detailed discussion of the results obtained from the proposed method, including comparisons with existing methods and a discussion of any limitations or potential improvements, is missing and should be included.",
                "The authors should summarize the main findings of the paper, discuss their implications, and suggest directions for future research.",
                "The references are well-cited. However, the authors should ensure that all references are up-to-date and relevant to the topic of the paper.",
                "The authors should consider making the paper more accessible to a broader audience by providing more intuitive explanations of the technical concepts and methods.",
                "The authors should provide more details about the experimental setup, such as the specific games used in the Atari Arcade Learning Environment, and the rationale behind the choice of these games.",
                "The paper could benefit from a more thorough discussion of the limitations of the presented methods and potential avenues for future research.",
                "The authors should consider providing a brief explanation of the terms and abbreviations used in the paper for the benefit of readers who may not be familiar with them.",
                "The paper could benefit from a more thorough literature review. While the authors do cite some relevant works, they could provide a more comprehensive overview of the current state of the field and how their work fits into it.",
                "The authors should consider adding more visual aids, such as graphs or diagrams, to help illustrate their points. This would make the paper more engaging and easier to understand.",
                "The paper could benefit from a more thorough proofreading to correct minor grammatical errors and improve sentence structure.",
                "The authors should consider providing a clearer explanation of the limitations of their study and suggestions for future research. This would help readers understand the scope of the authors' claims and the potential for further research in this area.",
                "The authors should ensure that all tables and figures mentioned in the text are included in the paper and are properly referenced.",
                "The authors should ensure that all references are properly cited and formatted according to the appropriate style guide."
            ]
        },
        "alignments": {
            "all": [
                {
                    "reference_id": 0,
                    "predicted_id": 3,
                    "relative_specificity": "same",
                    "relatedness": "high",
                    "pairwise_result": {
                        "relatedness": "high",
                        "relative_specificity": "same",
                        "same_meaning": true
                    },
                    "count": 4,
                    "score": 0.8,
                    "reference_comment": "The algorithm description in section 3 is very abstract. The paper would benefit from a running example and a dedicated section and pseudo-code describing the algorithm and how it can be instantiated in different experimental settings.",
                    "predicted_comment": "The methodology is explained in detail, but it might be too technical for some readers. It would be helpful to include a more intuitive explanation of the algorithm and its components, possibly with the help of diagrams or flowcharts."
                },
                {
                    "reference_id": 1,
                    "predicted_id": 4,
                    "relative_specificity": "same",
                    "relatedness": "medium",
                    "pairwise_result": {
                        "relatedness": "medium",
                        "relative_specificity": "same",
                        "same_meaning": true
                    },
                    "count": 3,
                    "score": 0.6,
                    "reference_comment": "I am not putting much weight on section 4 ('Performance Guarantees') given the gap between its assumptions and results vs. what is actually implemented, and the restriction to local optimization.",
                    "predicted_comment": "The authors have done a good job in providing performance guarantees for their proposed method. However, it would be beneficial to provide a more detailed explanation of the assumptions made in this section."
                },
                {
                    "reference_id": 0,
                    "predicted_id": 9,
                    "relative_specificity": "more",
                    "relatedness": "medium",
                    "pairwise_result": {
                        "relatedness": "medium",
                        "relative_specificity": "more",
                        "same_meaning": true
                    },
                    "count": 2,
                    "score": 0.4,
                    "reference_comment": "The paper could benefit from more detailed discussions in certain areas to improve clarity and understanding.",
                    "predicted_comment": "The authors should consider making the paper more accessible to a broader audience by providing more intuitive explanations of the technical concepts and methods."
                }
            ]
        },
        "metrics": {
            "all": {
                "n_reference": 17,
                "n_generated": 19,
                "n_total_aligns": 3,
                "recall": 0.21666666666666667,
                "precision": 0.039473684210526314,
                "pseudo_jaccard": 0.03378623188405797,
                "specificity_more": 0.3333333333333333,
                "specificity_less": 0.0,
                "specificity_same": 0.6666666666666666
            }
        },
        "metrics_for_reviews": {
            "all": [
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 4
                },
                {
                    "recall": 0.16666666666666666,
                    "precision": 0.05263157894736842,
                    "pseudo_jaccard": 0.041666666666666664,
                    "n_real": 6
                },
                {
                    "recall": 0.5,
                    "precision": 0.05263157894736842,
                    "pseudo_jaccard": 0.05,
                    "n_real": 2
                },
                {
                    "recall": 0.2,
                    "precision": 0.05263157894736842,
                    "pseudo_jaccard": 0.043478260869565216,
                    "n_real": 5
                }
            ]
        }
    },
    {
        "doc_id": "uB12zutkXJR",
        "method": "gpt_bare_independent_chunk",
        "reference_comments": [
            [
                "The paper does not convincingly demonstrate model novelty or significant improvement to the state-of-the-art on the provided baseline.",
                "The model architecture seems very closely based on the HOPPITY baseline, with the primary change being to the multi-head graph encoder. This does not introduce a fundamentally new idea.",
                "Quantitative evaluations show only marginal improvement at best in comparison to the large pre-trained models.",
                "The evaluation omits a comparison to the closely related Yao 2021 model that is cited throughout the paper.",
                "The pre-training regime, which is presented as a contribution of this paper, does not seem to produce markedly stronger results. It might be valid to apply the same pre-training regime to some of the other models for a fair comparison.",
                "The qualitative evaluation does not yield clear conclusions. It would be beneficial to provide evidence that 'GRAPHIX demonstrates strong inductive biases in learning complex bug-fix patterns' or some conclusion on the kinds of bugs that GRAPHIX tends to fix.",
                "The pre-training regime is not particularly novel. The authors suggest deleting elements of subtrees from existing code and reconstructing them, which is not sufficiently novel."
            ],
            [
                "The paper does not clearly explain the relevance of the presented work despite not beating the state of the art. A discussion on this topic is missing.",
                "The anecdotal examples are not compared to the results other approaches give, making it unclear what to make of them.",
                "The claim that the model is more than 10x smaller than 'current large scale sequence models' is misleading as only one of the evaluated baselines, 'BART', is that much larger. The presented approach is even outperformed by CodeT5-small, which is less than 2x as large.",
                "The paper lacks a discussion on the accuracy of detecting bug fixes by filtering for 'fix', 'bug', 'error', and 'exception'.",
                "The reasoning behind having exactly 600 nodes is not explained."
            ],
            [
                "The pre-training task, while claimed to be novel, is not particularly innovative. It involves 'masking sub-trees' on AST, which essentially asks the model to do 'missing code prediction', covering only a small subset of general program repair samples. The pre-training task could be more innovative if more thought was put into generating the pre-training dataset, such as how to generate data for pre-training other edits like copy, remove, and update.",
                "Pre-training is costly and does not provide a significant performance gain (<2%). This issue is more pronounced with medium-sized data. The reviewer suggests two questions for consideration: 1) Why is pre-training only done on 'sub-trees between 2 and 6 descendants'? Could the size be increased to cover longer edit sequences during pre-training? Is it possible to add such an experiment? 2) Could the lack of performance gain be due to the pre-training task only asking the model to predict a sequence of addition operations? Could more diverse tasks be added to allow the model to predict a variety of edits?",
                "The multi-head graph encoder does not seem particularly novel.",
                "The paper does not mention related works such as 'TFix: Learning to Fix Coding Errors with a Text-to-Text Transformer' and 'Learning semantic program embeddings with graph interval neural network'.",
                "The last paragraph in Section 4.1 mentions a single-head 'base' model, which is not mentioned in any experiment in the main paper. The reviewer suggests moving this description into the Appendix or including the 'base' model and its performance in Table 1/2.",
                "In Listing 2 Top, the code is not valid if the highlighted green part is removed. The reviewer asks for clarification on the before and after of that code snippet.",
                "The paper claims 'these observations suggest that the code abstraction may not be necessary'. The reviewer finds this argument weak and disagrees with the initial premise that 'code abstraction is necessary'."
            ],
            [
                "The paper lacks a comprehensive comparison with prior work, making the contributions over previous work hard to assess.",
                "The efficacy of the proposed multihead Graph Neural Network (GNN) scheme is not adequately ablated. The paper needs to include ablations with models of the same size.",
                "There are concerns about the scalability of the model given the need to encode the entire tree at each intermediate step.",
                "The paper needs to provide equal comparisons of Hoppity and one or more deeper non-multihead Graphix models in the 32M parameter domain.",
                "The contribution of pretraining seems quite slim; performance only increases a little on the Small dataset and actually decreases on the Medium data. This needs more analysis.",
                "The paper needs to analyze and discuss the potential scalability problems of reinstantiating and encoding the program graph on every edit, especially on longer chains of edits.",
                "The paper needs to clarify whether the ensemble-of-graphs model is meant to be a contribution in general or just for source code.",
                "The paper needs to provide a more detailed analysis of the ASDL-guided decoder, especially in comparison with a small instantiation of Hoppity."
            ]
        ],
        "generated_comments": {
            "all": [
                "1. Abstract: Include a brief mention of the limitations or potential areas for future work to give readers a more balanced understanding of the research.",
                "2. Introduction: Provide a brief overview of the paper's structure towards the end of the introduction to guide the reader through the paper.",
                "3. Motivating Examples: Include a brief explanation of the code snippets for readers who may not be familiar with Java.",
                "4. Approach: Provide a brief justification for the choice of the cross-entropy loss function.",
                "5. Multi-Head Graph Encoder: Include a visual representation of the encoder to aid understanding.",
                "6. Pre-Training Objective: Expand on the explanation of the novel pre-training strategy, including how it works and why it was chosen.",
                "7. Experiments: Provide a more detailed explanation of the experimental design, including why specific network architectures and data types were chosen.",
                "8. Dataset: Provide more context about the 'Patches in the Wild Java bug-fix benchmark', such as why it was chosen and how it compares to other potential benchmarks.",
                "9. Data Processing for GRAPHIX: Provide a more detailed explanation of the code parsing and ground-truth graph edit construction processes.",
                "10. Evaluation: Include a brief summary of the evaluation process and main findings.",
                "11. Results: Provide more context about the models chosen for comparison, including their design and capabilities.",
                "12. Discussion and Future Work: Expand on potential limitations of the current approach and potential directions for future research.",
                "13. Conclusion: Consider adding a section to summarize the main findings of the study and their implications.",
                "14. References: Include a brief literature review section to provide context and show how this work builds on previous research. Also, ensure that URLs are cited as references, following the citation style of the journal or conference.",
                "15. Terminology: Include a glossary or ensure that all terms are clearly defined upon first use.",
                "16. Visual Aids: Consider adding more visual aids, such as graphs or diagrams, to help illustrate complex concepts and results.",
                "17. Implementation Details: Provide more details about the implementation of GRAPHIX, such as the programming languages and tools used.",
                "18. Real-World Applications: Discuss the potential real-world applications and implications of GRAPHIX.",
                "19. Decoder: Provide a detailed explanation of the decoder to maintain the balance and completeness of the encoder and decoder section.",
                "20. Section Organization: Separate unrelated topics into distinct sections or subsections for clarity.",
                "21. High Precision Regime for GRAPHIX: Provide more details on how the calibration of prediction scores is performed.",
                "22. Ablation Studies: Provide more details on the role of the proposed multi-head architecture.",
                "23. More Anecdotal Examples: Include more bug fixing and code refactoring patterns learned by GRAPHIX.",
                "24. Negative Examples: Discuss potential solutions or future work to address the limitations of the proposed model.",
                "25. Annex: Clearly define the purpose of the annex or integrate this information into the main body of the paper.",
                "26. Figures and Tables: Ensure that all referred figures and tables are included in the final version of the paper."
            ]
        },
        "alignments": {
            "all": [
                {
                    "reference_id": 0,
                    "predicted_id": 13,
                    "relative_specificity": "more",
                    "relatedness": "medium",
                    "pairwise_result": {
                        "relatedness": "medium",
                        "relative_specificity": "more",
                        "same_meaning": true
                    },
                    "count": 2,
                    "score": 0.4,
                    "reference_comment": "The paper lacks a comprehensive comparison with prior work, making the contributions over previous work hard to assess.",
                    "predicted_comment": "14. References: Include a brief literature review section to provide context and show how this work builds on previous research. Also, ensure that URLs are cited as references, following the citation style of the journal or conference."
                }
            ]
        },
        "metrics": {
            "all": {
                "n_reference": 27,
                "n_generated": 26,
                "n_total_aligns": 1,
                "recall": 0.03125,
                "precision": 0.009615384615384616,
                "pseudo_jaccard": 0.007575757575757576,
                "specificity_more": 1.0,
                "specificity_less": 0.0,
                "specificity_same": 0.0
            }
        },
        "metrics_for_reviews": {
            "all": [
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 7
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 5
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 7
                },
                {
                    "recall": 0.125,
                    "precision": 0.038461538461538464,
                    "pseudo_jaccard": 0.030303030303030304,
                    "n_real": 8
                }
            ]
        }
    },
    {
        "doc_id": "nLb60uXd6Np",
        "method": "gpt_bare_independent_chunk",
        "reference_comments": [
            [
                "The quantitative results are good, but not revolutionary. The model does well on the crystal classification task, but this setting is described as 'not difficult'. It performs slightly worse than GemNet on molecular force regression. On the backmapping task, it is only compared against a naive transformer, as opposed to another rotation invariant model. Another instance of the proposed model outperforming a strong baseline on a difficult task would significantly improve the case the paper is making.",
                "While one of the advantages of the proposed method is scaling to arbitrary rank, the experiments are all limited to pairwise attention (not counting the current key element). It would be interesting to demonstrate the effect of scaling up the rank, especially as this is noted as a potential advantage of the GemNet baseline.",
                "Group representation-based approaches have not been compared against."
            ],
            [
                "The details of the four functions that make up the attention mechanism are vague. More elaboration on the technical details, such as what are rotation-invariant geometric quantities for tuples, is needed to improve readability.",
                "The paper lacks a mathematical proof of rotational equivariance.",
                "The paper does not provide information on the efficiency of the proposed method, especially when compared with other works.",
                "The paper does not include experiments testing rotation equivariance. It is recommended to have an experimental test for the rotation equivariance by comparing with other works, such as rotation equivariance achieved via data augmentation.",
                "The paper does not clarify whether the proposed method can be extended to larger point clouds. It is also unclear what the definition of 'small point clouds' is. An experiment on 3D point cloud classification, such as the popularly used Modelnet 40, is recommended."
            ],
            [
                "In Table 1, the proposed model performs worse than the baseline GemNet-Q. The authors should consider adjusting their method to incorporate properties such as the use of quadruplets atoms, the incorporation of energy, or a better architecture, in order to perform a fair comparison with this baseline."
            ],
            [
                "The authors do not clearly describe how the geometric product helps to achieve the rotation-invariant attributes. This should be explained in the main manuscript since this is one of the main contributions.",
                "Geometric products do not appear in both model architectures and appendix B. The authors need to explicitly describe how it is implemented.",
                "The interpretation of the linear combination in geometric algebra is not trivial. The paper lacks the interpretation, justification, and discussion about the attention mechanism in geometric algebra.",
                "The proposed architecture is limited to 'small point clouds' without clear explanation. If the statement about the computational complexity is the reason, the connection to it should be clarified.",
                "The authors defined four functions, V, M, J, and S. However, another function R is defined later. Why do the authors distinguish R from the others? Are the four functions cover everything sufficiently? Justification is required.",
                "The authors stated that GemNets can operate on quadruplets of atoms but the proposed network worked only in pairs of bonds from the central atom. If this is the limitation of the proposed network, clear statement and discussion are required. Moreover, a discussion is appreciated whether the proposed network has technical difficulties to include the force label."
            ]
        ],
        "generated_comments": {
            "all": [
                "The abstract provides a good summary of the paper. However, it would be beneficial to include a brief mention of the results or the impact of the proposed approach. This would give readers an immediate understanding of the significance of the work.",
                "The authors have done a good job in providing the necessary background information. However, it would be helpful to provide more context or examples to illustrate the importance of building symmetry into the architecture of a deep neural network.",
                "The related work section is comprehensive and well-cited. However, it would be beneficial to provide a more explicit comparison between the proposed approach and the existing methods. This would help readers understand the novelty and advantages of the proposed approach.",
                "The authors have provided a good overview of the applications of the proposed approach. However, it would be helpful to provide more details about the results obtained in these applications. This would give readers a better understanding of the effectiveness of the proposed approach.",
                "The methods section is detailed and well-explained. However, the authors could consider providing a visual representation of the proposed architecture. This would help readers better understand the structure and operation of the model.",
                "This section is quite technical and may be difficult for some readers to follow. The authors could consider simplifying the explanation or providing more intuitive examples to help readers understand the concepts.",
                "The paper does not include a results section. It would be beneficial to include a section discussing the results obtained from the proposed approach, including any quantitative evaluations or comparisons with existing methods. This would provide evidence of the effectiveness of the proposed approach.",
                "The paper does not include a conclusion section. It would be beneficial to include a conclusion summarizing the main findings of the paper and discussing potential future work.",
                "The paper refers to figures, but these are not included in the provided text. Including figures would greatly aid in understanding the proposed approach and its results.",
                "The paper refers to several references, but these are not included in the provided text. Including a list of references would allow readers to further explore the cited works.",
                "The authors have provided a detailed description of the model architectures used. However, it would be beneficial to include a brief overview of the rationale behind the choice of these specific architectures. This would help readers understand the thought process behind the model design.",
                "The authors have reported numerical results using the mean and standard error of the mean over 5 independent samples. It would be helpful if the authors could provide more information on the statistical tests used to analyze the results. This would strengthen the validity of the findings.",
                "The authors have mentioned that they selected specific prototypes and baselines for their study. It would be beneficial if the authors could provide a brief explanation of why these specific prototypes and baselines were chosen.",
                "The authors have compared their models with other models and mentioned that their models perform favorably. However, it would be helpful if the authors could provide more detailed comparative analysis, including the strengths and weaknesses of each model.",
                "The authors have provided a detailed explanation of the geometric algebra. However, this section seems to be more theoretical than related to reproducibility. It might be more appropriate to include this information in a separate section or appendix.",
                "The authors have provided Python-style pseudocode for the models used in this work. However, it would be helpful if the authors could provide a brief explanation of the pseudocode for readers who may not be familiar with Python or the Keras API.",
                "The authors mention potential extensions for future work. It would be helpful to provide a brief discussion on the implications of these extensions and how they could potentially improve the results or broaden the applicability of the method.",
                "The authors mention that the method is being used to memorize training data directly, rather than model a thermodynamic ensemble. It would be beneficial to provide a justification for this approach and discuss any potential limitations or drawbacks.",
                "The authors use the training set error to characterize model performance. It would be helpful to provide a discussion on why this is a suitable metric for this study and how it compares to other potential metrics.",
                "The authors discuss the properties of multivectors. It would be beneficial to provide a brief introduction to multivectors for readers who may not be familiar with the concept. Additionally, a visual representation or example could help illustrate these properties and make the concept more accessible."
            ]
        },
        "alignments": {
            "all": []
        },
        "metrics": {
            "all": {
                "n_reference": 15,
                "n_generated": 20,
                "n_total_aligns": 0,
                "recall": 0.0,
                "precision": 0.0,
                "pseudo_jaccard": 0.0,
                "specificity_more": NaN,
                "specificity_less": NaN,
                "specificity_same": NaN
            }
        },
        "metrics_for_reviews": {
            "all": [
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 3
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 5
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 1
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 6
                }
            ]
        }
    },
    {
        "doc_id": "cVak2hs06z",
        "method": "gpt_bare_independent_chunk",
        "reference_comments": [
            [
                "The motivation for CnC is centered on the class-conditional alignment loss. There is even a bound on the worst-group loss in terms of the average-group and class-conditional alignment loss. So why not replace step 2, and instead fine-tune the model using L_avg_group + L_alignment? Or even just train models from scratch with this loss. It would be good to compare to these. If CnC is simply more empirically successful than this alternative, then it would be good to see this.",
                "In a related vein to the previous question, how much is CnC buying us as compared to the usual supervised contrastive training? It would be good to see SupCon as a baseline in Table 1. This seems an important baseline, since the main idea of CnC is to pull items from the same class together in feature space, which is also done using SupCon.  The main (even only?) difference is the hard positive/negative sampling approach of CnC."
            ],
            [
                "The observation of aligning representation for improving model robustness is not novel. There are a lot of work with similar ideas in domain generalization/adaptation literature, e.g., [1], [2]. There\u2019s also a recent work [3] that applies contrastive learning for doing so. A more comprehensive discussion for these related work needs to be included.",
                "The assumption of Theorem 3.1 is not well explained and motivated. In particular, the assumption that \u201cthe loss function l(x; y) is 1-Lipschitz in x and bounded from above by one.\u201d seems to be necessary and simplify the proof a lot, but does not hold for typical losses like cross-entropy for classification and MSE for regression.",
                "Using ERM prediction as the group label is not convincing enough, and it is not clear how it would affect the contrastive part. It could be interesting to more extensively analyze how the label prediction affects the improvement given by the contrastive method, probably using a scientific setup where the label prediction is controlled.",
                "For the contrastive part, the current empirical comparison obfuscates the advantage on its own. To decouple it from the effect of wrong group prediction, it is important to compare in the setting where group labels are available, i.e., GDRO vs GDRO + contrastive. Also, there could be a lot of choices of negative selections but only one is used without sufficient explanations, it would be great to include more explanation or compare with some other possible choices as an ablation study.",
                "Though the proposed contrastive method leads to improved worst-group performance, it seems to decrease the average-case performance compared to baselines."
            ],
            [
                "The proof provided in the paper may not be intuitively useful, particularly due to the bound B on the weight matrix. The weight matrix and the representations are learned jointly, and equivalent predictions could be achieved by scaling the weight matrix down and the representations up. Additionally, the Lipschitz and boundedness constraints on the loss functions do not seem to apply in any of the settings explored experimentally.",
                "Section 5.2 is unclear, particularly regarding the role of ERM 'predicting the sensitive attribute'. It is not clear how ERM's predictions of the sensitive attribute play into the CNC algorithm.",
                "Some important training details, such as the clustering-based prediction from the first step ERM model, are buried in the appendix. These details seem crucial to the functioning of the method and should be discussed in the main body, possibly with an ablation study."
            ]
        ],
        "generated_comments": {
            "all": [
                "Clarity of the problem statement: The authors should provide more concrete examples or case studies to illustrate the problem of spurious correlations. This would help readers, especially those not deeply familiar with the topic, to better understand the problem and the need for the proposed solution.",
                "Explanation of the proposed method: The authors should provide a more detailed explanation of the Correct-N-Contrast (CNC) method. A step-by-step walkthrough of the method with a simple example would make the method more accessible to readers.",
                "Theoretical analysis: The presentation of the theoretical analysis could be improved. The authors should consider providing more intuitive explanations or visualizations to accompany the mathematical proofs. This would make the theoretical analysis more accessible to readers who may not have a strong mathematical background.",
                "Evaluation of the method: More details about the evaluation process should be provided. For instance, what were the configurations of the models used for comparison? Were there any specific conditions under which the proposed method performed particularly well or poorly?",
                "Discussion of limitations and future work: The authors should include a section discussing the limitations of their proposed method and potential directions for future work. This would provide a more balanced view of their work and help guide future research in this area.",
                "Missing equations and figures: There are several instances in the text where equations and figures are mentioned, but they are not included. Please ensure that all relevant equations and figures are included and correctly referenced in the final version of the paper.",
                "Formatting issues: There are several instances where the formatting is inconsistent or incorrect. Please ensure that all mathematical notation is correctly formatted in the final version of the paper.",
                "Computational complexity of the CNC method: The authors should discuss the computational complexity of the CNC method. This would provide readers with a better understanding of the practicality of the method.",
                "Detailed explanations of the results: The authors should provide more detailed explanations of the results in the 'EXPERIMENTAL RESULTS' section. For example, why does CNC perform better in more spurious settings (p corr > 0.95)? What are the implications of these results?",
                "Potential applications of the CNC method: The authors should discuss the potential applications of the CNC method. This would provide readers with a better understanding of the practical implications of the method.",
                "Reproducibility of the results: The authors should provide a more detailed discussion on the reproducibility of their results. For example, how sensitive are the results to the choice of hyperparameters? How robust are the results to changes in the dataset?",
                "Model Training Details: The authors should provide a rationale for the choice of specific hyperparameters and training details. This would help the reader understand why these particular settings were chosen and how they might affect the results.",
                "Comparison with other methods: The authors should provide a more detailed comparison of their method with other methods. This could include a discussion of the strengths and weaknesses of each method, and why their method might be preferred.",
                "Grammar and Sentence Structure: There are a few instances where the sentence structure could be improved for clarity.",
                "Consistency in Terminology: Ensure consistency in the use of terminology throughout the paper."
            ]
        },
        "alignments": {
            "all": []
        },
        "metrics": {
            "all": {
                "n_reference": 10,
                "n_generated": 15,
                "n_total_aligns": 0,
                "recall": 0.0,
                "precision": 0.0,
                "pseudo_jaccard": 0.0,
                "specificity_more": NaN,
                "specificity_less": NaN,
                "specificity_same": NaN
            }
        },
        "metrics_for_reviews": {
            "all": [
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 2
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 5
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 3
                }
            ]
        }
    },
    {
        "doc_id": "2234Pp-9ikZ",
        "method": "gpt_bare_independent_chunk",
        "reference_comments": [
            [
                "The paper lacks conceptual innovation. While the results are solid, there is little insight about the behavior of the method. No ablations are performed beyond the comparison with NAGO, making it hard to assess the importance of the individual components.",
                "The paper does not include results on ImageNet.",
                "The results are compared with models that use other teacher architectures, making it hard to determine if the improvements are due to an improved teacher or a better knowledge distillation method.",
                "The claim that a standard neural architecture search would produce architectures sampled from the same distributions and therefore not be efficient in exploring the space of students is insufficiently explored.",
                "The paper does not provide comparisons with other architecture search algorithms for knowledge distillation or surrogate functions, therefore the introduction of a new framework may not be warranted under the claims of the authors."
            ],
            [
                "The application of knowledge distillation (KD) into network architecture generator optimization (NAGO) appears to be naively done, suggesting that the proposed method is incremental and the contribution is limited.",
                "The differences between the proposed method and existing methods are not clearly highlighted.",
                "The comparison of results in Table 1 is not fair. The KD used in this paper used better teachers following the convention, but the competitor KD-LSR and SKD in the table are self-distillation methods, making the comparison meaningless.",
                "On the CIFAR100 dataset, the paper inaccurately reports that CRD used ShuffleNetV1, which has more parameters, while the original paper used WRN-40-2 as a teacher and trained the student of WRN-16-2.",
                "On the MIT67 dataset, AutoKD used the fine-tuned teacher, which is much beneficial to KD in terms of performance, while VID used an ImageNet-pretrained model for transfer learning.",
                "On the CIFAR10 dataset, the compared models have fewer parameters than that of NAGO for AutoKD, making it hard to say that AutoKD outperforms them.",
                "The experimental results are unconvincing. For example, as weight is zero in Figure 2, the accuracies in the table should show consistent performance but are deviated with respect to temperature.",
                "The accuracies of NAGO in Figure 4 appear low compared to the other results in the paper, which needs clarification.",
                "The use of KD on NAS introduces additional computational cost, but this is not clearly compared quantitatively."
            ],
            [
                "The paper's main difference from existing KD-NAS approaches is the search for a family of architectures, which mainly takes advantage of the generator in NAGO. This reduces the novelty and contribution of the work.",
                "The purpose of some experiments is unclear. It would be more beneficial to compare AutoKD with earlier KD-NAS approaches instead of NAGO to show the impact of KD on NAS.",
                "The paper does not clearly articulate how the family of student architectures can benefit knowledge distillation. It is suggested that the performance gains may result from the ensemble of networks.",
                "The comparisons shown in Figure 7 do not seem to make much sense.",
                "The logic and results shown in the visualization of Figure 6 are not clear."
            ]
        ],
        "generated_comments": {
            "all": [
                "The abstract provides a good overview of the paper. However, it would be beneficial to include a brief explanation of the key terms such as Knowledge Distillation (KD) and Neural Architecture Search (NAS) for readers who may not be familiar with these concepts.",
                "The introduction is well-structured and provides a clear problem statement. However, it would be helpful to provide a brief overview of the proposed solution (AutoKD) in this section as well.",
                "This section provides a comprehensive review of the existing literature. However, it would be beneficial to provide a more explicit comparison between the proposed method and the existing methods, highlighting the unique contributions of this work.",
                "The methodology is explained in detail, but it might be beneficial to include a more detailed explanation or visual representation of the AutoKD framework for better understanding.",
                "The experimental setup and results are well-presented. However, it would be beneficial to include more details about the datasets used in the experiments. Additionally, a discussion on the limitations of the proposed method and potential future work would strengthen the paper.",
                "This section provides valuable insights into the contribution of KD. However, the authors should consider discussing the implications of these findings in more detail. In this section, the authors mention that AutoKD enables better multi-fidelity correlation, as seen in Fig. 5. However, it would be beneficial to provide a brief explanation of what is depicted in Fig. 5 for readers who may not have immediate access to the figure.",
                "The authors provide a comparison of AutoKD with other KD methods. While this is informative, it would be helpful to provide a more detailed discussion on why AutoKD outperforms these methods. Are there specific features or aspects of AutoKD that make it more effective?",
                "The figures and tables included in the paper are informative. However, it would be beneficial to include more descriptive captions to aid reader understanding.",
                "A conclusion summarizing the key findings and contributions of the paper is missing. It would be beneficial to include this to provide a clear summary of the work. In the 'DISCUSSION AND CONCLUSION' section, the authors mention that their method searches for a family of networks sharing the same characteristics. It would be beneficial to provide a more detailed explanation of what these shared characteristics are and why they are important.",
                "The references are well-cited. However, the authors should ensure that all references are up-to-date and relevant to the topic.",
                "The language and style of the paper are appropriate for a scientific paper. However, the authors should consider using more accessible language to make the paper more readable for a broader audience.",
                "The authors mention that AutoKD can effectively search for the optimal student family with only 300 samples. It would be interesting to know why this specific number of samples was chosen and how it compares to the number of samples used in other methods.",
                "The authors' message 'DON'T BE PICKY' is catchy and memorable. However, it would be beneficial to provide a more detailed explanation of what this means in the context of their research.",
                "In the final paragraph, the authors mention that future work should explore how to fully exploit the distribution of the optimal student family. It would be helpful to provide some suggestions or hypotheses on how this could be achieved.",
                "The authors should consider discussing any limitations of their study. This would provide a more balanced view of their work and could also suggest areas for future research.",
                "Lastly, the authors should consider including a section on the practical implications of their research. How could their findings be used in real-world applications? This would help to demonstrate the relevance and impact of their work."
            ]
        },
        "alignments": {
            "all": []
        },
        "metrics": {
            "all": {
                "n_reference": 19,
                "n_generated": 16,
                "n_total_aligns": 0,
                "recall": 0.0,
                "precision": 0.0,
                "pseudo_jaccard": 0.0,
                "specificity_more": NaN,
                "specificity_less": NaN,
                "specificity_same": NaN
            }
        },
        "metrics_for_reviews": {
            "all": [
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 5
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 9
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 5
                }
            ]
        }
    },
    {
        "doc_id": "KPEFXR1HdIo",
        "method": "gpt_bare_independent_chunk",
        "reference_comments": [
            [
                "The authors should report the wall clock time to demonstrate the time performance of the fine-grained model.",
                "The authors should clarify the biggest time step the simulation can deal with, as the current time step is relatively small (0.001s).",
                "The authors should demonstrate how this method can scale to more complex topologies. All the experiments are currently on one square sheet, but it would be beneficial to see if the method can simulate something like a T-shirt or dress, which is more relevant to design and fabrication."
            ],
            [
                "The paper should include a discussion comparing this work and the latest work on differentiable cloth simulation in a mesh-based view, as mentioned in reference [1].",
                "The statement 'Previous research (Liang et al., 2019; Du et al., 2021) suffers from this problem, which unfortunately leads to learning implausible parameter values' is technically inaccurate. Leveraging prior knowledge for physical parameters is now a necessary step for system identification tasks.",
                "The motivation for using a yarn-level simulator is unclear. The experiments are too coarse to show the advantages of more accurate collision handling and detailed presentation, which are the reasons for proposing a yarn-level simulation. A more valid explanation for motivation or a set of better results that are more complex than 25*25 is expected.",
                "The manuscript should clarify why the authors chose the yarn-based method, how they plan to use this simulator, and where they see the simulator fits in. The motivation for using yarn-level, which is originally designed for fine details but applied on over-simplified models, is not convincing."
            ],
            [
                "The authors identify a major shortcoming of previous simulation models, namely the use of discontinuous force terms, and engineer alternative models that approximate the terms from domain literature but have the added benefit of being smooth everywhere.",
                "The paper raises a question about the non-linear stick-slip force term leading to oscillatory behavior, which could potentially lead to free energy being trapped in entropy and therefore thermal loss.",
                "The paper raises a question about why differences between inter/intra parameters (Table 2) and ground truth increase as the grid size increases.",
                "In the Comparison video, it is difficult to spot any significant difference between the different weaves, which is a weakness of the paper.",
                "The paper lacks real-world experiments, and the range of simulated experiments is not very wide, making it difficult to judge the expressivity / gamut of the model.",
                "The paper acknowledges that neither the specific problem nor the general idea of differentiable simulation is new, and it is unclear whether the specific solutions introduced in the paper generalize to other problems."
            ],
            [
                "The paper does not comment on the computational cost and comparisons to baseline methods. It would be beneficial to provide such information in the main paper, especially when compared with non-differentiable simulator [Cirio et al., 2014] and prior work on differentiable cloth simulation [Liang et al., In NeurIPS 2019].",
                "The quantitative results need to be presented in a clearer manner. For example, it would be good to show the material prediction error in percentage in Table 2-4 (rather than the absolute value). It would be beneficial to include the algorithm (refer to Section 3.1 in [Liang et al. 2019]) in the main paper.",
                "It is unclear whether the proposed differentiable simulation is deterministic or not? Whether the material estimation is sensitive to initialization? In this case, please consider reporting the standard deviation for multiple runs of the same setting.",
                "It is unclear what happens if the parameter prior was not provided to the proposed method in the control learning experiment. It would be beneficial to provide such ablation studies and discuss the results in the rebuttal."
            ],
            [
                "The design process of the model is heuristic and lacks analysis or ablation study to justify the design choices made.",
                "The paper does not discuss how the method performs as a function of the magnitude of the forces. Additional experiments should be conducted to illustrate this.",
                "There is a discrepancy between the claim in paragraph-2 of section 4.2.1 and the data presented in Fig-6 and Table-4. The paper claims that the error reduces by around 100 times when the training data increase from 5 frames to 25 frames, but the figures show only a 10-fold reduction.",
                "The experiments focus only on simulated woven cloth, and the models are heavily designed. This raises questions about the generalizability of the proposed method to other materials and weaving structures."
            ]
        ],
        "generated_comments": {
            "all": [
                "The abstract could be improved by providing a brief explanation of the key terms for readers unfamiliar with the topic. For instance, a concise definition or explanation of 'differentiable physics modeling' and 'gradient-based learning' would be beneficial.",
                "The introduction could be improved by providing a clearer statement of the paper's objectives and contributions.",
                "It would be beneficial to provide a more explicit comparison between the proposed model and existing models, highlighting the unique contributions of this work.",
                "The methodology section is detailed but could benefit from more intuitive explanations or visual aids to help readers understand the complex mathematical formulations.",
                "The explanation of the force models is detailed but could be challenging for readers not familiar with the topic. Consider simplifying the language or providing more intuitive explanations to make this section more accessible.",
                "This section is missing. It would be beneficial to see how the authors have evaluated their model and what results they have obtained.",
                "This section is also missing. A well-written conclusion summarizing the main findings, contributions, and potential future work is essential for a complete scientific paper.",
                "Ensure that all references are correctly cited and formatted according to the chosen citation style.",
                "Ensure that the appendix referred to in the paper is included in the final paper and that all information therein is clear and well-organized.",
                "Ensure that the figures referred to in the text are clear, well-labeled, and effectively support the text.",
                "The paper could benefit from a more thorough proofreading to correct minor typographical errors and improve readability.",
                "The authors should consider including more references to previous work throughout the paper to provide context and support for their claims.",
                "The authors should consider improving the organization of the paper. The paper seems to jump between different topics, which can make it difficult for readers to follow the authors' line of reasoning.",
                "The authors should provide a clear explanation of the physical meaning and significance of the variables and equations presented.",
                "The authors should consider providing a brief overview of the mathematical methods used in the paper.",
                "The authors should consider providing more context for the references cited in the paper.",
                "The authors should consider including a section on future work, the limitations of their study, and the practical applications of their research.",
                "The authors should provide a clear definition of any new variables introduced.",
                "The authors should ensure that all sections labeled as 'EQUATION' include the appropriate equations.",
                "The authors should provide a rationale for any assumptions made in the paper."
            ]
        },
        "alignments": {
            "all": []
        },
        "metrics": {
            "all": {
                "n_reference": 21,
                "n_generated": 20,
                "n_total_aligns": 0,
                "recall": 0.0,
                "precision": 0.0,
                "pseudo_jaccard": 0.0,
                "specificity_more": NaN,
                "specificity_less": NaN,
                "specificity_same": NaN
            }
        },
        "metrics_for_reviews": {
            "all": [
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 3
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 4
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 6
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 4
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 4
                }
            ]
        }
    },
    {
        "doc_id": "HyxLRTVKPH",
        "method": "gpt_bare_independent_chunk",
        "reference_comments": [
            [
                "The paper does not clearly demonstrate the advantages of using a linear scaling schedule over other schedules. For example, step-based schedules outperform the proposed method in 2 of the 4 tasks in Table 2, and Poly and Cosine schedules perform better in some budgets in Figure 2.",
                "The comparisons in Figure 2 and Table 2 are not convincing without considering the variance of different trials. It is unclear whether the advantage is due to the learning rate schedule or randomness. The paper should report the mean and variance for multiple trials and ideally perform a significance test.",
                "The paper should include other learning rate schedules in Table 2. As shown in Figure 2, step-based schedule is not among the top three schedules for CIFAR-10.",
                "As shown in Table 3, the proposed method requires waiting until the end of training to get the best performing model, while step-based schedule can find the best model around 90% training. This means early stopping is not possible for linear scaling based schedule, which could be useful when the training budget is large enough and evaluation is cheap.",
                "The paper lacks a deeper understanding of why a linear learning rate schedule might work better. The authors attempt to provide an explanation from the relationship between learning rate and gradient magnitudes, but no clear conclusion is given. The paper should investigate when no weight decay is used and whether there is any correlation between the learning rate and gradient norms.",
                "The paper does not specify the learning rate decay unit for the linear schedule. Is it decaying per epoch or per mini-batch? If epoch-based learning rate decay is used, it is essentially step-based learning rate decay with many steps.",
                "The paper should investigate when the linear schedule starts to outperform step-based decay in terms of epochs or iterations. The difference between two schedules for small batch size at the early stage of training might be less in comparison with large batch training, especially when the number of iterations is enough.",
                "The paper only compares different schedules with a single initial learning rate. Different initial learning rates may result in different behaviors. The paper should consider scenarios where the initial learning rate is small, as there might not be much difference for different schedules in such cases.",
                "The authors' rebuttal did not fully address the concern about the lack of early stopping in the proposed method, which could limit its usage, especially for Hyperparameter Optimization (HPO).",
                "The authors' rebuttal did not fully address the concern about the lack of understanding of why the linear scaling schedule is better."
            ],
            [
                "The paper lacks a sound theory explaining why linear decay or other smooth decay methods work well.",
                "The novelty of the methodology proposed by the authors might be limited, as Mishkin et al. have already experimented with linear decay."
            ],
            [
                "The paper makes unclear claims about the phenomena of gradient magnitude vanishing and its effectiveness. For example, in section 5, the authors state 'We call this \u201cvanishing gradient\u201d phenomenon budgeted convergence. This correlation suggests that decaying schedules to near-zero rates (and using BAC) may be more effective than early stopping.' This claim appears to be an overreach as the paper merely shows gradient magnitude decreasing with learning rate.",
                "The paper does not perform extensive comparisons for commonly used algorithms like Adam, which are key motivating use cases for budget-aware training, such as providing approximations for problems like neural architecture search and hyperparameter tuning."
            ]
        ],
        "generated_comments": {
            "all": [
                "Provide a brief explanation of what is meant by 'budgeted training' in the Abstract for readers who may not be familiar with the term.",
                "Improve the clarity of the paper's objectives and contributions in the Introduction.",
                "Clarify whether the 'allowed budget refers to a limitation on the total time' refers to computational time, real-world time, or some other measure in Introduction (paragraph id: 3).",
                "Explain why the constraint of limiting the number of iterations was chosen over others in Introduction (paragraph id: 4).",
                "Provide more detail on how the main contributions advance the field in Introduction (paragraph id: 9).",
                "Provide a more explicit comparison of the authors' work with previous studies in the Related Work section.",
                "Correct the typographical error from 'Budge-Aware Schedule' to 'Budget-Aware Schedule' in the Budget-Aware Schedules section.",
                "Provide more detail on how the observation that a better strategy is to systematically decay the learning rate in proportion to the total iteration budget was made and what the implications are in Budget-Aware Schedules (paragraph id: 19).",
                "Ensure that all referenced tables and figures, such as Table 1, are included in the final version of the paper in Budget-Aware Schedules (paragraph id: 21).",
                "Provide a brief explanation of the significance of the introduced budget-aware schedules and how they relate to the authors' work in Budget-Aware Schedules (paragraph id: 22-27).",
                "Improve the clarity of the presentation in some sections, such as paragraph 28, by providing a more structured comparison of the learning rate schedules.",
                "Provide more justification for the choices made in the experiments, such as the use of the CIFAR-10 dataset and ResNet-18 as the backbone architecture.",
                "Discuss the limitations of the study, including any situations where the linear schedule might not perform well and potential drawbacks of the linear schedule.",
                "Clarify some of the terminology used in the paper, such as 'budgeted convergence' and 'aggressive early descent'.",
                "Provide further analysis of the results, such as why cosine, poly, and linear schedules achieve very similar results and why the linear schedule significantly outperforms traditional step decay given limited budgets.",
                "Provide more detailed conclusions, including implications of the findings for future research or practice.",
                "Provide a detailed explanation or references for each of the four different learning rate schedules mentioned in paragraph 51.",
                "Provide more justification or evidence for the claim that 'smooth-decaying schedule, such as linear or cosine, are preferred over step decay' in paragraph 52.",
                "Discuss why 21 out of 100 random architectures could not be trained in paragraph 53. Was there a common factor or issue that led to these failures?",
                "Provide more context or background information about why data subsampling strategies are important in the context of budgeted training in paragraph 72.",
                "Expand upon the statement that 'it is inconclusive that one is strictly better than the other within the smooth-decaying family' in paragraph 77. What factors might influence which method is better?",
                "Support the claim that 'there does not exist a theory for learning rate schedules in the context of general non-convex optimization' with references in paragraph 82.",
                "Provide a reference for the claim of a link between SGD and simulated annealing in paragraph 90.",
                "Ensure that all mathematical expressions, such as the derivation for the equivalent learning rate, are correctly formatted and visible in paragraph 96.",
                "Include a conclusion section that summarizes the main findings and implications of the research.",
                "Ensure that all references are correctly formatted and consistent throughout the paper."
            ]
        },
        "alignments": {
            "all": [
                {
                    "reference_id": 0,
                    "predicted_id": 17,
                    "relative_specificity": "more",
                    "relatedness": "high",
                    "pairwise_result": {
                        "relatedness": "high",
                        "relative_specificity": "more",
                        "same_meaning": true
                    },
                    "count": 2,
                    "score": 0.4,
                    "reference_comment": "The paper lacks a sound theory explaining why linear decay or other smooth decay methods work well.",
                    "predicted_comment": "Provide more justification or evidence for the claim that 'smooth-decaying schedule, such as linear or cosine, are preferred over step decay' in paragraph 52."
                }
            ]
        },
        "metrics": {
            "all": {
                "n_reference": 14,
                "n_generated": 26,
                "n_total_aligns": 1,
                "recall": 0.16666666666666666,
                "precision": 0.012820512820512822,
                "pseudo_jaccard": 0.012345679012345678,
                "specificity_more": 1.0,
                "specificity_less": 0.0,
                "specificity_same": 0.0
            }
        },
        "metrics_for_reviews": {
            "all": [
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 10
                },
                {
                    "recall": 0.5,
                    "precision": 0.038461538461538464,
                    "pseudo_jaccard": 0.037037037037037035,
                    "n_real": 2
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 2
                }
            ]
        }
    },
    {
        "doc_id": "giit4HdDNa",
        "method": "gpt_bare_independent_chunk",
        "reference_comments": [
            [
                "No theoretical or empirical evidence is presented that confirms that the training speed of N-CODE is significantly lower compared to NODE.",
                "While performance seems generally higher, the limitations of the proposed N-CODE method are not clear.",
                "The claim of better performance in less time is not fully supported by the results."
            ],
            [
                "The supervised classification part of the paper is highly related to the 'Data Controlled Neural ODEs' section in Massaroli et al (2020b), a paper that has been cited in the related work section but not addressed in the main content. The problems tackled and the results are highly related to those of Massaroli et al (2020b). This issue needs to be addressed sufficiently.",
                "The unsupervised section needs more work. The experiments and tables can be described more effectively. For example, it would be preferable to clearly explain which row section 5.3 refers to in Figure 7, and which row corresponds to section 5.4.",
                "The paper claims that the replacement of a linear layer with a Neural CODE improves image reconstruction quality. This should mean that all layers in the encoder can be replaced to give better encoding, taking care of dimensionality (such as in Normalizing Flows). However, this paper uses a typical neural network for image reconstruction and generation. This suggests that the majority of heavy-lifting is done by the decoder, hence the Neural CODE is more amenable to warping the latent space suitable for the decoder. For image generation as well, the latent space has been designed so that the decoder can produce nice images, this is not necessarily a win for the Neural CODE.",
                "To make the case for Neural CODE, especially for images, higher resolution images need to be tackled, since it is in higher dimensions that the success of the advancements in the methods listed in Figure 7 lies."
            ],
            [
                "The authors should investigate how the model performance changes as f grows. Learning the parameters of a neural network via another neural network(s) is a very challenging problem, and it would be beneficial to see this verified or not.",
                "The connection with control theory can be made clearer. There is very little reference to Pontryagin's maximum principle and the link is not visible.",
                "The authors should test vanilla NODE on experiments 5.3 and 5.4. It would be interesting to see if the improvement of N-CODE is significant when NODE is latent."
            ],
            [
                "The paper is closely related to other works that have also focused on making the weights of neural ODEs time dependent. A more thorough discussion of the differences between these models is needed to better understand where the novelty/contribution comes in.",
                "The closed loop model, which is the main innovation, is thoroughly discussed in the paper. However, most experiments are performed with the open loop model, which is very similar to other models already proposed in the literature. This puts into question whether the full closed loop model is actually useful in practice.",
                "There is no evaluation of the number of functions evaluations in the paper. According to the abstract, the model trains faster so it seems important to include this information in the paper.",
                "The authors claim that the model achieves state of the art reconstruction on CIFAR10. However, reconstruction doesn\u2019t really make sense as a task (since the identity function would be optimal in this case). This claim is questionable and should be removed."
            ]
        ],
        "generated_comments": {
            "all": [
                "The abstract could benefit from a brief explanation of technical terms such as homeomorphisms, to make it more accessible to a wider audience.",
                "A brief overview of what Neural Ordinary Differential Equations (NODEs) are before discussing their limitations would be beneficial.",
                "Both papers could benefit from a simpler, high-level explanation of the proposed models (N-CODE and the hybrid version of autoencoders and generative normalizing flows) before diving into the technical details.",
                "More context and explanation for each equation included in the papers would be helpful.",
                "More detail about the experimental setup, including the datasets used, the specific models compared, the evaluation metrics used, and the training process (such as the number of epochs, learning rate, and any regularization techniques used) would be beneficial.",
                "A justification for the choice of optimizer and learning rate would be appreciated.",
                "Including the referred figures in the text with detailed captions explaining what each figure shows would be helpful.",
                "Including a conclusion that summarizes the main findings of the paper, discusses the implications of these findings, and suggests directions for future research would be beneficial.",
                "A list of references at the end of the paper would be helpful.",
                "Consider sharing the code and data, or at least providing more detailed information about the experimental setup to enhance the reproducibility of the study.",
                "Providing more context on how the work advances or diverges from previous studies would be beneficial.",
                "A brief discussion of potential methods or approaches for investigating the robustness and generalization properties of the model in future work would be appreciated.",
                "Including a brief, non-technical summary of the proof for readers who may not be familiar with the mathematical concepts used would be helpful.",
                "More detailed discussion on the experiments with different components and sampling strategies, including how the optimal number of components was determined and why certain strategies were chosen, would be beneficial."
            ]
        },
        "alignments": {
            "all": []
        },
        "metrics": {
            "all": {
                "n_reference": 14,
                "n_generated": 14,
                "n_total_aligns": 0,
                "recall": 0.0,
                "precision": 0.0,
                "pseudo_jaccard": 0.0,
                "specificity_more": NaN,
                "specificity_less": NaN,
                "specificity_same": NaN
            }
        },
        "metrics_for_reviews": {
            "all": [
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 3
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 4
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 3
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 4
                }
            ]
        }
    },
    {
        "doc_id": "b7ZRqEFXdQ",
        "method": "gpt_bare_independent_chunk",
        "reference_comments": [
            [
                "The paper lacks novelty as it combines existing procedures such as relativistic discriminator, Gumbel-Softmax approximation for categorical distribution, and features matching to improve upon vanilla sequence generation networks.",
                "The generated sentences by the GAN, especially the lengthy ones, are not semantically meaningful as illustrated in Table 8.",
                "The Mean Distance Alignment (MDA) and the Mean Square alignment (MSA) used for features distribution alignment encode the same matching up to a power 2, and it's unclear why they lead to different empirical results.",
                "The paper should consider aligning the overall distributions of the latent representations by considering metrics such as MMD or Wasserstein distance.",
                "The paper should clarify earlier that the used features are extracted from the discrimination network and from which layer of the discrimination network the features are extracted.",
                "The findings of human evaluation are not unequivocal as MSA and MDA achieve higher scores than the real sentences, and the best model with MSA is not preferred due to a lack of diversity and quality."
            ],
            [
                "The authors claim that the use of Gumbel-softmax in GAN training is under-explored, but this is not clear. There are other methods using Gumbel-softmax, such as Gu et al. 2019, and similar softmax with temperature annealing. The authors need to clearly distinguish between using Gumbel-softmax and other smoothed softmax methods.",
                "The authors missed some related work, such as DialogWAE (Gu et al. 2019) and ARAML (Ke et al. 2019). In particular, DialogWAE uses GAN and Gumbel-softmax for text generation, even though it focuses on dialog generation.",
                "To verify mode collapse issues, the authors should consider using Self-BLUE in addition to BLUE scores as a metric to evaluate the diversity.",
                "The novelty of the paper might be incremental. It seems that the novelty comes from using feature statistics alignment. To emphasize the contribution of feature statistics, the authors should consider comparing between the latent feature visualization with and without FSA, in addition to the ablation study."
            ],
            [
                "Although the proposed model is thoroughly evaluated and empirically effective, it is not very different from existing methods, except for the Feature Statistics Alignment (FSA). The application of FSA in this context might be novel; however, the proposed approach seems to be a simple combination of two existing approaches. Therefore, the novelty of the model is limited."
            ],
            [
                "In Table 2, the LSTM model gets NLL lower than the real data, which is a clear evidence of overfitting.",
                "In Table 2, the NLL_{gen} metric, used in SAL (Zhou et. al, 2020) to evaluate the diversity of the generator, is missing without explanation.",
                "In Table 3, the BLEU metric used is the BLEU(F) metric from SAL (Zhou et. al, 2020), which evaluates the generated sentences using the test set as a reference and thus cannot show the diversity of examples.",
                "In Table 3, the BLEU(B) metric from SAL (Zhou et. al, 2020) is missing. This metric evaluates the test set using the generated sentences as a reference, so it can detect mode collapse of a generative model.",
                "The evaluation metrics used in the paper prefer overfitted models, i.e., if the model can remember one example from the training set and repeat that sentence, it can get a very high score.",
                "The authors need to provide more evidence on the diversity of the generated sentences, for example by showing the NLL_{gen} metric on the synthetic dataset, and BLEU(B) metric on real datasets."
            ]
        ],
        "generated_comments": {
            "all": [
                "Include a brief mention of the specific improvements observed in the experiments in the abstract to give readers a clearer understanding of the impact of the proposed approach.",
                "Provide a brief overview of the proposed solution earlier in the introduction to set the context for the rest of the paper.",
                "Include a visual representation of the proposed architecture in the methodology section to help readers better understand the proposed solution.",
                "Ensure that all equations are correctly formatted and clearly explained in the text.",
                "Ensure that the results of the experiments are clearly presented and discussed, including a comparison of the proposed approach with existing methods.",
                "Provide a more in-depth discussion of these results. For instance, why does the LSTM generator outperform the RMC generator for shorter sequences but not for longer ones? What implications do these findings have for the field?",
                "Provide more context and discussion around the negative results. Why were these approaches unsuccessful? What can be learned from these failures?",
                "Include a conclusion that summarizes the main findings and discusses the implications of the results. Strengthen it by discussing the potential impact of this work on the field and its practical applications.",
                "Ensure that all references are correctly formatted and all cited works are included in the reference list.",
                "Include the 'Adversarial Training Algorithm Alg. 1' or provide a more detailed description for readers to understand the proposed framework.",
                "Define all acronyms upon first use for clarity.",
                "Include more information about the evaluation metrics used, such as NLL oracle and BLEU score, to help readers understand how the performance of the models was assessed.",
                "Provide more context about these models, such as their strengths and weaknesses, to better understand the novelty and advantages of the proposed framework.",
                "Include the referred appendices (A, B, C, D) or provide more context in the main text for readers to fully understand the work.",
                "Improve several grammatical errors and awkward phrasings throughout the text for clarity and readability.",
                "Complete the sentences in paragraph ids: 11, 36, 40, and clarify the contradictory sentence in paragraph id: 44.",
                "In paragraph id: 46, provide more details on why a CNN was chosen over other potential architectures.",
                "Revise the text to ensure that each sentence contributes to a clear, overarching argument or narrative.",
                "Provide more information about the topic at hand, the existing literature on the topic, and the gap in the literature that this research aims to fill.",
                "Revise vague sentences to provide more specific and accurate information.",
                "Consider restructuring the text to improve its flow and readability.",
                "Ensure that all information and ideas taken from other sources are properly cited."
            ]
        },
        "alignments": {
            "all": []
        },
        "metrics": {
            "all": {
                "n_reference": 17,
                "n_generated": 22,
                "n_total_aligns": 0,
                "recall": 0.0,
                "precision": 0.0,
                "pseudo_jaccard": 0.0,
                "specificity_more": NaN,
                "specificity_less": NaN,
                "specificity_same": NaN
            }
        },
        "metrics_for_reviews": {
            "all": [
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 6
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 4
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 1
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 6
                }
            ]
        }
    },
    {
        "doc_id": "zCu1BZYCueE",
        "method": "gpt_bare_independent_chunk",
        "reference_comments": [
            [
                "The experiments focus only on selecting a single initial learning rate, which is less interesting because normally a learning rate scheduler that changes over time is used. The experiment does not consider different types of learning rate schedulers for comparisons.",
                "The learning rate is just a scalar, so a simple grid search could be used to coarsely find a good learning rate and then refine it. This makes the focus on learning rate less impactful.",
                "The work would be more impactful if it demonstrated improvement in other hyper-parameter optimizations such as weight decay and convolution filter size and channels."
            ],
            [
                "The paper lacks comparisons to baseline hyperparameter tuning setups. For example, in Figure 3, the best final validation and/or test accuracies achieved by autoHyper and by random search for the same number of trials are not shown.",
                "The paper does not compare the proposed algorithm to existing state-of-the-art methods, which would be useful for a solid paper.",
                "The suggested initial learning rates (LRs) seem problematic to compare to. It would be useful to highlight how the suggested initial LRs were tuned.",
                "The suggested initial LRs were tuned using less trials than the proposed algorithm, and using a grid search algorithm that may be worse than random search.",
                "The suggested initial LRs were for a different model than the models considered in the experiments here, which means they could serve as a poor baseline.",
                "The ranges of values tuned over in Wilson 2017 seem to be quite close to several of the values proposed by autoHyper, meaning that perhaps repeating the same grid search could be competitive.",
                "In the cases where the autoHyper values are not close, they are sometimes outside the range considered by Wilson 2017, which could bias the results towards the proposed algorithm.",
                "Several recent works have shown that when tuning optimizers one needs to be careful to report the ranges used, as changing the hyperparameter ranges can drastically affect experimental results.",
                "Figure 1a would be much more informative if you showed the entire training trajectory, including past the first 5 epochs, to see if the selected learning rates actually generalize noticeably better.",
                "In your conclusion you discuss that you could extend your tuning algorithm to multiple hyperparameters, and I believe in order to truly demonstrate its capabilities this would be required."
            ],
            [
                "The algorithm has an implicit assumption that the response function is monotonously decreasing. The paper should clarify what happens if the response function does not decrease, and how the range of the search area is chosen in such cases.",
                "The algorithm introduces new hyperparameters, such as alpha and the 'rate of change plateaus'. The paper should explain how these hyperparameters are chosen and how they influence the result.",
                "The paper should provide a reasonable explanation for why the initial learning rate influences the testing accuracy, not just the convergence rate for training loss.",
                "The paper only compares the algorithm with the baseline. The authors should discuss if there are any other works about tuning the initial learning rate, or if this paper is the first of its kind.",
                "The reviewer suggests that it may be more convincing if the whole parameters are chosen together, not just the initial learning rate."
            ]
        ],
        "generated_comments": {
            "all": [
                "The abstract provides a good overview of the paper, but it could be improved by providing a brief explanation of the problem being addressed and the significance of the findings in a broader context.",
                "The introduction does a good job of setting the context and explaining the problem. However, it could be improved by providing a clearer statement of the paper's objectives and contributions.",
                "The methodology section is detailed and well-explained. However, the authors should consider providing more justification for their choice of parameters and methods. For example, why was the initial learning rate chosen as the single HP? Why was T set to 5 in the experiments?",
                "The authors have provided a detailed description of the experimental setups, including the hardware used, datasets, network architectures, and optimizers. However, it would be beneficial to include more information about the selection criteria for these elements. Why were these specific datasets, architectures, and optimizers chosen? What are the implications of these choices for the generalizability of the results?",
                "The results section provides a good amount of empirical evidence to support the authors' claims. However, it would be beneficial to include more comparative analysis with other methods. This would help to highlight the advantages of the proposed method. The results are presented in a clear and detailed manner. However, the authors frequently refer to appendices for additional details. If possible, consider incorporating key details into the main body of the paper to improve readability.",
                "The authors mention that in many cases where baselines perform better, they remain within the standard deviation of trials and are therefore not significantly better. However, it would be beneficial to conduct a formal statistical test to confirm this. This would strengthen the authors' argument and provide more robust evidence for the effectiveness of autoHyper.",
                "The related works section could be expanded to provide a more comprehensive review of the literature. This would help to situate the paper within the broader field of research.",
                "The figures and equations are well-presented and support the text. However, the authors should ensure that all figures and equations are properly referenced in the text. The authors frequently refer to tables and figures in the appendices. However, without seeing these tables and figures, it is difficult to evaluate their quality and relevance. In future, consider including key tables and figures in the main body of the paper, or providing them alongside the paper for review. The authors provide a wealth of additional experimental details in Section B. However, it would be beneficial to include a brief summary of these details in the main body of the paper. This would provide readers with a more complete understanding of the experimental design without having to refer to the appendices.",
                "The authors briefly mention that their method is susceptible to random initialization variations and that they leave the investigation of multiple trialling to future work. This is a good start, but a more thorough discussion of the limitations of the study would be beneficial. This could include potential biases in the experimental design, limitations of the algorithm itself, and areas where further research is needed.",
                "A conclusion section summarizing the main findings and implications of the study would be a valuable addition to the paper.",
                "The authors mention potential future work, such as adapting autoHyper to optimize multiple hyperparameters simultaneously. This is a good way to indicate the potential for further development of the algorithm. However, it would be beneficial to expand on this and discuss other potential avenues for future research.",
                "The authors should consider providing a more detailed explanation of some of the technical terms and concepts used in the paper. This would make the paper more accessible to readers who are not experts in the field.",
                "The authors should ensure that all references are correctly formatted and consistently styled."
            ]
        },
        "alignments": {
            "all": [
                {
                    "reference_id": 2,
                    "predicted_id": 2,
                    "relative_specificity": "more",
                    "relatedness": "medium",
                    "pairwise_result": {
                        "relatedness": "medium",
                        "relative_specificity": "more",
                        "same_meaning": true
                    },
                    "count": 3,
                    "score": 0.6,
                    "reference_comment": "The paper should provide a reasonable explanation for why the initial learning rate influences the testing accuracy, not just the convergence rate for training loss.",
                    "predicted_comment": "The methodology section is detailed and well-explained. However, the authors should consider providing more justification for their choice of parameters and methods. For example, why was the initial learning rate chosen as the single HP? Why was T set to 5 in the experiments?"
                },
                {
                    "reference_id": 1,
                    "predicted_id": 2,
                    "relative_specificity": "same",
                    "relatedness": "medium",
                    "pairwise_result": {
                        "relatedness": "medium",
                        "relative_specificity": "same",
                        "same_meaning": true
                    },
                    "count": 2,
                    "score": 0.4,
                    "reference_comment": "The algorithm introduces new hyperparameters, such as alpha and the 'rate of change plateaus'. The paper should explain how these hyperparameters are chosen and how they influence the result.",
                    "predicted_comment": "The methodology section is detailed and well-explained. However, the authors should consider providing more justification for their choice of parameters and methods. For example, why was the initial learning rate chosen as the single HP? Why was T set to 5 in the experiments?"
                }
            ]
        },
        "metrics": {
            "all": {
                "n_reference": 18,
                "n_generated": 13,
                "n_total_aligns": 2,
                "recall": 0.13333333333333333,
                "precision": 0.025641025641025644,
                "pseudo_jaccard": 0.030303030303030304,
                "specificity_more": 0.5,
                "specificity_less": 0.0,
                "specificity_same": 0.5
            }
        },
        "metrics_for_reviews": {
            "all": [
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 3
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 10
                },
                {
                    "recall": 0.4,
                    "precision": 0.07692307692307693,
                    "pseudo_jaccard": 0.09090909090909091,
                    "n_real": 5
                }
            ]
        }
    },
    {
        "doc_id": "rrWeE9ZDw_",
        "method": "gpt_bare_independent_chunk",
        "reference_comments": [
            [
                "The paper claims that the learned object-centric abstraction can be transferred to a new task with the same object type, but it does not define how 'same' is with respect to the same object type in the new task. For example, an apple on a table and an apple on a tree are semantically the same but have different preconditions for the 'pick' action. This suggests that the object-centric abstractions are still more task-specific, even for semantically identical objects.",
                "The paper suggests using Problem-Specific Instantiation to solve the problem of same-type objects having different preconditions in different scenarios. However, this process is similar to manually adjusting the planning domain to adapt to a different scenario, which does not solve the fundamental limitation of the human-defined planning domain.",
                "The learned symbolic predicates of specific object types are not general enough to be applied across different tasks. The proposed object-centric abstraction only groups similar conditions it observed, but does not abstract the preconditions of why an action could be performed. For example, if an apple is placed at different heights, the proposed method will lead to different apple object types as they have different preconditions. If the apple is placed even higher--a condition out of the previously seen cases, the proposed method cannot solve this problem as it does not abstract the 'reachable' concept for the picking action."
            ],
            [
                "The paper claims that the proposed method results in being able to obtain a successful agent for long-term planning with considerably fewer environment interactions, but does not provide a quantitative evaluation against a baseline to demonstrate this reduction in environment interactions.",
                "The paper's comparison with prior works like Kaiser et al. (2020) and Hafner et al. (2021) may not be fair, as the presented method assumes that environment observations are pre-factored and pre-processed into object components, which is a non-trivial task that might explain the sample inefficiency of earlier methods.",
                "The paper should either significantly reduce the prominence of the sample efficiency claims or provide a fair experimental comparison against a baseline that has access to the same factored, pre-processed observations and abstract options as the presented technique."
            ],
            [
                "The paper should clarify why a grouping based on effect distributions alone is preferred over one that also considers the pre-condition.",
                "The paper should provide more details on how it is determined what objects/operators require grounding.",
                "The paper should explain how the clustering proceeds for X, including how X is partitioned and how the result from clustering X is connected to clustering S.",
                "The paper should clarify how much domain knowledge is injected in the method for integrating task-specific information in the learned representations.",
                "The paper should provide more details on the steps needed to achieve the result in the Craft environment experiment, including how the need for having identities is identified, how it is determined which objects require ids, and how the id is connected to the object.",
                "The paper should discuss the limitations of the approach, including the assumptions made such as the frame assumption, that options only affect the object they act upon, and that the world comes pre-segmented according to objects.",
                "The paper should clarify how the grounding is achieved and what knowledge is assumed to arrive at the presented results."
            ]
        ],
        "generated_comments": {
            "all": [
                "The abstract and introduction provide a good overview of the paper's content and context, but they could be more explicit about the novelty of the proposed method and the paper's contributions. It would be beneficial to highlight the unique aspects of your approach compared to existing methods in the field and clearly outline the contributions in a separate section or paragraph.",
                "The methodology is explained in detail, but it might be too technical for readers not familiar with the field. Consider providing more intuitive explanations or examples to make it more accessible.",
                "In the section 'LEARNING OBJECT-CENTRIC REPRESENTATIONS', Step 3 is missing. Please provide the details for this step. Also, ensure that all figures are included and correctly referenced in the text.",
                "The paper uses a lot of domain-specific terminology, which might make it difficult for readers outside the field to understand. Consider providing brief explanations or definitions for these terms when they are first introduced.",
                "The paper lacks a conclusion section. It would be beneficial to summarize the main findings, discuss the implications of your work, and suggest directions for future research.",
                "Ensure that all references are correctly cited in the text. For example, the reference '(Konidaris et al., 2018)' is mentioned multiple times but it is not clear what specific work by these authors is being referred to.",
                "There is some repetition in the text, especially in the introduction section. Consider revising the text to avoid redundancy.",
                "The paper would greatly benefit from a section discussing the experimental results, comparing the proposed method with existing methods, and providing insights into the performance of the proposed method.",
                "In several instances, the paper would benefit from more detailed examples or explanations, such as the point about local information transfer between tasks, the introduction of terms \u03ba i and \u03bb i, and the complex crafting task.",
                "While the authors have done a good job of comparing their work with previous studies, a more detailed comparison, particularly in terms of performance metrics, would highlight the advantages of the proposed method.",
                "Discussing the limitations of the approach and potential future work would provide a more balanced view of the work and indicate areas for further research.",
                "Consider discussing the potential real-world applications of the research to highlight the significance of the work.",
                "The pseudocode provided is helpful for understanding the proposed method. However, it would be beneficial to provide more detailed comments explaining each step of the pseudocode.",
                "The authors have provided visualisations of some learned operators for the tasks. However, it would be beneficial to provide more detailed explanations of these visualisations, explaining what each part of the operator represents and how it contributes to the overall task.",
                "The paper could benefit from a more detailed discussion of the results, including statistical analysis where appropriate, and a more thorough interpretation of the findings."
            ]
        },
        "alignments": {
            "all": []
        },
        "metrics": {
            "all": {
                "n_reference": 13,
                "n_generated": 15,
                "n_total_aligns": 0,
                "recall": 0.0,
                "precision": 0.0,
                "pseudo_jaccard": 0.0,
                "specificity_more": NaN,
                "specificity_less": NaN,
                "specificity_same": NaN
            }
        },
        "metrics_for_reviews": {
            "all": [
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 3
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 3
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 7
                }
            ]
        }
    },
    {
        "doc_id": "EG5Pgd7-MY",
        "method": "gpt_bare_independent_chunk",
        "reference_comments": [
            [
                "The contributions of the paper are not clearly stated in the introduction section, making it difficult to identify the main contributions.",
                "The proposed framework, which connects membership inference attacks with binary hypothesis testing, lacks novelty as it has been previously proposed in other works.",
                "The paper heavily relies on the assumption introduced in equation (1) to characterize the outcome of the algorithm obtained via SGD training, but no valid proof or formal justification for this assumption is provided.",
                "The paper lacks numerical results and comparisons with competing methods for building attacks in the literature.",
                "The tradeoffs between Type I and Type II error are not always reported.",
                "There is a lack of diverse datasets and relevant architectures to validate the results."
            ],
            [
                "The paper does not clearly explain how having multiple specific forms of attacks can provide a comprehensive picture of whether an algorithm is private or not.",
                "The paper does not provide any justification as to why their set of attacks are 'complete'.",
                "The paper's plans are cryptic and each page has many ambiguous sentences with unclear goals.",
                "The paper does not clearly justify why they pick certain criteria and focus on them.",
                "The paper's definition of privacy is an 'average case, computational, indistinguishability-based' variation of DP, which is not standard DP.",
                "The first attack writes probabilities P(theta|D) as if we are aware of the learning algorithm, which is an assumption that needs to be clarified.",
                "The paper's assertion that 'The population data used for constructing the attack algorithm, and evaluating the inference game, need to be similar, in distribution, to the training data' needs proof.",
                "The paper's claim that 'By violating this principle, we might overestimate the privacy loss' is incorrect as the whole point of DP is that the adversary might have arbitrary auxiliary information.",
                "The paper's statement 'The adversary knows the underlying data distribution' is unclear.",
                "The paper's use of pi(z) in Equation (4) is questionable as z should be independent of theta and D in that case.",
                "The paper does not specify the learner in the experiments of the main body.",
                "The paper needs a much more detailed and justified approach, arguing for 'complete' attacks that at least 'capture known attack techniques so far'.",
                "The paper needs to be much clearer in its criteria that it proposes (in addition to the success rate of the attacks) to be part of the 'report' on privacy."
            ],
            [
                "Many of the attacks proposed could still be inefficient for auditing purposes as one might need to train 1000 reference models to perform the attacks. The numbers are also only high for models that are extremely overfitting. The paper should discuss how to audit models that are well-generalized.",
                "The comparison and difference between this work and prior work is vaguely discussed. There is no detailed comparison with [1], which also formalized MIA with an indistinguishability based framework. The hypothesis testing framework in this work is very similar to the threshold adversary in [1]. The authors should discuss the differences in detail. There is also no comparison to white-box models (e.g. [2]). The authors should discuss how this compares to the proposed framework.",
                "No connection is made between this work and differential privacy, although the indistinguishability setup is highly related. The authors should discuss how the framework translates to privacy loss in DP."
            ]
        ],
        "generated_comments": {
            "all": [
                "The abstract provides a good overview of the paper. However, it could be improved by providing a brief context or background about the problem being addressed. This would help readers understand the significance of the study.",
                "The introduction is comprehensive and sets the stage for the rest of the paper. However, it could benefit from a clearer statement of the paper's objectives and contributions. These are mentioned, but could be highlighted more effectively.",
                "The authors have done a good job explaining the attack framework. However, the use of technical jargon and complex sentences could make it difficult for readers not familiar with the topic. Simplifying the language and breaking down complex sentences could improve readability.",
                "This section is quite technical and could benefit from more explanations or examples to help readers understand the concepts better. The authors might consider adding diagrams or flowcharts to visually represent the process.",
                "The paper includes several equations, but some are not explained adequately in the text. Providing more context or explanation for each equation would help readers understand their significance and how they contribute to the overall study.",
                "The paper would benefit from a separate results and discussion section where the authors can present the outcomes of their empirical evaluations and discuss their implications. This would help readers understand the practical significance of the study.",
                "The authors should provide more detailed explanations of the mathematical equations and their implications. For instance, the authors could provide more context or explanation for the equations in paragraph 50, 61, 63, and 82.",
                "The authors mention that Attack D is designed to reproduce the results of the leave-one-out attack without assuming the knowledge of n \u2212 1 data records in D \\ {(x b , y b )}. It would be helpful if the authors could elaborate on how this is achieved in Attack D.",
                "The authors have provided a summary and comparison of different attacks, which is very helpful. However, it would be beneficial if the authors could provide a more detailed comparison of the attacks, perhaps in a table format, highlighting the key differences and similarities between the attacks.",
                "The authors mention that they expect Attack D to be the closest to the strongest attack, which is the leave-one-out attack. It would be interesting if the authors could provide empirical evidence or a more detailed explanation to support this claim.",
                "The authors mention that they use two metrics to quantify the attacker's performance: true positive rate (TPR), and false positive rate (FPR). It would be helpful if the authors could provide a brief explanation of these metrics for readers who may not be familiar with them.",
                "The authors mention that they plot the ROC curves of all attacks on the Purchase100 dataset, and compute their AUC (area under the ROC curve) score. It would be beneficial if the authors could provide these plots and scores in the main body of the paper, rather than in the appendix.",
                "The authors should consider discussing the potential limitations of their study and the proposed attacks. This would provide a more balanced view and also suggest areas for future research.",
                "The authors should also consider discussing the practical implications of their findings. How can these attacks be mitigated or prevented? What are the implications for privacy and data security?",
                "In paragraph 102, the authors pose several questions about the performance of different attacks. While these questions are interesting and relevant, it would be helpful if the authors could provide more direct answers to these questions in the subsequent sections. The current structure leaves the reader to infer the answers from the presented data and discussions.",
                "The authors should consider providing more context or explanation for the terms and concepts used in the paper. For instance, terms like 'Attack S', 'Attack P', 'Attack D', and 'Attack R' are used frequently but their meanings or the specific methods they refer to are not clearly explained.",
                "In paragraph 103, the authors present a table of results but do not provide a clear explanation or discussion of these results. It would be beneficial to include a paragraph discussing these results in detail, explaining what they mean and their implications for the study.",
                "In the 'Experiment setup' section, the authors provide a detailed description of the experimental setup. However, it would be beneficial to include a brief rationale or justification for the chosen setup. For instance, why were specific datasets chosen? Why were certain models used for certain attacks?",
                "The 'Related Works' section provides a comprehensive overview of the existing literature. However, it would be beneficial to include a brief discussion on how the current study builds upon or differs from these existing works.",
                "The explanation of the simulation of the DP adversary could be more explicit. It would be beneficial to provide a more detailed explanation of how this simulation works and why it is important for removing the effects of other points in the dataset.",
                "The authors mention 'type I and type II errors' without providing any context or explanation. It would be helpful to briefly define these terms for readers who may not be familiar with them.",
                "The authors should consider adding a brief summary of the main findings from the referenced works (Jagielski et al., 2020; Nasr et al., 2021; Malek et al., 2021). This would provide the reader with a better understanding of the context and significance of the current study.",
                "The authors have included links without any accompanying text or explanation. It would be helpful to provide a brief description of what each link is for and how it relates to the study. For example, are these links to datasets used in the study, to related works, or to tools used in the analysis? Providing this context would make it easier for readers to understand the relevance of these links.",
                "The authors should ensure that all links are correctly formatted and functional. The link in paragraph 146 appears to have a space in it, which could prevent it from working correctly.",
                "A conclusion summarizing the main findings, their implications, and potential future work would be a valuable addition to the paper.",
                "Ensure all references are correctly cited in the text and listed in the reference section.",
                "The authors mention an appendix with additional information. Make sure this is included in the final version of the paper and properly referenced in the text.",
                "Overall, the paper could benefit from a thorough proofreading to correct minor typographical errors and improve sentence structure."
            ]
        },
        "alignments": {
            "all": [
                {
                    "reference_id": 0,
                    "predicted_id": 1,
                    "relative_specificity": "more",
                    "relatedness": "high",
                    "pairwise_result": {
                        "relatedness": "high",
                        "relative_specificity": "more",
                        "same_meaning": true
                    },
                    "count": 4,
                    "score": 0.8,
                    "reference_comment": "The contributions of the paper are not clearly stated in the introduction section, making it difficult to identify the main contributions.",
                    "predicted_comment": "The introduction is comprehensive and sets the stage for the rest of the paper. However, it could benefit from a clearer statement of the paper's objectives and contributions. These are mentioned, but could be highlighted more effectively."
                },
                {
                    "reference_id": 3,
                    "predicted_id": 8,
                    "relative_specificity": "more",
                    "relatedness": "medium",
                    "pairwise_result": {
                        "relatedness": "medium",
                        "relative_specificity": "more",
                        "same_meaning": true
                    },
                    "count": 3,
                    "score": 0.6,
                    "reference_comment": "The paper lacks numerical results and comparisons with competing methods for building attacks in the literature.",
                    "predicted_comment": "The authors have provided a summary and comparison of different attacks, which is very helpful. However, it would be beneficial if the authors could provide a more detailed comparison of the attacks, perhaps in a table format, highlighting the key differences and similarities between the attacks."
                },
                {
                    "reference_id": 1,
                    "predicted_id": 18,
                    "relative_specificity": "more",
                    "relatedness": "medium",
                    "pairwise_result": {
                        "relatedness": "medium",
                        "relative_specificity": "more",
                        "same_meaning": true
                    },
                    "count": 2,
                    "score": 0.4,
                    "reference_comment": "The comparison and difference between this work and prior work is vaguely discussed. There is no detailed comparison with [1], which also formalized MIA with an indistinguishability based framework. The hypothesis testing framework in this work is very similar to the threshold adversary in [1]. The authors should discuss the differences in detail. There is also no comparison to white-box models (e.g. [2]). The authors should discuss how this compares to the proposed framework.",
                    "predicted_comment": "The 'Related Works' section provides a comprehensive overview of the existing literature. However, it would be beneficial to include a brief discussion on how the current study builds upon or differs from these existing works."
                }
            ]
        },
        "metrics": {
            "all": {
                "n_reference": 22,
                "n_generated": 28,
                "n_total_aligns": 3,
                "recall": 0.2222222222222222,
                "precision": 0.03571428571428571,
                "pseudo_jaccard": 0.03194444444444444,
                "specificity_more": 1.0,
                "specificity_less": 0.0,
                "specificity_same": 0.0
            }
        },
        "metrics_for_reviews": {
            "all": [
                {
                    "recall": 0.3333333333333333,
                    "precision": 0.07142857142857142,
                    "pseudo_jaccard": 0.0625,
                    "n_real": 6
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 13
                },
                {
                    "recall": 0.3333333333333333,
                    "precision": 0.03571428571428571,
                    "pseudo_jaccard": 0.03333333333333333,
                    "n_real": 3
                }
            ]
        }
    },
    {
        "doc_id": "DILxQP08O3B",
        "method": "gpt_bare_independent_chunk",
        "reference_comments": [
            [
                "The paper doesn't fully address why DETR performs better than FasterRCNN features. It's not clear why DETR is doing better than Faster-RCNN especially when the detection accuracy of DETR is also better than Faster RCNN.",
                "The method for obtaining the appearance features from Faster RCNN based method is not clear. It's not explained how it's different from the approach taken by Bottom-Up, Top-Down paper in which 2048-dim appearance features are extracted for each visual region.",
                "The experimental setup isn't fully reflective of the object goal navigation task. The experiments are conducted in AI2 thor scenes which only contain one room. It's not clear how this method will perform when evaluated on significantly more complicated environments like Matterport / Gibson.",
                "The navigation task is simplified by discretizing into a grid. Single room environments and discrete grids simplify a lot of navigation-related challenges and the authors don't discuss how the proposed architecture will generalize to more complex object navigation tasks.",
                "The use of spatial embeddings as well as appearance embedding isn't all that surprising. Existing work including Du et al. uses bounding box coordinates to help learn spatial associations between objects.",
                "It's not clear how the agent learns long-term associations between objects across multiple frames. The proposed architecture puts all the burden of learning these long-term object relationships across multiple frames on the LSTM policy since the VT only learns association within a single frame."
            ],
            [
                "The paper adopts the Transformer and adapts it for the navigation problem, but does not propose a new architecture or model.",
                "A similar usage of the Transformer has already been demonstrated in the vision-and-language navigation task. The referenced paper also shows that pre-training of navigation tasks using Transformers can help to boost performance."
            ],
            [
                "The writing in the approach section isn't very clear. It would be better to define clear notations for all the features/descriptors and use such notations in the figure. The current writing uses various terms like 'instance feature', 'global feature', 'positional-global', 'spatial feature', 'spatial-enhanced', which are confusing.",
                "The details in Fig.2 are not sufficient and it is not as informative as the detailed version (Fig.4) in Appendix. These two figures are not consistent, for example, the 'add' symbol for positional enhancement is missing in Fig.4.",
                "In Sec.4.2, it is not clear how the reduction of the channel dimension of a high-level activation map from D to a smaller dimension d is done.",
                "The terms $h$, 'w', and $L$ are used inconsistently in the paper, causing confusion.",
                "The statement in Sec.4.1 about Faster RCNN being blamed for scale-sensitive is not fully convincing. It is unclear what scale-sensitive means here and why DETR doesn't suffer from it.",
                "The statement about 'early stopping' in Sec.4.4 is not fully convincing. It is unclear why the transformer-based representation learner suffers from 'early stopping'.",
                "The SPL formulation in Sec.5.1 seems to be incorrect. The success indicator seems to be missing.",
                "It is unclear why global features are not also added into the transformer encoder."
            ],
            [
                "The introduction of the paper is difficult to understand as it discusses details such as the difference between DETR and Faster RCNN or difficulty of training the transformers without providing a high-level overview of the proposed method.",
                "The paper does not provide a satisfactory explanation for why nothing is learned without the imitation pre-training.",
                "The paper should run the method on other frameworks which include slightly larger scenes, such as RoboTHOR, to test if the method generalizes to those as well."
            ]
        ],
        "generated_comments": {
            "all": [
                "The abstract provides a good overview of the paper. However, it would be beneficial to include some quantitative results to give the reader an immediate understanding of the effectiveness of the proposed method.",
                "The introduction is well-written and provides a clear problem statement. However, it would be helpful to provide more context on why the current state-of-the-art methods are insufficient and how VTNet addresses these limitations.",
                "The methodology is explained in detail, which is commendable. However, the authors could consider providing more intuitive explanations or visual aids to help the reader understand the complex concepts, especially the workings of the Visual Transformer and the spatial-enhanced local descriptor.",
                "The related works section could be expanded to include a broader range of existing methods in visual navigation. This would help to position the proposed method in the context of the existing literature.",
                "The experimental setup and the dataset used are well-described. However, the paper would benefit from a more detailed discussion of the results, including a comparison with other methods and an analysis of the strengths and weaknesses of the proposed method.",
                "The authors mention that training a deep VT is difficult, especially when the supervision signals are provided by a weak reward from reinforcement learning. It would be beneficial to elaborate more on this issue and explain why this is the case.",
                "The mathematical formulas in paragraph 32 and 33 are not clearly presented. It would be beneficial to provide a more detailed explanation of the variables and the equations used to compute the success rate and the Success Weighted by Path Length (SPL).",
                "In paragraph 35, the authors mention a two-stage training strategy. However, it would be helpful to provide more details about the training process, such as the specific parameters used in the Adam optimizer and the rationale behind the chosen learning rates.",
                "In paragraph 36, the authors compare their method with several others. It would be beneficial to provide a brief overview of the strengths and weaknesses of these methods to give the reader a better understanding of the context in which VTNet is being evaluated.",
                "The authors have done a good job in presenting the results and comparing them with other methods. However, it would be helpful to provide more statistical analysis to support the claims made. For instance, are the improvements statistically significant?",
                "The ablation study in paragraphs 41-44 is well-conducted and provides valuable insights into the importance of each component in VTNet. However, it would be beneficial to provide more details about the specific changes made in each variant and how these changes affected the performance.",
                "In the last paragraph, the authors discuss the performance of different transformer architectures. It would be beneficial to provide more details about these architectures and why certain configurations performed better than others.",
                "A conclusion section summarizing the main findings and contributions of the paper, as well as potential future work, would be a valuable addition. In the conclusion, the authors mention a few failure cases of VTNet. It would be interesting to discuss potential solutions or future work to address these issues.",
                "Ensure that all references are correctly cited and formatted. For instance, the citation 'Vaswani et al., 2017' is mentioned in the text, but the full reference is not provided.",
                "The paper refers to figures and tables (e.g., Figure 1, Figure 2), but these are not included in the provided text. Ensure that all figures and tables are correctly referenced and clearly illustrate the points you wish to convey.",
                "The authors mention that their codes and pre-trained model will be publicly released. It would be helpful to provide a link or a reference to where these resources can be found for reproducibility purposes.",
                "The language is generally clear and precise. However, there are a few instances where the wording could be improved for clarity. For example, in the sentence 'Given such visual representations, agents are able to explore the correlations between visual observations and navigation actions,' it would be clearer to say 'Given these visual representations, agents can explore the correlations between visual observations and navigation actions.'"
            ]
        },
        "alignments": {
            "all": [
                {
                    "reference_id": 0,
                    "predicted_id": 2,
                    "relative_specificity": "same",
                    "relatedness": "medium",
                    "pairwise_result": {
                        "relatedness": "medium",
                        "relative_specificity": "same",
                        "same_meaning": true
                    },
                    "count": 3,
                    "score": 0.6,
                    "reference_comment": "The writing in the approach section isn't very clear. It would be better to define clear notations for all the features/descriptors and use such notations in the figure. The current writing uses various terms like 'instance feature', 'global feature', 'positional-global', 'spatial feature', 'spatial-enhanced', which are confusing.",
                    "predicted_comment": "The methodology is explained in detail, which is commendable. However, the authors could consider providing more intuitive explanations or visual aids to help the reader understand the complex concepts, especially the workings of the Visual Transformer and the spatial-enhanced local descriptor."
                }
            ]
        },
        "metrics": {
            "all": {
                "n_reference": 19,
                "n_generated": 17,
                "n_total_aligns": 1,
                "recall": 0.03125,
                "precision": 0.014705882352941176,
                "pseudo_jaccard": 0.010416666666666666,
                "specificity_more": 0.0,
                "specificity_less": 0.0,
                "specificity_same": 1.0
            }
        },
        "metrics_for_reviews": {
            "all": [
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 6
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 2
                },
                {
                    "recall": 0.125,
                    "precision": 0.058823529411764705,
                    "pseudo_jaccard": 0.041666666666666664,
                    "n_real": 8
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 3
                }
            ]
        }
    },
    {
        "doc_id": "fmOOI2a3tQP",
        "method": "gpt_bare_independent_chunk",
        "reference_comments": [
            [
                "The paper does not clearly demonstrate if any insight is gained from the theoretical analysis, as the derivation of value and sample complexity bounds for approximate bisimulation was already performed in Gelada et al. 2019.",
                "The empirical gains are modest and it's unclear if they are due to the image representation learning component of the loss or other aspects of the method.",
                "The paper uses a very small number of training tasks - only 4. It's unclear if using more training tasks would improve the generalization of single-task methods like DeepMDP.",
                "There seems to be a missing baseline - a generic multi-task algorithm that conditions on the environment ID but does use the bisimulation loss to help process the image observations.",
                "It's unclear why there's a gap between your method in the multi-task experiments but not in the meta-RL ones.",
                "It's not explained why HiP-BMDP handles the sticky observation setting better than the baselines.",
                "The paper does not convincingly demonstrate that the structural assumptions on the MDP used by the proposed algorithm yield performance improvement."
            ],
            []
        ],
        "generated_comments": {
            "all": [
                "Abstract: Include a brief mention of the results or findings to give the reader a complete summary of the work.",
                "Introduction: Provide a clearer statement of the problem being addressed.",
                "Background: Provide a brief summary or overview at the beginning of this section to help guide the reader.",
                "The Model: Provide a brief explanation or interpretation of each equation.",
                "Learning HiP-BMDPs: Provide more details on how the components interact during training.",
                "Theoretical Analysis: Provide more context or explanation for the theorems.",
                "Results: Include a results section that discusses the performance of the proposed method, ideally with comparisons to existing methods.",
                "Figures and Tables: Ensure these are included in the paper as they would greatly aid in understanding the proposed method and its performance.",
                "References: Ensure that all references are correctly formatted and consistent.",
                "Conclusion: Include a conclusion section summarizing the main findings, implications, and future work.",
                "Throughout the paper, there are several instances where equations and theorems are referred to but not included in the provided text. Please ensure that all referenced equations and theorems are included in the final manuscript.",
                "The paper could benefit from a more detailed discussion of the results, including the implications of the findings and how they contribute to the existing body of knowledge.",
                "Expand the discussion section to include a more detailed analysis of the study's limitations and potential areas for future research.",
                "Consider including sections on the practical, ethical, policy, commercial, environmental, health, educational, social, cultural, legal, technological, economic, political, historical, philosophical, psychological, sociological, anthropological, geographical, architectural, artistic, literary, musical, theatrical, cinematic, culinary, fashion, sports, religious, spiritual, military, humanitarian, philanthropic, journalistic, broadcasting, publishing, advertising, marketing, public relations, customer service, human resources, operations management, project management implications of the research. This would help to demonstrate the potential impact of the findings on various practices.",
                "In the additional implementation details, baselines, MTRL algorithm, additional results, multi-task setting, Meta-RL setting, evaluating the universal transition model sections, and annex, provide more context, explanation, and details about the equations, algorithms, methods, environments, models, assumptions, limitations, and hyperparameters used."
            ]
        },
        "alignments": {
            "all": []
        },
        "metrics": {
            "all": {
                "n_reference": 7,
                "n_generated": 15,
                "n_total_aligns": 0,
                "recall": 0.0,
                "precision": 0.0,
                "pseudo_jaccard": 0.0,
                "specificity_more": NaN,
                "specificity_less": NaN,
                "specificity_same": NaN
            }
        },
        "metrics_for_reviews": {
            "all": [
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 7
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 0
                }
            ]
        }
    },
    {
        "doc_id": "hbzCPZEIUU",
        "method": "gpt_bare_independent_chunk",
        "reference_comments": [
            [
                "The comparison in the experiment section is weak without any reference to existing prior arts such as Chen et al., Fine-grained representation learning and recognition by exploiting hierarchical semantic embedding, ACM-MM 2018.",
                "There is a significant performance gap between the proposed method and the latest methods when considering the 5 experiment datasets.",
                "The baseline performance in the experiments shows considerable gaps to standard baseline training without bells and whistles, raising questions about its solidity.",
                "The performance gain of the proposed method diminishes very quickly on bigger datasets such as Tiny ImageNet, and the results on ImageNet are not provided.",
                "The proposed method depends on a pre-defined semantic hierarchical graph rather than a learned one, which potentially limits the technical value of this work.",
                "There is concern about the selection of initial radius $R_0$ and its decay policy, as these parameters should be dataset dependent due to different numbers of categories and the densities of class distributions.",
                "Forcing a fixed radius does not seem as reasonable as allowing a learnable radius with soft regularization."
            ],
            [
                "The empirical evaluation is relatively weak and the evaluation metric does not well reflect the advantages of hierarchically modelling the label space. It would be more informative to incorporate the classification accuracy of the super-classes.",
                "More experiments that analyze the difference in feature distributions between normally trained neural networks and the hierarchically trained neural networks are needed. An intuitive visualization of the feature space would be of great interest.",
                "Important ablation studies to justify some heuristic designs are necessary. For example, the effect of the hyperparameter in the radius decay on performance is crucial. Evaluations should be conducted on what happens if no sphericity constraint is applied, or if no radius decay is used.",
                "The empirical evaluation does not convincingly demonstrate the usefulness of modeling the hierarchical label space, especially in experiments on CIFAR-100 and Tiny-ImageNet. More discussions and insights on this issue would be useful.",
                "The usefulness of the hierarchical label structure should be evaluated and verified. A simple way to evaluate it is to use some random assignment or simple K-means assignments for the super-classes. If using the ground truth hierarchical structure consistently outperforms the random or K-means super-class assignment, then it can be argued that incorporating the ground truth hierarchical label structure is indeed useful."
            ],
            [
                "Section 2 needs more specific definitions for terms such as 'classifier' and 'separators'. For example, in equation (2), Wp and Wpi are called classifiers. Are these hyperplanes?",
                "In Definition 1, it would be helpful to provide early examples of P and L to make it easier to interpret the matrix H.",
                "The notation for Delta in equation (8) could be confusing as it may remind an operator on H in equation (9). Consider using a different notation.",
                "In equation (9), it is unclear whether deltas in the same subtree are required or observed to be in roughly the same direction.",
                "In Section 3, the claim that no hyperparameters are added seems incorrect. Initial radius R0, radius decay parameter, and the organization of classes could all be considered additional hyperparameters.",
                "In practice, defining mutually exclusive class partitions to form the required class tree in Figure 1 can be non-trivial or even impossible. The authors should discuss how different class hierarchies affect the classification accuracy, for example, in Table 2."
            ],
            [
                "The third paragraph of Section 1 is unclear about why Euclidean distance is not sufficient for learning with hierarchical regularization.",
                "The paper does not clearly explain whether the whole model follows end-to-end training or stage-wise training.",
                "In Section 2.2, the definition of 'separator' is unclear and the sentence about classifiers identifying dog breeds being similar is confusing.",
                "The paper does not provide a clear rationale or related work for the use of radius decay in Section 3.1.",
                "The optimization method used for learning other layers is not specified.",
                "The paper does not provide a clear explanation or justification for the construction of the spherical fully-connected layer.",
                "The paper does not present the hierarchical structure in a visually appealing or clear way.",
                "The paper does not clearly explain whether images from datasets Dogs and Tiny-Imagenet are part of ImageNet or if the classes in the two datasets are included in the set of ImageNet classes.",
                "The definition of 'plain networks' in Section 4.1 is unclear.",
                "The paper does not justify its claim of 'high efficiency' in Section 4.2.1.",
                "The paper does not formally compare Riemannian gradient and 'projected gradient' in Figure 2 right.",
                "The paper does not discuss how the proposed method may work if classes do not follow a tree hierarchy.",
                "The explanation of why 'Euclidean distance is not sufficient for learning such a hierarchical regularization' in the rebuttal is not intuitive or concrete.",
                "The paper does not clearly explain whether other methods suffer severely from the choice of learning rate and scheduler.",
                "The blue line in Page-2 is confusing and the logic of why diversity reduces over-fitting is unclear.",
                "The tSNE visuals in Figure 5 are not adequately analyzed."
            ]
        ],
        "generated_comments": {
            "all": [
                "Abstract: Include a brief mention of the key results or findings from the experiments conducted.",
                "Introduction: Provide a clearer statement of the problem being addressed.",
                "Provide more explanation or examples to clarify the following concepts: 'similarity preserving embdding', 'uniformly distributed classes', 'constraining the angle by independently regularizing the norm of each node embedding', 'manifold embedding', 'hyperbolic network', 'path taken in the tree', 'paths associated to nodes whose label appears in the dataset', 'similar representations for classes along a path p', 'hierarchical regularization', 'output of CNNs for classification', 'Hierarchical layer', and 'hierarchical ( 2 ) regularization'.",
                "Figures and Equations: Ensure that all figures and equations are correctly referenced and clearly explained in the text.",
                "Results and Discussion: Include a section discussing the results of the experiments conducted, the implications of these results, and how they contribute to the field.",
                "Conclusion: Include a conclusion summarizing the main findings, their implications, and potential future work.",
                "References: Ensure all references are correctly cited in the text and listed in the reference section.",
                "Language: Improve the wording in a few instances for clarity.",
                "Technical Details: Explain some concepts in more detail or with examples to make them more accessible to readers who are not experts in the field.",
                "Provide a more detailed explanation of the 'rewinding' equation 2 and why equation 2 does not necessarily capture a certain property.",
                "Provide a brief overview of the equations mentioned in the text.",
                "Explain why their approach does not add hyperparameters.",
                "Provide a more detailed comparison of the methods to optimize the network, discussing the advantages and disadvantages of each.",
                "Provide a more detailed explanation of Riemannian gradient descent and why it is beneficial for their study.",
                "Provide more detailed statistical analysis of the results, including measures of statistical significance, confidence intervals, or other relevant metrics.",
                "Discuss the limitations of the study and potential ways to address these in future work.",
                "Provide a brief introduction or transition sentence to guide the reader from the mathematical explanation to the description of the ResNet and DenseNet architectures.",
                "Provide the hyperparameters for ResNet for consistency and to allow for reproducibility.",
                "Explain why SGD was chosen over other optimization methods for optimization.",
                "Provide a brief description of the content of Table 3 mentioned in the 'C.2 Dataset' section.",
                "Explain why a hierarchy tree was used in the 'C.3 Hierarchy for Datasets' section and how it benefits the study.",
                "Explain why the Wordnet hierarchy is not a tree and how it affects the study in the 'C.3.5 (TINY) IMAGENET' section.",
                "Explain how the radius decay may influence the accuracy of the network in the 'C.4 Generalization Performance Along Different Radius Decay Values' section."
            ]
        },
        "alignments": {
            "all": []
        },
        "metrics": {
            "all": {
                "n_reference": 34,
                "n_generated": 23,
                "n_total_aligns": 0,
                "recall": 0.0,
                "precision": 0.0,
                "pseudo_jaccard": 0.0,
                "specificity_more": NaN,
                "specificity_less": NaN,
                "specificity_same": NaN
            }
        },
        "metrics_for_reviews": {
            "all": [
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 7
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 5
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 6
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 16
                }
            ]
        }
    },
    {
        "doc_id": "ab7lBP7Fb60",
        "method": "gpt_bare_independent_chunk",
        "reference_comments": [
            [
                "The proposed method is not compatible with federated averaging, which is a significant limitation in federated learning due to the communication bottleneck characteristic of federated settings.",
                "The paper does not compare the proposed method to prior work on group fairness in the centralized setting, such as the work by Zafar et al., (2017). An in-depth experimental evaluation of this aspect is needed to motivate the proposed approach.",
                "The proposed method may be susceptible to a potential privacy violation, as the statistics shared at every round include the number of individuals per protected attribute for every client. This could be exploited to learn an unfair model with respect to certain sensitive attributes.",
                "The paper incorrectly characterizes prior fair federated learning approaches, such as the work by Li et al. (2019), as individual fairness methods. These methods enforce uniform performance across all devices, which is neither individual nor group fairness, but a novel notion tailored to the federated learning setting."
            ],
            [
                "The paper is missing important literature review, including methods that enforce group fairness in Federated Learning such as 'Fair and Consistent Federated Learning' by Cui et al. 2021. These could have been considered as a baseline for comparing their method.",
                "The paper does not include enough baselines for Fair Federated Learning to compare against. Even if some methods do not satisfy privacy considerations, they should still be included for the reader to understand how the proposed method compares against such methods, especially given that the results are not promising. Some baselines to consider include Cui et al or Tran et al.",
                "The authors need to justify some of the incompatibility results shown in previous work between fairness and privacy.",
                "Algorithm 1 needs improvement. It is unclear what the clients do, what 'UpdateMultiplier', 'UpdateParameters', and 'Calculate noiseScale' mean.",
                "The results are not promising for predictive parity among groups. There is also a reduction in accuracy. The authors should discuss why this is the case. Including the suggested baselines could provide a sense of what other methods achieve in terms of loss in accuracy, etc.",
                "The results for the central setting should be included in Table 2."
            ]
        ],
        "generated_comments": {
            "all": [
                "The abstract provides a good overview of the paper. However, it would be beneficial to include a brief mention of the key results or findings from the experiments. This would give readers an immediate understanding of the paper's contributions.",
                "The introduction is well-written and provides a clear problem statement. However, the authors could consider providing a brief overview of the proposed solution (FPFL) in the introduction itself. This would help readers understand the context and the novelty of the proposed solution.",
                "The authors have done a good job explaining the concept of federated learning. However, the mathematical notation used in paragraph id: 9 could be clarified. It is not immediately clear what the function L(d_k, w) represents.",
                "The authors have explained the concept of differential privacy well. However, the explanation of the Gaussian mechanism in paragraph id: 15 could be expanded. It would be helpful to explain why Gaussian noise is used and how the variance of the noise is determined.",
                "The authors have provided a detailed explanation of the MMDM algorithm. However, the explanation of the algorithm's convergence properties in paragraph id: 25 could be simplified or explained in more layman terms for readers who are not familiar with the concept.",
                "The authors have done a good job explaining the concept of group fairness. However, the mathematical notation used in paragraph id: 28 could be clarified. It is not immediately clear what the function f represents.",
                "The paper could benefit from a discussion section where the authors discuss the implications of their findings, potential applications of their algorithm, and future research directions.",
                "The authors should consider discussing the limitations of their study. This could include limitations in the datasets used, assumptions made in the algorithm, or potential issues with scalability or computational efficiency.",
                "The authors should consider including a comparison of their proposed method with existing methods in the experimental results section. This would help to highlight the advantages and improvements of their proposed method.",
                "The authors should consider providing more details about the datasets used in the experiments. This includes the number of samples, the number of features, and the distribution of the target variable. This information would help readers to understand the complexity of the problem and the robustness of the proposed solution.",
                "The authors should provide a brief explanation or definition of the variables and terms used in the paper, especially for readers who may not be familiar with this specific context.",
                "The authors should consider presenting the results in a more consistent manner for easier comparison.",
                "The authors refer to equations without actually providing them. This makes it difficult for the reader to follow the discussion. Please include these equations for completeness.",
                "In the experimental details section, the authors should provide more information about how the experiments were conducted, such as the specific algorithms used, the number of iterations, and the evaluation metrics.",
                "In the sections where the authors describe the process of image modification, it would be helpful to include a visual example of the original and modified images. This would provide a clearer understanding of the modifications made.",
                "It would be beneficial to include more detailed statistical analysis of the results, including any statistical tests used, the significance of the results, and how these results compare to previous research in the field."
            ]
        },
        "alignments": {
            "all": []
        },
        "metrics": {
            "all": {
                "n_reference": 10,
                "n_generated": 16,
                "n_total_aligns": 0,
                "recall": 0.0,
                "precision": 0.0,
                "pseudo_jaccard": 0.0,
                "specificity_more": NaN,
                "specificity_less": NaN,
                "specificity_same": NaN
            }
        },
        "metrics_for_reviews": {
            "all": [
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 4
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 6
                }
            ]
        }
    },
    {
        "doc_id": "rsf1z-JSj87",
        "method": "gpt_bare_independent_chunk",
        "reference_comments": [
            [
                "The performance of the proposed model is promising, but still below the baselines.",
                "The claim of the model being end-to-end is misleading as the character-based model is not performing well, and the phoneme-based model is not truly end-to-end, as the grapheme-to-phoneme (g2p) part is not trained jointly.",
                "The reason behind using an adversarial loss is not adequately explained in the paper. A few lines before section 2.1 would help clarify that.",
                "It's not clear which dataset was used in the experiment. If it is a private dataset, please state it clearly."
            ],
            [
                "The paper does not provide a comparison over the computational cost or model size. This is particularly important because the proposed model is non-autoregressive and may be capable of real-time inference.",
                "The paper does not use widely accepted benchmark datasets. A more direct comparison would be beneficial.",
                "The proposed aligner module doesn't seem to be very useful compared with the attention-based aligner as seen in the ablation study (Table 1): there is only a very small improvement from 3.551 to 3.559 MOS. More explanation is needed."
            ],
            [
                "The elegance in the architecture is overshadowed by the complicated training algorithm, making the method look a bit heuristic and harder to reproduce.",
                "The authors should provide brief guidelines for readers trying to reimplement EATS, such as how to tune the hyperparameters.",
                "EATS performs slightly worse than GAN-TTS, which does not quite show the benefit of end-to-end training. It would be worthwhile to expand the discussion a bit by showing further experiments that demonstrate the potential benefit of end-to-end training.",
                "Without a clearly interpretable hidden representation, it is harder to have direct control over prosody. The authors should discuss how prosody control would be possible under the end-to-end framework."
            ],
            [
                "The paper lacks a comparison with Tacotron 2 in Table 1. This would be informative as all the baselines are trained on aligned data while Tacotron is a legitimate contender for EATS as it can be trained on the same data.",
                "The authors claim that their method is simpler because the training is in one stage. However, given the large number of losses and components in their model, with their respective hyper-parameters to tune, the simplicity argument is not entirely convincing.",
                "The performance of the transformer attention is surprisingly poor, particularly in the audio samples where the output for this model is garbage towards the end of the signal. The authors should provide an explanation for this."
            ]
        ],
        "generated_comments": {
            "all": [
                "The abstract could provide more context about why this work is important and how it advances the field. Mentioning the main challenges faced and how they were addressed would also be beneficial.",
                "More context about the state of the art in this field and how the proposed method compares to other end-to-end TTS systems would be helpful in the introduction.",
                "More explanation about the choice of certain parameters and techniques, such as the choice of a feed-forward convolutional network and a Gaussian kernel in the aligner, is needed in the method section.",
                "More details about the evaluation, including the number of evaluators, the nature of the test set, and any particular strengths or weaknesses noted in the synthesized speech, would be beneficial in the results section.",
                "Ensure that all figures and equations are clearly presented and adequately explained in the text.",
                "A more detailed discussion section discussing the implications of the findings, potential applications of the model, directions for future research, and any limitations of the study would be beneficial.",
                "Ensure that all references are correctly formatted and all cited works are included in the reference list.",
                "Ensure that all appendices are included and that they provide useful, supplementary information to the main text.",
                "Provide more empirical evidence or a detailed explanation to support the claim about the trade-off between a higher \u03c4 and the accuracy of the resulting loss in the Dynamic Time Warping section.",
                "A comparison or discussion on the performance difference between character input and phoneme input would be interesting in the Text Pre-Processing section.",
                "A more structured comparison between the proposed method and existing methods, possibly in the form of a table, would be beneficial in the Related Work section.",
                "Including other metrics in addition to the Mean Opinion Score (MOS) would provide a more comprehensive evaluation of the model's performance in the Evaluation section.",
                "Discuss any potential biases in the dataset and how they might affect the results in the Multi-Speaker Dataset section.",
                "Discuss the rationale behind the choice of these specific hyperparameters in the Hyperparameters and Other Details section.",
                "Include a comparison with other models or methods to provide context for these results in the Inference Speed section.",
                "Include a brief description of the pseudocode in the text to aid readers who may not have immediate access to the figure in the Pseudocode section.",
                "Clarify the rationale behind the choice of architecture and its advantages over other possible architectures in the Spectrogram Discriminator Architecture section.",
                "Provide a brief explanation of why the complexity of the implementation is quadratic and how it impacts the performance of the model in the Dynamic Time Warping Pseudocode section.",
                "A comparison of the performance of this model with the proposed model would provide valuable context in the Transformer-Based Attention Aligner Baseline section.",
                "Provide a brief explanation of why this variation occurs and how it impacts the performance of the model in the Variation in Alignment section.",
                "Discuss these results and their implications in the MultiSpeaker Results section.",
                "Discuss the advantages and disadvantages of each approach in the Comparison of TTS Methods section.",
                "Provide a brief explanation of why this step is necessary and how it improves the performance of the model in the Mel-Spectrogram Computation section.",
                "Discuss potential solutions or future directions for improving these metrics in the Limitations of Current Evaluation Metrics section.",
                "Provide a brief explanation of what each section of code is doing and why it is necessary for the model.",
                "Ensure all sections are labeled with a title or section number to improve readability.",
                "Provide a brief explanation of what each section of mathematical notation is doing and why it is necessary for the model."
            ]
        },
        "alignments": {
            "all": [
                {
                    "reference_id": 0,
                    "predicted_id": 14,
                    "relative_specificity": "same",
                    "relatedness": "medium",
                    "pairwise_result": {
                        "relatedness": "medium",
                        "relative_specificity": "same",
                        "same_meaning": true
                    },
                    "count": 4,
                    "score": 0.8,
                    "reference_comment": "The paper does not provide a comparison over the computational cost or model size. This is particularly important because the proposed model is non-autoregressive and may be capable of real-time inference.",
                    "predicted_comment": "Include a comparison with other models or methods to provide context for these results in the Inference Speed section."
                },
                {
                    "reference_id": 2,
                    "predicted_id": 19,
                    "relative_specificity": "more",
                    "relatedness": "medium",
                    "pairwise_result": {
                        "relatedness": "medium",
                        "relative_specificity": "more",
                        "same_meaning": true
                    },
                    "count": 3,
                    "score": 0.6,
                    "reference_comment": "The performance of the transformer attention is surprisingly poor, particularly in the audio samples where the output for this model is garbage towards the end of the signal. The authors should provide an explanation for this.",
                    "predicted_comment": "Provide a brief explanation of why this variation occurs and how it impacts the performance of the model in the Variation in Alignment section."
                }
            ]
        },
        "metrics": {
            "all": {
                "n_reference": 14,
                "n_generated": 27,
                "n_total_aligns": 2,
                "recall": 0.16666666666666666,
                "precision": 0.018518518518518517,
                "pseudo_jaccard": 0.017241379310344827,
                "specificity_more": 0.5,
                "specificity_less": 0.0,
                "specificity_same": 0.5
            }
        },
        "metrics_for_reviews": {
            "all": [
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 4
                },
                {
                    "recall": 0.3333333333333333,
                    "precision": 0.037037037037037035,
                    "pseudo_jaccard": 0.034482758620689655,
                    "n_real": 3
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 4
                },
                {
                    "recall": 0.3333333333333333,
                    "precision": 0.037037037037037035,
                    "pseudo_jaccard": 0.034482758620689655,
                    "n_real": 3
                }
            ]
        }
    }
]