[
    {
        "doc_id": "B1x8anVFPr",
        "method": "gpt_independent_chunk",
        "reference_comments": [
            [
                "The authors should have performed multiple runs of their experiments and shown the standard deviations across runs to make their results more convincing.",
                "The authors claim that using Pre-LN rather than Post-LN transformers leads to faster convergence, but the models converge to the same result. This work is incremental as Wang et al. have already shown the benefits of Pre-LN rather than Post-LN transformers for machine translation.",
                "The paper is very long for an incremental improvement.",
                "It would be good to see repeats for Figure 2 and the standard deviations for Figure 3.",
                "Without reading the appendix it is not clear where the assumption that W^Q and W^K are zero is used. Making some connection with how this assumption relates to the lemmas would be useful.",
                "In Lemma two, the authors are comparing the magnitudes for the input in the Pre-LN and the output in the Post-LN transformer according to how x_{l,i}^post and x_{l, i}^pre are defined in Table 1.",
                "In Figure 3(b) the gradients are clearly decreasing with the number of layers, are there any comments on this? In the limit this could cause vanishing gradients?",
                "Figure 2 and 4 appear to contradict. Is the difference a result of using RAdam? If so, this should be made very clear. If not, why are the results contradictory?"
            ],
            [
                "The novelty of the paper is limited as Pre-LN placement has been used in prior work.",
                "There are concerns about the relation between the analytic investigation of the gradient norms and the empirical results that are presented.",
                "The theoretical results do not clearly demonstrate that there is a problem with Post-LN and that this problem is fixed by switching to Pre-LN.",
                "The paper does not clearly explain the relationship between the theoretical results and the empirical study.",
                "The paper does not adequately explain the scaling of the gradient changes throughout the layers, which is examined in appendix section F.",
                "The connection between the expression that scales in the upper bound and the actual gradient norm is tenuous and there are multiple places where the argument could break down.",
                "The paper does not verify the sqrt(2/3) scaling on the data from the empirical study that is shown.",
                "The paper does not explain where the expectation near the bottom of page 20, which is approximately 2/3, comes from."
            ]
        ],
        "generated_comments": {
            "all": [
                "To enhance the accessibility of your paper, consider providing succinct explanations of the terms 'Post-LN Transformer', 'Pre-LN Transformer', and 'BERT models' in the abstract and introduction. This will ensure that readers from various backgrounds can grasp the context and significance of your work.",
                "The section discussing the learning rate warm-up stage in the optimization of the Post-LN Transformer could be expanded. Please provide more details on how it affects the model's performance and why it is a significant issue. This will help readers understand the motivation behind your research and the problem you are addressing.",
                "The paper would benefit from a more detailed, step-by-step explanation of your modification to the Transformer architecture. Please also elaborate on why it eliminates the need for a learning rate warm-up stage. This will help readers understand the technical aspects of your work and the novelty of your approach.",
                "More details about your experimental setup would be beneficial. Please include information such as how parameters were chosen, how fairness of comparisons was ensured, how the performance of the models was measured, the size of the datasets, the distribution of classes, any preprocessing steps taken, and the choice of experimental settings in the machine translation experiments. This will ensure that your experiments are reproducible and that readers can evaluate the robustness of your results.",
                "Including figures or tables to visualize the results such as BLEU scores and validation loss curves would greatly enhance the presentation of the results. Also, please include information about how the results might vary with different hardware configurations. This will help readers understand the impact of your work and its practical implications.",
                "Please expand on the discussion of your results, explaining why your modified Transformer architecture performed better than the original one, and discuss any limitations or potential drawbacks of your approach. Elaborate more on the implications of your findings, such as how the faster training of the Pre-LN model impacts the broader field of machine learning and translation tasks. This will help readers understand the significance of your results and their potential impact on the field.",
                "In the conclusion, summarize your findings and discuss the implications of your work. Also, discuss potential future work, such as how your approach could be applied to other models or tasks, or how it could be further improved. This will help readers understand the broader context of your work and its potential future directions.",
                "Consider separating the results from the discussion to enhance the readability of the paper. There are a few instances where sentences could be rephrased for clarity. Also, ensure all sentences are complete and convey the intended information. This will improve the overall readability and clarity of your paper.",
                "The mathematical proofs provided are quite complex. Please provide a more layman-friendly interpretation of these proofs to make the paper more accessible to readers who may not have a strong mathematical background. Also, structure the proofs of Lemma 3 in a more coherent manner, ensuring that each step logically follows from the previous one. This will help readers understand the mathematical foundations of your work.",
                "There are several instances where the text refers to an 'EQUATION' that is not provided. Please ensure that all necessary equations are included in the paper for completeness and to aid understanding. This will ensure that your paper is complete and that readers can follow your mathematical derivations.",
                "Please provide a brief explanation or reference for techniques such as the Chernoff bound and union bound for readers who may not be familiar with them. This will help readers understand the mathematical techniques used in your work.",
                "Ensure that all references are correctly cited. For example, clarify which specific paper by Vaswani et al., 2017 you are referring to. When referencing other works, please provide a brief summary of each referenced work and its relevance to the current study. Also, ensure that all references are included in a references section at the end of the paper. This will ensure that your paper adheres to academic standards and that readers can follow up on your references for further reading."
            ]
        },
        "alignments": {
            "all": []
        },
        "metrics": {
            "all": {
                "n_reference": 16,
                "n_generated": 12,
                "n_total_aligns": 0,
                "recall": 0.0,
                "precision": 0.0,
                "pseudo_jaccard": 0.0,
                "specificity_more": NaN,
                "specificity_less": NaN,
                "specificity_same": NaN
            }
        },
        "metrics_for_reviews": {
            "all": [
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 8
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 8
                }
            ]
        }
    },
    {
        "doc_id": "o2UwRc8fbXI",
        "method": "gpt_independent_chunk",
        "reference_comments": [
            [
                "The paper does not clearly state the main claims. The proposed method does not demonstrate a speed advantage or a clear performance boost.",
                "The reason for coupling the proposed method with CapsGCN is unclear, especially if the RL module is intended to tune the depth and width of convolutional layers.",
                "The paper does not clearly differentiate the proposed method from Neural Architecture Search (NAS).",
                "The motivations and experimental results presented in the paper are weak."
            ],
            [
                "The use of Reinforcement Learning (RL) during the training process to search for and modify the neural structures may create stability issues. The paper should provide some theoretical justifications or 'proofs' of convergence, or at the minimum, provide some empirical analysis on the stability of the training process.",
                "The evaluation of the proposed Adaptive Graph Capsule Convolutional Networks (AdaGCCN) could be more thorough. The paper should include ablation studies to show how effective the RL is in adapting the network structure, and discuss the runtime complexity, among other things."
            ],
            [
                "The motivations for the paper are not well discussed.",
                "The experimental methodology used in the paper is not well detailed, making it difficult to reproduce the reported results.",
                "The authors' claims are not always supported by the experimental evidence.",
                "The authors do not provide information about how the models considered during the experiments were validated. The policy used to validate the hyperparameters of a model highly impacts the model's performance.",
                "The authors do not report the standard deviation of the accuracies in table 5. This is crucial to correctly assess the model performance.",
                "The results in Table 5 suggest that using the AM to optimize the D and W does not justify the increase of complexity due to the use of this external model.",
                "The results reported in Table 5 are outperformed by results published in the literature for Enzymes datasets and in NCI.",
                "The performance of the model in terms of memory consumption is not completely discussed. Using AM seems to significantly impact the memory consumption and/or the training time of the model.",
                "The authors state that adjusting the model structure through an RL-based searching process improves the explainability of the model. This point should be further discussed with empirical results."
            ],
            [
                "The capsule graph neural network section (2.2) is somewhat shallow and could benefit from a more detailed introduction to the topics discussed to make the paper more self-contained.",
                "The paper lacks ablation experiments on the epoch sliding window size and choice of search space for D and W. It's also unclear how the method would perform without the capsule components, i.e. is the assistant module strategy practically useful for other architectures.",
                "There are concerns about reporting test accuracy throughout training in figure 3, as models could be overfit to the test set, rendering the results potentially incomparable to previous works.",
                "No standard deviations are reported in the results in table 2, and generally only marginal improvements are observed despite the increase in runtime complexity of the proposed method.",
                "The paper lacks meaningful runtime comparisons between the proposed method and the various previous works without the assistant module. For example, a comparison to a parallel cross validation version of CapsGNN in figure 4 is suggested.",
                "In the discussion, the authors claim the proposed approach improves the explainability of the model, but it's not clear how that is the case. The authors should either elaborate on this or exclude it from the paper.",
                "The purpose of using dynamic routing in capsule networks is to adaptively modify the network connectivity based on the input. Therefore, it might be possible to reduce the search space by only considering depth D and not width W, since dynamic routing already takes care of 'pruning' W. The authors should address this point."
            ]
        ],
        "generated_comments": {
            "all": [
                "The model/framework and its processes, including the assistant module and the RL-based searching process, could benefit from a more detailed explanation. Consider incorporating diagrams or flowcharts to aid in visualization and comprehension. This will allow readers to better understand the inner workings of your model and its unique features.",
                "The performance metrics used to evaluate the model could be elaborated upon. Please specify which metrics were used, why they were chosen, and provide a more comprehensive presentation of your experimental results. Including specific results, such as tables or graphs, will allow readers to clearly see the performance of the model and understand the implications of your findings.",
                "A detailed comparison with other models, particularly those that also utilize reinforcement learning or other adaptive techniques, would strengthen your paper. Discuss why the proposed model outperforms these methods and in what specific ways. This will highlight the unique contributions of your work and provide a clear context for the advantages of your model.",
                "More details about the experiments conducted would be beneficial. This should include information about the datasets used, the training process, and the evaluation process. To ensure the reproducibility of the results, consider providing the code used to implement the model, the specific parameters used, and any other necessary information. This will allow other researchers to replicate your work and further validate your findings.",
                "A more thorough discussion of the limitations of the proposed model is recommended. This will help readers understand the potential drawbacks of the method and areas for future improvement. It will also demonstrate your understanding of the model's weaknesses and your commitment to improving it.",
                "Future work could be discussed in more detail. This could include potential improvements to the model, other applications for the model, or other research questions that arose during this work. Providing more details on your future work, such as what specific optimizations you plan to make and how you expect these changes to improve your method, will give readers a clear understanding of the potential future directions of your research.",
                "Please ensure that all references are correctly cited and formatted according to the appropriate style guide. This will help readers find the original sources of information and verify the claims made in the paper. It also ensures that the original authors receive proper credit for their work.",
                "Ensure that all terminology is clearly defined and consistently used throughout the paper. This will help readers understand the content of the paper more easily and prevent any confusion that might arise from inconsistent or unclear terminology."
            ]
        },
        "alignments": {
            "all": [
                {
                    "reference_id": 2,
                    "predicted_id": 2,
                    "relative_specificity": "more",
                    "relatedness": "medium",
                    "pairwise_result": {
                        "relatedness": "medium",
                        "relative_specificity": "more",
                        "same_meaning": true
                    },
                    "count": 3,
                    "score": 0.6,
                    "reference_comment": "The paper does not clearly differentiate the proposed method from Neural Architecture Search (NAS).",
                    "predicted_comment": "A detailed comparison with other models, particularly those that also utilize reinforcement learning or other adaptive techniques, would strengthen your paper. Discuss why the proposed model outperforms these methods and in what specific ways. This will highlight the unique contributions of your work and provide a clear context for the advantages of your model."
                },
                {
                    "reference_id": 1,
                    "predicted_id": 1,
                    "relative_specificity": "same",
                    "relatedness": "medium",
                    "pairwise_result": {
                        "relatedness": "medium",
                        "relative_specificity": "same",
                        "same_meaning": true
                    },
                    "count": 4,
                    "score": 0.8,
                    "reference_comment": "The evaluation of the proposed Adaptive Graph Capsule Convolutional Networks (AdaGCCN) could be more thorough. The paper should include ablation studies to show how effective the RL is in adapting the network structure, and discuss the runtime complexity, among other things.",
                    "predicted_comment": "The performance metrics used to evaluate the model could be elaborated upon. Please specify which metrics were used, why they were chosen, and provide a more comprehensive presentation of your experimental results. Including specific results, such as tables or graphs, will allow readers to clearly see the performance of the model and understand the implications of your findings."
                },
                {
                    "reference_id": 1,
                    "predicted_id": 3,
                    "relative_specificity": "more",
                    "relatedness": "high",
                    "pairwise_result": {
                        "relatedness": "high",
                        "relative_specificity": "more",
                        "same_meaning": true
                    },
                    "count": 4,
                    "score": 0.8,
                    "reference_comment": "The experimental methodology used in the paper is not well detailed, making it difficult to reproduce the reported results.",
                    "predicted_comment": "More details about the experiments conducted would be beneficial. This should include information about the datasets used, the training process, and the evaluation process. To ensure the reproducibility of the results, consider providing the code used to implement the model, the specific parameters used, and any other necessary information. This will allow other researchers to replicate your work and further validate your findings."
                },
                {
                    "reference_id": 3,
                    "predicted_id": 1,
                    "relative_specificity": "more",
                    "relatedness": "medium",
                    "pairwise_result": {
                        "relatedness": "medium",
                        "relative_specificity": "more",
                        "same_meaning": true
                    },
                    "count": 2,
                    "score": 0.4,
                    "reference_comment": "No standard deviations are reported in the results in table 2, and generally only marginal improvements are observed despite the increase in runtime complexity of the proposed method.",
                    "predicted_comment": "The performance metrics used to evaluate the model could be elaborated upon. Please specify which metrics were used, why they were chosen, and provide a more comprehensive presentation of your experimental results. Including specific results, such as tables or graphs, will allow readers to clearly see the performance of the model and understand the implications of your findings."
                },
                {
                    "reference_id": 4,
                    "predicted_id": 2,
                    "relative_specificity": "more",
                    "relatedness": "medium",
                    "pairwise_result": {
                        "relatedness": "medium",
                        "relative_specificity": "more",
                        "same_meaning": true
                    },
                    "count": 2,
                    "score": 0.4,
                    "reference_comment": "The paper lacks meaningful runtime comparisons between the proposed method and the various previous works without the assistant module. For example, a comparison to a parallel cross validation version of CapsGNN in figure 4 is suggested.",
                    "predicted_comment": "A detailed comparison with other models, particularly those that also utilize reinforcement learning or other adaptive techniques, would strengthen your paper. Discuss why the proposed model outperforms these methods and in what specific ways. This will highlight the unique contributions of your work and provide a clear context for the advantages of your model."
                }
            ]
        },
        "metrics": {
            "all": {
                "n_reference": 22,
                "n_generated": 8,
                "n_total_aligns": 5,
                "recall": 0.2867063492063492,
                "precision": 0.15625,
                "pseudo_jaccard": 0.10459158896658896,
                "specificity_more": 0.8,
                "specificity_less": 0.0,
                "specificity_same": 0.2
            }
        },
        "metrics_for_reviews": {
            "all": [
                {
                    "recall": 0.25,
                    "precision": 0.125,
                    "pseudo_jaccard": 0.09090909090909091,
                    "n_real": 4
                },
                {
                    "recall": 0.5,
                    "precision": 0.125,
                    "pseudo_jaccard": 0.1111111111111111,
                    "n_real": 2
                },
                {
                    "recall": 0.1111111111111111,
                    "precision": 0.125,
                    "pseudo_jaccard": 0.0625,
                    "n_real": 9
                },
                {
                    "recall": 0.2857142857142857,
                    "precision": 0.25,
                    "pseudo_jaccard": 0.15384615384615385,
                    "n_real": 7
                }
            ]
        }
    },
    {
        "doc_id": "tJCwZBHm-jW",
        "method": "gpt_independent_chunk",
        "reference_comments": [
            [
                "The novelty of the paper is limited as the idea of transforming a 2D image pre-train backbone into a 3D version has already been used in other 2D-3D domains. The paper needs to place extra emphasis on discussing why it works and conducting ablation studies.",
                "The discussion section provides some experiments, but the results seem quite random (figure 4). The explanation for why 'shape representation' are better transferred is not convincing.",
                "The paper does not discuss if there is a difference on which axis to inflate (x, y, or z) when designing inflation. This is different to video since 3 axis is symmetric.",
                "The paper does not compare the parameter size in section 4.1. This raises concerns about the fairness of the comparison with the baseline, as the performance gain could be solely due to the increase in parameters.",
                "In section 4.2, there is a possibility that the ResNet structure is not a good structure to train on point cloud, making it quite bad on scratch training. The training method for pointnet++ is also questionable."
            ],
            [
                "The paper's visualizations do not adequately explain why the transfer works or what information can be transferred.",
                "The conclusion on page 8 that 'shape representations are better transferred from image to point-cloud' cannot be inferred from overall dataset performances. The term 'shape representations' is also not clearly defined."
            ],
            [
                "The paper lacks comparisons between results from datasets of different sizes in Table 1. It is unclear whether a larger dataset would lead to better performance.",
                "The paper does not include results of state-of-the-art task specific methods for comparison. It would be beneficial to compare with different self-supervised learning methods, such as Foldingnet and Pointcontrast.",
                "The paper does not provide a theoretical analysis to explain why inflating 2D filters to 3D is reasonable, given the significant domain gap between 2D and 3D datasets."
            ],
            [
                "The idea of inflating model weight from 2D to 3D is not new, as shown in the work of Carreira and Zisserman.",
                "The effectiveness of pretrained weight would be more convincing if the author could do further ablation study to initialize new model with expanding subsets of layers and exploring the effect on model performance. This would indicate which part of the pretrained model is really useful in this transferred learning setting."
            ],
            [
                "The paper is missing detailed information, making it difficult to follow the process. For example, in Table 1, the performances of pointnet++ and the performances are listed, but it's unclear how the inflation in point net++ is performed.",
                "The authors only perform experiments on classification and segmentation tasks. The performance on detection tasks should also be evaluated.",
                "The paper does not clearly address why the proposed method of inflating 2D CNN of image for 3D pointcloud works."
            ]
        ],
        "generated_comments": {
            "all": [
                "The paper could benefit from a more detailed explanation of the process of converting 2D ConvNets into 3D ConvNets. A visual representation or a step-by-step walkthrough of this process would enhance the reader's understanding and provide more context to the methodology. This could include diagrams or flowcharts to visually represent the process, and a detailed explanation of each step, including the rationale behind it and its impact on the results.",
                "The paper would be strengthened by a comprehensive comparison with existing point-cloud models. This comparison should include specific performance metrics and a discussion on why your method outperforms others. A table format would be ideal for presenting this information, as it would allow for a clear, side-by-side comparison of the performance of different methods on the same datasets. This would provide readers with a clear understanding of the advantages of your method over existing ones.",
                "A section discussing the limitations of the proposed method would provide a more balanced view of the work. This could also suggest potential directions for future research. Additionally, discussing potential future work, including potential improvements to the method or other tasks or datasets the method could be applied to, would provide valuable context for the implications of your research. This would help readers understand the broader impact of your work and its potential for future development.",
                "A discussion on potential real-world applications of your method would help readers understand the practical implications of the research. This could include potential industries or fields where your method could be applied, and the potential impact it could have. This would help to demonstrate the real-world relevance and potential impact of your research.",
                "To ensure reproducibility of the results and to allow other researchers to build upon your work, consider making your code, models, and data publicly available. This would also increase the transparency and credibility of your research. This could include providing a link to a public repository where your code and models are stored, and providing detailed instructions on how to use them.",
                "The paper could be strengthened by conducting additional experiments to validate your method. For instance, testing your method on different types of point-cloud data or using different pretraining datasets could provide more robust evidence of its effectiveness. More details about the experimental setup, such as the hyperparameters used, training process, the size of the training and test sets, the hardware used, the version of the software tools, and any other relevant details, would provide valuable context for your results. This would help to ensure that your results are robust and generalizable, and would provide readers with a clear understanding of how your experiments were conducted.",
                "To make the paper more accessible to readers who are not familiar with the field, provide clear definitions of the technical terms used in the paper (e.g., FIP-IO, FIP-IO+BN, FIP-ALL). This would also help to ensure that your methodology is clearly understood. This could include a glossary of terms or a section dedicated to explaining these terms in detail.",
                "The structure of the paper could be improved by clearly defining sections such as Introduction, Methodology, Results, Discussion, and Conclusion. This would enhance readability and make it easier for readers to follow the flow of your research. This could include using clear headings and subheadings, and ensuring that each section contains relevant and necessary information.",
                "Providing a rationale for the choice of datasets (ModelNet 3D Wharehouse, S3DIS, and SemanticKITTI) and explaining how these datasets contribute to the robustness of your model would strengthen your methodology. Justifying the choice of different parameters for training on different datasets (e.g., mini batch size, learning rate, epochs) and discussing how these choices affect the model's performance would provide valuable context for your results. This could include a discussion on the characteristics of each dataset and why they were chosen, and an analysis of how different parameters affect the model's performance on each dataset.",
                "A discussion on why you chose to use Pytorch and torchsparse for your experiments would provide valuable context. Discussing how these tools contribute to the implementation of your model and why they were chosen over other potential tools would enhance the reader's understanding of your methodology. This could include a comparison of Pytorch and torchsparse with other potential tools, and a discussion on the advantages and disadvantages of each."
            ]
        },
        "alignments": {
            "all": [
                {
                    "reference_id": 0,
                    "predicted_id": 0,
                    "relative_specificity": "more",
                    "relatedness": "medium",
                    "pairwise_result": {
                        "relatedness": "medium",
                        "relative_specificity": "more",
                        "same_meaning": true
                    },
                    "count": 4,
                    "score": 0.8,
                    "reference_comment": "The novelty of the paper is limited as the idea of transforming a 2D image pre-train backbone into a 3D version has already been used in other 2D-3D domains. The paper needs to place extra emphasis on discussing why it works and conducting ablation studies.",
                    "predicted_comment": "The paper could benefit from a more detailed explanation of the process of converting 2D ConvNets into 3D ConvNets. A visual representation or a step-by-step walkthrough of this process would enhance the reader's understanding and provide more context to the methodology. This could include diagrams or flowcharts to visually represent the process, and a detailed explanation of each step, including the rationale behind it and its impact on the results."
                },
                {
                    "reference_id": 2,
                    "predicted_id": 0,
                    "relative_specificity": "more",
                    "relatedness": "medium",
                    "pairwise_result": {
                        "relatedness": "medium",
                        "relative_specificity": "more",
                        "same_meaning": true
                    },
                    "count": 5,
                    "score": 1.0,
                    "reference_comment": "The paper does not provide a theoretical analysis to explain why inflating 2D filters to 3D is reasonable, given the significant domain gap between 2D and 3D datasets.",
                    "predicted_comment": "The paper could benefit from a more detailed explanation of the process of converting 2D ConvNets into 3D ConvNets. A visual representation or a step-by-step walkthrough of this process would enhance the reader's understanding and provide more context to the methodology. This could include diagrams or flowcharts to visually represent the process, and a detailed explanation of each step, including the rationale behind it and its impact on the results."
                },
                {
                    "reference_id": 1,
                    "predicted_id": 1,
                    "relative_specificity": "same",
                    "relatedness": "medium",
                    "pairwise_result": {
                        "relatedness": "medium",
                        "relative_specificity": "same",
                        "same_meaning": true
                    },
                    "count": 4,
                    "score": 0.8,
                    "reference_comment": "The paper does not include results of state-of-the-art task specific methods for comparison. It would be beneficial to compare with different self-supervised learning methods, such as Foldingnet and Pointcontrast.",
                    "predicted_comment": "The paper would be strengthened by a comprehensive comparison with existing point-cloud models. This comparison should include specific performance metrics and a discussion on why your method outperforms others. A table format would be ideal for presenting this information, as it would allow for a clear, side-by-side comparison of the performance of different methods on the same datasets. This would provide readers with a clear understanding of the advantages of your method over existing ones."
                },
                {
                    "reference_id": 2,
                    "predicted_id": 0,
                    "relative_specificity": "more",
                    "relatedness": "high",
                    "pairwise_result": {
                        "relatedness": "high",
                        "relative_specificity": "more",
                        "same_meaning": true
                    },
                    "count": 4,
                    "score": 0.8,
                    "reference_comment": "The paper does not clearly address why the proposed method of inflating 2D CNN of image for 3D pointcloud works.",
                    "predicted_comment": "The paper could benefit from a more detailed explanation of the process of converting 2D ConvNets into 3D ConvNets. A visual representation or a step-by-step walkthrough of this process would enhance the reader's understanding and provide more context to the methodology. This could include diagrams or flowcharts to visually represent the process, and a detailed explanation of each step, including the rationale behind it and its impact on the results."
                }
            ]
        },
        "metrics": {
            "all": {
                "n_reference": 15,
                "n_generated": 10,
                "n_total_aligns": 4,
                "recall": 0.24,
                "precision": 0.08,
                "pseudo_jaccard": 0.06731601731601732,
                "specificity_more": 0.75,
                "specificity_less": 0.0,
                "specificity_same": 0.25
            }
        },
        "metrics_for_reviews": {
            "all": [
                {
                    "recall": 0.2,
                    "precision": 0.1,
                    "pseudo_jaccard": 0.07142857142857142,
                    "n_real": 5
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 2
                },
                {
                    "recall": 0.6666666666666666,
                    "precision": 0.2,
                    "pseudo_jaccard": 0.18181818181818182,
                    "n_real": 3
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 2
                },
                {
                    "recall": 0.3333333333333333,
                    "precision": 0.1,
                    "pseudo_jaccard": 0.08333333333333333,
                    "n_real": 3
                }
            ]
        }
    },
    {
        "doc_id": "H1enKkrFDB",
        "method": "gpt_independent_chunk",
        "reference_comments": [
            [
                "The role of the partitioning index in the proposed algorithm is unclear, as it does not appear to be used in the experiments. The authors should clarify its importance and usage.",
                "The empirical evaluation of the normalization technique is insufficient to demonstrate its practical usefulness. The authors should focus more on showing how their regularization can improve generalization in practice.",
                "The authors should provide experiments on at least one additional dataset, such as CIFAR10 or ImageNet, to strengthen their empirical results.",
                "The reported accuracies for ResNet and DenseNet on the CIFAR100 dataset are significantly lower than what is reported in the literature. This issue needs to be resolved.",
                "The current results are based on training with a fixed number of epochs. Instead, the authors should train with a stopping criterion based on the cross-entropy loss on the training set and use the same stopping criterion for all models. They should also add plots showing training and test errors based on the number of epochs."
            ],
            [
                "The paper should characterize the runtime difference between SRN and SN. It is presently unclear how computationally intensive the method is. What is the difference in time per training iteration? The authors should also indicate their hardware setup and overall training time.",
                "Table 1 is confusing as it lacks the test error. If there is a difference in testing error, then this table is misleading. If the test errors are approximately the same, then why should I care if the training error is higher? This would just be a way to decrease the stated \u201cgeneralization gap,\u201d which is not necessarily indicative of a better model.",
                "The paper does not explain what \u201cStable-50\u201d, \u201cSRN-50\u201d, and \u201cSRN-50%\u201d are. This should be explicitly stated so that the reader knows which model corresponds to which settings."
            ],
            [
                "The paper could mention some related older introductory approaches, such as representing linear layers as 'bottlenecks' to enforce low rank explicitly, or solving in the manifold of reduced-rank matrices directly.",
                "The authors target the same stable rank (srank) r=c*min(m,n) for all layers, even though only the sum of sranks is important. It would be interesting to see if there is any observable difference for CNNs with only a few linear layers by lightly deviating from this.",
                "The paper could explore whether the first linear layer typically contributes the majority to the sum of sranks.",
                "The paper could discuss how 'stable rank' concepts might be extended to the convolutional layers. As a starting point, spectral values of the block-circulant matrices corresponding to convolutions have been described in previous work."
            ]
        ],
        "generated_comments": {
            "all": [
                "Revise the abstract to provide a concise explanation of the Stable Rank Normalization (SRN) and its benefits.",
                "Introduce and explain the concept of 'stable rank' earlier in the text, possibly in the introduction.",
                "Add explanatory text between equations to guide the reader through your thought process.",
                "Ensure all terms and symbols are clearly defined before they are used, including 'stable rank', 'spectral normalization', and symbols like '\u03a3', '\u039b', '\u0393', '\u00b5'.",
                "Explain the SRN-GAN methodology in layman's terms or include a diagram to aid understanding.",
                "Expand the justification for the choice of SRN over other normalization methods.",
                "Include a separate section detailing the experimental design, including the selection of networks, the specific tests run, and the criteria for evaluation.",
                "Expand the discussion of the results to provide a comprehensive understanding of the results and their significance.",
                "Provide a detailed comparison with other normalization methods, such as Spectral Normalization (SN).",
                "Include a discussion of potential future work and limitations of SRN in the conclusion.",
                "Include more visual aids, such as figures and tables, to help illustrate the concepts and results.",
                "Consolidate the presentation of Theorem 1 and its proof in one place, with a clear explanation of the theorem's significance and implications.",
                "Include a section or appendix that clearly defines all mathematical notations used in the paper.",
                "Discuss potential real-world applications of SRN-GAN.",
                "Consider providing the code used for the experiments, or at least a pseudocode of the main algorithm, to ensure the reproducibility of the results.",
                "Ensure all referenced works are properly cited in a references section and provide a brief explanation of each reference's relevance to the work.",
                "Proofread the paper for typographical errors and inconsistencies. For example, in paragraph id: 161, the algorithm is not completely shown."
            ]
        },
        "alignments": {
            "all": []
        },
        "metrics": {
            "all": {
                "n_reference": 12,
                "n_generated": 17,
                "n_total_aligns": 0,
                "recall": 0.0,
                "precision": 0.0,
                "pseudo_jaccard": 0.0,
                "specificity_more": NaN,
                "specificity_less": NaN,
                "specificity_same": NaN
            }
        },
        "metrics_for_reviews": {
            "all": [
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 5
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 3
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 4
                }
            ]
        }
    },
    {
        "doc_id": "Qm7R_SdqTpT",
        "method": "gpt_independent_chunk",
        "reference_comments": [
            [
                "The paper should provide insights on why switching actions at some fixed number of frames beats using the Gaussian variance for FVD.",
                "The paper should discuss the importance of the heuristic of changing states when using GP, and how the performance would be affected if a different threshold is used."
            ],
            [
                "The experimental section could be improved. More details about how the comparison to some baselines was made would be appreciated.",
                "The results for the VRNN model in Figure 4 and 5 do not follow the results in the literature, where it outperforms SVG and SAVP. It's unclear whether this is due to an architectural change, suboptimal hyperparameters, or a different reimplementation.",
                "The VRNN model is missing from some other comparisons such as Table 1.",
                "For SAVP, the results for Figure 4 seem much worse than those reported in the original paper."
            ],
            [
                "The application of Gaussian Processes (GP) in this work is straightforward and naive. Dynamical modeling with GP has been widely investigated since the introduction of Gaussian Process Dynamical Model in NIPs 2005.",
                "The modules of LSTM Frame Generation and GP Frame Generation in Equation (4) are not clearly explained or depicted in Figure 3. It is unclear if these modules correspond to 'D' in Stage 3.",
                "The use of GP to generate images is questionable as GP is more suitable for working in the latent space.",
                "The datasets used in the study are not representative due to their simplicity and experimental nature.",
                "The paper does not demonstrate the utility of the proposed method for high-level research topics such as large-scale action recognition, video captioning, etc."
            ]
        ],
        "generated_comments": {
            "all": [
                "Please provide a more detailed explanation of the Diverse Video Generator's methodology. Specifically, it would be beneficial to elaborate on how Gaussian Processes (GP) are used to model the diversity of future states. Additionally, a more in-depth explanation of the GP Temporal Dynamics Encoder and LSTM Temporal Dynamics Encoder, including their functionality and reasons for their selection, would be helpful.",
                "Consider including more visual aids, such as diagrams or flowcharts, to enhance the understanding of the proposed method. Specifically, illustrating how the GP variance is used to trigger a change in action sequence would be beneficial.",
                "Please provide a more detailed comparison of your method with existing variational approaches for video generation. This should include a discussion on the limitations of these existing methods and how your proposed method addresses these limitations.",
                "More experimental results showing how the Diverse Video Generator performs in comparison to other methods on a variety of datasets would be beneficial. A table or graph summarizing these results would enhance readability and understanding.",
                "Please discuss the interpretation of the results in more detail, specifically in the context of the research question and how they compare to the results of other methods.",
                "Consider adding a section discussing the limitations of your proposed method and the current study. This would provide a balanced view of the method and suggest directions for future research.",
                "To ensure reproducibility, consider providing the code for your method. This would allow other researchers to replicate your results and further build upon your work.",
                "Please provide a more detailed explanation of the evaluation metrics used in the paper. Specifically, how these metrics are used to evaluate the quality and diversity of the generated sequences.",
                "Please provide a detailed explanation of how the hyperparameters in the model were chosen or optimized.",
                "Ensure consistency in the naming of your models. In some sections, you mention DVG-RNN and DVG-GRU, but in others, you only mention RNN, GRU, and LSTM. Please clarify whether these are the same models or different ones.",
                "You mention using GPytorch for your GP layer implementation. Could you provide more details about why you chose this specific tool and how it compares to other potential tools?",
                "You mention in one section that you hope the community will stop relying on reconstruction metrics for video prediction. It would be interesting if you could propose and test alternative metrics in your paper to support this statement.",
                "In one section, you mention using a stochastic optimization technique (Adam optimizer) to minimize the variational ELBO for a GP. Could you provide a brief explanation of why you chose this specific optimization technique and how it benefits your model?"
            ]
        },
        "alignments": {
            "all": []
        },
        "metrics": {
            "all": {
                "n_reference": 11,
                "n_generated": 13,
                "n_total_aligns": 0,
                "recall": 0.0,
                "precision": 0.0,
                "pseudo_jaccard": 0.0,
                "specificity_more": NaN,
                "specificity_less": NaN,
                "specificity_same": NaN
            }
        },
        "metrics_for_reviews": {
            "all": [
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 2
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 4
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 5
                }
            ]
        }
    },
    {
        "doc_id": "K5j7D81ABvt",
        "method": "gpt_independent_chunk",
        "reference_comments": [
            [
                "The paper does not clarify whether 'S_F = S_sTEX' refers to exact string equality or after white space normalization. The authors should specify the exact normalizations and provide the success rate before and after them.",
                "The paper does not discuss the potential impact of using larger GPT models.",
                "The paper does not explore the potential usefulness of unsupervised learning methods, which have recently seen significant improvements.",
                "The term 'fully disambiguated' is used in definition 4.1 without considering the types of variables. In systems with subtypes, the meaning and provability of a statement can change depending on the quantification over different types of numbers."
            ],
            [
                "The current benchmark lacks sufficient training and evaluation data. The lack of training corpora may be addressed by pretraining and building synthetic data.",
                "A larger and high-quality evaluation set is needed to validate any actual progress on this problem. The current evaluation set is too small and covers limited math topics.",
                "The evaluation protocol is unclear. The best evaluation protocol should be checking if S_F belongs to STEX(S_STEX), which is not used in this work. The authors should consider implementing this protocol.",
                "An ablation study on the corresponding contributions of pretraining and synthetic data is needed for the proposed approach."
            ],
            [
                "The paper does not compare the proposed method against other systems listed in section 4 that also aim to automate the formalization process.",
                "The choice of phrasing the task as a translation problem is questionable, as it seems to set up the NMT baselines to perform poorly due to the identity transformation required for much of the document.",
                "The evaluation methodology is confusing, particularly the use of automated procedures to generate some of the data. This raises questions about why these automated methods are not sufficient for the end task.",
                "The results section does not present the results of the baselines, making it difficult to assess their performance relative to the proposed method.",
                "The paper does not provide a clear understanding of the problem setting, what is being learned, and what is failing. This makes it difficult to assess the importance and difficulty of the targeted problem.",
                "The experimental section is short and lacks important comparisons to other work in this area.",
                "The model is used in a very off-the-shelf way and does not treat the problem setting any differently than a standard translation task, which raises questions about the novelty of the modeling contribution.",
                "The paper uses a lot of domain-specific terminology that may be difficult for a general ML audience to understand. For example, the terms 'formal' and 'informal' are used in a way that is not immediately clear.",
                "The paper needs major restructuring and refocusing, more experiments, and more analysis to be considered for acceptance."
            ],
            [
                "The problem definition was not clear. A concrete example demonstrating what exactly an algorithm for the problem gets as input and what is its output is missing.",
                "The description of the dataset was unclear. While there is a formal description, the lack of examples leaves the description at a very abstract level, making it difficult to understand what exactly should be expected in the dataset.",
                "The authors do not show awareness of work in semantic parsing and in style transfer. These works are very important both for the algorithmic approach and for understanding the challenges of evaluation. For example, there is lots of semantic parsing research on transferring text into SQL queries or on solving textual mathematical problems. The connection to relevant ideas and approaches should be part of the introduction of the task."
            ]
        ],
        "generated_comments": {
            "all": [
                "The introduction could benefit from a clearer structure. Please consider including a brief overview of the paper's structure at the end of the introduction. This would help readers understand the flow of your paper and what to expect in each section. This is a common practice in scientific writing and would enhance the readability of your paper.",
                "The methodology section needs more details about the transformer language model used. Please elaborate on the architecture of the model, the training process, and the choice of hyperparameters. Additionally, provide a more detailed explanation of the rationale behind choosing the GPT2 model over others. This would help readers understand the technical aspects of your study better and justify your choice of model.",
                "The dataset used in your study needs a more detailed description. Please provide information on how it was collected and annotated, its size, and its distribution. Also, provide more context about the SMGLoM and MiKoMH datasets used in the study, including their size, nature, and source. This would help readers understand the basis of your study better and assess the generalizability of your results.",
                "The evaluation metrics used to assess the performance of your model need to be explained in more detail. Consider using more standard evaluation metrics for your model. Despite the unique challenges in evaluating your model, widely accepted metrics in the field would provide a clearer understanding of your model's performance and allow for easier comparison with other studies.",
                "Please provide a more detailed comparison with the baseline models that failed to yield syntactically valid L A T E X before overfitting. Explain why these models failed and how your model overcomes these failures. This would help readers understand the improvements your model brings to the field and the unique challenges you faced.",
                "A detailed discussion of your results is needed. Please include tables or graphs to illustrate the performance of your model. Discuss the implications of your findings, how your work advances the field, and potential applications of your research. This would help readers understand the significance of your study and its potential impact on the field.",
                "Please include a section discussing the limitations of the current study and potential directions for future research. In your conclusion, you mention future plans to combine the proposed symbolic disambiguation approach with an autoformalization framework. Please elaborate more on this, providing insights into how you plan to achieve this and the expected impact on your research. This would give readers a clearer understanding of the potential future developments in your research.",
                "You mention that all code and data relevant to the paper is available at a certain link. Please provide more details about what exactly is available at this link, such as whether it includes raw data, processed data, code for data processing, code for analysis, etc. This would be beneficial for other researchers who want to reproduce the study or build upon it. It would also demonstrate your commitment to open science and reproducibility."
            ]
        },
        "alignments": {
            "all": [
                {
                    "reference_id": 1,
                    "predicted_id": 2,
                    "relative_specificity": "more",
                    "relatedness": "high",
                    "pairwise_result": {
                        "relatedness": "high",
                        "relative_specificity": "more",
                        "same_meaning": true
                    },
                    "count": 4,
                    "score": 0.8,
                    "reference_comment": "The description of the dataset was unclear. While there is a formal description, the lack of examples leaves the description at a very abstract level, making it difficult to understand what exactly should be expected in the dataset.",
                    "predicted_comment": "The dataset used in your study needs a more detailed description. Please provide information on how it was collected and annotated, its size, and its distribution. Also, provide more context about the SMGLoM and MiKoMH datasets used in the study, including their size, nature, and source. This would help readers understand the basis of your study better and assess the generalizability of your results."
                }
            ]
        },
        "metrics": {
            "all": {
                "n_reference": 20,
                "n_generated": 8,
                "n_total_aligns": 1,
                "recall": 0.08333333333333333,
                "precision": 0.03125,
                "pseudo_jaccard": 0.025,
                "specificity_more": 1.0,
                "specificity_less": 0.0,
                "specificity_same": 0.0
            }
        },
        "metrics_for_reviews": {
            "all": [
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 4
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 4
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 9
                },
                {
                    "recall": 0.3333333333333333,
                    "precision": 0.125,
                    "pseudo_jaccard": 0.1,
                    "n_real": 3
                }
            ]
        }
    },
    {
        "doc_id": "rkxZCJrtwS",
        "method": "gpt_independent_chunk",
        "reference_comments": [
            [
                "The paper should include an argument explaining that accurately estimating Q using Q_phi does not necessarily mean that the gradients of Q_phi will be good approximations of the true gradients of Q. The reviewer suggests referring to Fig 1 of arxiv.org/pdf/1705.07107.pdf for an informative example.",
                "The choice of Euclidean norm in line 10 needs justification. The reviewer suggests considering the importance of the direction of the gradient over the norm and proposes the use of cosine similarity instead.",
                "The paper argues that Deep Reinforcement Learning (DRL) is superior to Model Predictive Control (MPC) due to better exploration. The reviewer suggests exploring the possibility of using simulator gradients to further improve exploration in DRL."
            ],
            [
                "The paper's contribution is empirical in nature, and a promising future direction would be to add derivative information to and evaluate similar variants of newer actor-critic methods such as TD3 and SAC."
            ],
            [
                "The form of gradient given in equation (2) might contain an error. In DDPG, the action is given by a deterministic policy, thus we have $a_t = \\pi(s_t)$ for all $t\\geq 0$. For critic estimation, it seems you are basing on the Bellman equation $ Q(s,a) = r(s,a) + Q(s', \\pi(s'))$, where $s'$ is the next state following $(s,a)$. Then, it seems that Equation (2) is obtained by taking gradient with respect to $(s,a)$. However, I cannot understand what $\\nabla_{\\pi} Q$ stands for. If it is $\\nabla_a Q(s_{i+1}, a_{i+1}) \\cdot \\nabla_s \\pi(s_{i+1}) $, then that makes sense.",
                "Based on the experiments, the proposed method does not always outperform MPC or DDPG, even in a small-scale control problem Mountaincar. Moreover, it seems that the performance is similar to that of the DDPG.",
                "The model-based gradient in equation (2) is defined by only unroll one-step forward by going from $s_i, a_i$ to $s_{i+1}$. It would be interesting to see how the number of unroll steps affect the algorithm, which is a gradient version of TD($\\lambda$)."
            ]
        ],
        "generated_comments": {
            "all": [
                "The abstract could benefit from a more straightforward explanation of the paper's main contributions. Consider simplifying the language and focusing on the key findings and their implications. This will help readers quickly understand the purpose, methods, and results of your study.",
                "The paper would benefit from a more detailed explanation of the hybrid algorithm. Specifically, it would be helpful to understand how it combines the best aspects of gradient-based methods and DRL. Consider providing a step-by-step breakdown of the algorithm to aid understanding and replication of the study. Visual aids, such as diagrams or flowcharts, could be particularly useful in explaining the proposed method.",
                "A more detailed comparison with other state-of-the-art methods would strengthen the paper. This should include both quantitative results (performance metrics) and qualitative results (discussion of why the proposed method is superior). This will help readers understand the unique value of your method and how it advances the field.",
                "The paper could provide more details about the experimental setup. This includes information about the differentiable physical simulator used, the specific 2D robot control tasks, and the evaluation metrics. Justification for the choice of specific tasks and environments used in the simulations would also be beneficial. This will help readers understand the context and constraints of your study.",
                "A discussion of the limitations of the proposed method would enhance the paper. This should include situations where the method might not perform well, assumptions made by the method, and potential ways to address these limitations in future work. Additionally, expanding on the suggestions for future research directions based on the findings of this study would be valuable.",
                "To ensure reproducibility, consider providing the code for the proposed method, as well as any data used in the experiments. This will allow other researchers to replicate your study and build upon your work.",
                "A discussion of potential real-world applications of the method would highlight its practical significance and potential impact. This could include potential industries or specific scenarios where your method could be applied."
            ]
        },
        "alignments": {
            "all": []
        },
        "metrics": {
            "all": {
                "n_reference": 7,
                "n_generated": 7,
                "n_total_aligns": 0,
                "recall": 0.0,
                "precision": 0.0,
                "pseudo_jaccard": 0.0,
                "specificity_more": NaN,
                "specificity_less": NaN,
                "specificity_same": NaN
            }
        },
        "metrics_for_reviews": {
            "all": [
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 3
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 1
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 3
                }
            ]
        }
    },
    {
        "doc_id": "xP37gkVKa_0",
        "method": "gpt_independent_chunk",
        "reference_comments": [
            [
                "The paper's proposed method, LBS, only supports one agent in a two-player game.",
                "The authors mention learning a centralized reward function using VDN, while other agent\u2019s q-value functions are unavailable. It's unclear how this is achieved.",
                "The method for using the total reward expectation to avoid having to unroll episodes until the end of the game is not clear."
            ],
            [
                "The paper needs to address how overestimation is handled when using argmax of $Q(a^i|\\tau^i)$ in n-step rollout, especially considering the large variance in rollout. The use of any variance reduction technique should be clarified.",
                "The experiments are only evaluated on Hanabi, raising concerns about the generalizability of the method. The paper should include at least one experiment evaluated on a different game, such as Leduc, to demonstrate its applicability to different imperfect information games.",
                "The paper needs to provide clear definitions and explanations for terms and concepts used, such as 'BP' on page 1, 'blueprint policies' in section 2.1, and the belief definition in section 3.",
                "Equations 2, 3, and 4 are confusing and need further explanation, as they are crucial to the paper."
            ],
            [
                "The motivation of why Learned Belief Search (LBS) can be challenging and useful for DEC-POMDP or the multi-agent game domains is not convincingly explained.",
                "The experiment settings, problem description, and discussions need more elaboration.",
                "The results in Table 1 and 3 are not discussed in the main text, making it hard to understand the reported numbers. The authors should elaborate on these in their response.",
                "A brief description of the Hanabi game should be included in the Appendix.",
                "Comparisons of different design/hyperparameter choices should be included to help judge the benefit of using learning for belief representation."
            ],
            [
                "The paper's proposed method, LBS, is highly dependent on the well-trained Blue Policy (BP). The importance of BP's contribution to the final performance is unclear.",
                "It is not clear how LBS would perform when based on a broken or flawed BP policy.",
                "The paper does not provide clarity on how LBS would perform when using an unconverging learned belief model or value model.",
                "The choice of the number of factorized private features in the belief model is not clear.",
                "The efficacy of LBS, especially in more complex environments like Contract Bridge, is not convincingly demonstrated despite the provided ablation studies."
            ],
            [
                "More detail is required to explain why multi-agent search is not theoretically sound. If the trained model is only accurate for single agent search, is it not possible to train a model that is compatible with multi-agent search under different settings for max range?",
                "The authors focus on 2-player Hanabi and claim it to be straightforward to extend to any number of players. However, SPARTA itself was computationally limited to single-agent search for these 3-player and up variants. Applying your approach in these experiments would make a stronger case for elevation of the state-of-the-art than the 6-card variant.",
                "The experimental setup requires significantly more details on the hardware used for training, testing and validating.",
                "Have you examined how this would look for more general partially observable settings? In particular, work on POSGs with public observations [Hor\u00e1k, K.; and Bosansk\u00fd, B. 2019. Solving Partially Observable Stochastic Games with Public Observations. In AAAI Conf. on Artificial Intelligence, 2029\u20132036. AAAI Press.]",
                "Are there any other DEC-POMDP settings that you considered? It may be insightful to compare the effects of different feature spaces."
            ]
        ],
        "generated_comments": {
            "all": [
                "The methodology section could benefit from a more detailed explanation of the Learned Belief Search (LBS) methodology. Consider including a flowchart or algorithmic pseudocode to illustrate the process. Additionally, it would be helpful to provide a step-by-step walkthrough of the LBS process using a simple example, which would further enhance the reader's understanding.",
                "The paper would benefit from a more detailed comparison of LBS with other search methods, such as SPARTA. A table or chart that clearly outlines the differences and advantages of LBS would be beneficial. Additionally, it would be helpful to discuss why certain methods were chosen for comparison and how they relate to your work.",
                "The experimental results section could be expanded to include more detailed results, including the specific settings and parameters used, as well as a comparison with the results of other methods. Information on the training and testing datasets, the computational resources used, and the hyperparameters chosen would be useful for readers. To enhance the reproducibility of the study, consider sharing the code, models, and data used in the experiments. Furthermore, providing a detailed explanation of how the results were interpreted and their significance in relation to your research question would be beneficial.",
                "The paper could benefit from a discussion of potential real-world applications of LBS. While the application to the game of Hanabi is mentioned, a discussion of how this method could be applied to other domains or problems would be interesting. For instance, how might LBS be applied in other game scenarios, or even in real-world decision-making contexts? What are the potential benefits and challenges of such applications?",
                "A section discussing the limitations of the current LBS method and potential areas for future work would be beneficial. You mention potential future directions, including retraining the belief model on data generated from LBS and integrating the search process into the training process. It would be beneficial if you could elaborate on these points, providing more concrete examples or potential approaches. For instance, what specific strategies might be used to retrain the belief model, and what are the potential benefits and challenges of integrating the search process into the training process?"
            ]
        },
        "alignments": {
            "all": []
        },
        "metrics": {
            "all": {
                "n_reference": 22,
                "n_generated": 5,
                "n_total_aligns": 0,
                "recall": 0.0,
                "precision": 0.0,
                "pseudo_jaccard": 0.0,
                "specificity_more": NaN,
                "specificity_less": NaN,
                "specificity_same": NaN
            }
        },
        "metrics_for_reviews": {
            "all": [
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 3
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 4
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 5
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 5
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 5
                }
            ]
        }
    },
    {
        "doc_id": "-qB7ZgRNRq",
        "method": "gpt_independent_chunk",
        "reference_comments": [
            [
                "The motivation for the new task proposed in the paper is not clear.",
                "The paper does not compare the proposed model, DDNet, to any other baselines that incorporate the audio information in a different way.",
                "The paper incorrectly claims that the method from Serdyuk et al. (2018) was 'concurrent', despite it being published in 2018.",
                "It is unclear why the Spoken-CoQA dataset includes text transcripts as well as the audio. It would make more sense for the text transcripts to be part of the model solving the dataset."
            ],
            [
                "The work is limited in its scope and is not yet ready to be published at ICLR due to lack of comparisons made to prior approaches, making it hard to assess the merits of the proposed approach.",
                "The authors do not mention any plans of releasing the new dataset described in this work, which is a concern.",
                "It would be interesting to show how F1 scores vary on the test instances as a function of the number of turns in the conversation, and how test F1 scores vary as a function of ASR accuracy of the spoken documents/questions.",
                "The error rate of the ASR system on the spoken documents and spoken questions should be provided to give the reader an idea of the accuracy of the transcriptions fed as input to the student model.",
                "In Table 4, the F1 scores using SDNet are higher for S-CoQA compared to CoQA which is unexpected. The authors should provide an explanation for this.",
                "The reliance of the proposed system on clean text is a significant issue that needs to be addressed."
            ],
            [
                "The paper's contributions and novelty are unclear, and it's uncertain if they warrant acceptance.",
                "The paper's methods, including the cross attention mechanism for speech and text embedding fusion and knowledge distillation for combatting ASR errors, are existing, well-studied methods.",
                "The Spoken-CoQA dataset, which is a significant contribution of the paper, is not made available.",
                "The paper should clarify whether the knowledge distillation and cross attention mechanisms can be combined for better performance.",
                "The paper should address whether the textual input is more useful than the audio input in the Spoken-CoQA dataset, especially considering the audio input is larger and more difficult to process."
            ],
            [
                "The biggest weakness of this paper is in its data construction. When the ASR output is noisy, the spans refer to ghost token positions based on the clean text. This makes the data difficult to learn from and may result in models predicting the wrong span.",
                "The paper falls short of delivering a usable dataset for speech-based conversational QA. The authors should consider returning the audio segments as answers instead of using text-based spans. This might require additional annotation but could make the dataset more meaningful and usable.",
                "The use of a knowledge distillation (KD) layer to address the issue of noisy ASR text is questionable. The KD layer shows the model the gold clean transcription (original passage), which could defeat the purpose of speech-based conversational QA as motivated in this paper."
            ]
        ],
        "generated_comments": {
            "all": [
                "Introduction and Background: The Spoken Conversational Question Answering task (SCQA) could be better explained. Please provide a more detailed explanation of its significance in the field of natural language processing. Additionally, it would be beneficial to include a brief overview of the current state of research in this area to further establish the relevance of your work.",
                "Methodology: The novel unified data distillation approach, DDNet, and the CMRC module need more elaboration. Please provide more details about how the fusion of audio-text features occurs, how the Encoding Layer, Attention Layer, and Output Layer work together, and why these methods are effective. This will help readers understand the technical aspects of your work and its potential advantages over existing methods.",
                "Experiments: More information about the experiments conducted would be beneficial. Specifically, explain how you selected the baseline models and why you chose to use the Spoken-CoQA dataset. This will help readers understand the rationale behind your experimental design and its relevance to the research question.",
                "Results: More specific results and a detailed analysis are needed to support the claim that your proposed method achieves superior performance in spoken conversational question answering. This could include numerical data or comparisons with other methods. Explain why the F1 scores dropped when training the models on Spoken-CoQA and testing on the Spoken-CoQA test set. This will help readers understand the implications of your findings and their potential impact on the field.",
                "Dataset: More information about the Spoken Conversational Question Answering (Spoken-CoQA) dataset would be helpful. Discuss how it was assembled and why it is suitable for evaluating the capacity of QA systems in a dialogue-style interaction. This will help readers understand the validity and reliability of your data source.",
                "Knowledge Distillation: More details about the knowledge distillation process would be beneficial. Specifically, explain how the teacher model guides the student model to learn contextual features. This will help readers understand the mechanisms underlying your approach and its potential advantages over existing methods.",
                "Related Work: A more direct comparison with previous studies would be beneficial. This could include a discussion of how your approach improves upon or addresses the limitations of existing methods. This will help readers understand the novelty and significance of your work in the context of the existing literature.",
                "Conclusion: Summarize the main findings of your study and discuss their implications. Discuss the limitations of your study and suggest directions for future research in this area. This will help readers understand the broader impact of your work and its potential to drive future research.",
                "References: Ensure that all references are correctly cited and formatted according to the guidelines of the venue where you plan to submit the paper. This will help maintain the integrity of your work and ensure that all sources are properly acknowledged.",
                "Figures and Tables: Ensure that all figures and tables are clearly labeled and referenced in the text. Provide detailed captions that explain what each figure or table shows. This will help readers understand the data and findings presented in your work.",
                "Language and Style: Proofread the paper to correct any grammatical errors and improve the clarity and coherence of the writing. Ensure that the paper follows the style guidelines of the venue where you plan to submit it. This will help ensure that your work is presented in a professional and accessible manner."
            ]
        },
        "alignments": {
            "all": [
                {
                    "reference_id": 0,
                    "predicted_id": 0,
                    "relative_specificity": "more",
                    "relatedness": "high",
                    "pairwise_result": {
                        "relatedness": "high",
                        "relative_specificity": "more",
                        "same_meaning": true
                    },
                    "count": 5,
                    "score": 1.0,
                    "reference_comment": "The motivation for the new task proposed in the paper is not clear.",
                    "predicted_comment": "Introduction and Background: The Spoken Conversational Question Answering task (SCQA) could be better explained. Please provide a more detailed explanation of its significance in the field of natural language processing. Additionally, it would be beneficial to include a brief overview of the current state of research in this area to further establish the relevance of your work."
                },
                {
                    "reference_id": 1,
                    "predicted_id": 6,
                    "relative_specificity": "more",
                    "relatedness": "medium",
                    "pairwise_result": {
                        "relatedness": "medium",
                        "relative_specificity": "more",
                        "same_meaning": true
                    },
                    "count": 3,
                    "score": 0.6,
                    "reference_comment": "The paper does not compare the proposed model, DDNet, to any other baselines that incorporate the audio information in a different way.",
                    "predicted_comment": "Related Work: A more direct comparison with previous studies would be beneficial. This could include a discussion of how your approach improves upon or addresses the limitations of existing methods. This will help readers understand the novelty and significance of your work in the context of the existing literature."
                },
                {
                    "reference_id": 0,
                    "predicted_id": 6,
                    "relative_specificity": "more",
                    "relatedness": "high",
                    "pairwise_result": {
                        "relatedness": "high",
                        "relative_specificity": "more",
                        "same_meaning": true
                    },
                    "count": 4,
                    "score": 0.8,
                    "reference_comment": "The work is limited in its scope and is not yet ready to be published at ICLR due to lack of comparisons made to prior approaches, making it hard to assess the merits of the proposed approach.",
                    "predicted_comment": "Related Work: A more direct comparison with previous studies would be beneficial. This could include a discussion of how your approach improves upon or addresses the limitations of existing methods. This will help readers understand the novelty and significance of your work in the context of the existing literature."
                },
                {
                    "reference_id": 0,
                    "predicted_id": 6,
                    "relative_specificity": "more",
                    "relatedness": "medium",
                    "pairwise_result": {
                        "relatedness": "medium",
                        "relative_specificity": "more",
                        "same_meaning": true
                    },
                    "count": 3,
                    "score": 0.6,
                    "reference_comment": "The paper's contributions and novelty are unclear, and it's uncertain if they warrant acceptance.",
                    "predicted_comment": "Related Work: A more direct comparison with previous studies would be beneficial. This could include a discussion of how your approach improves upon or addresses the limitations of existing methods. This will help readers understand the novelty and significance of your work in the context of the existing literature."
                }
            ]
        },
        "metrics": {
            "all": {
                "n_reference": 18,
                "n_generated": 11,
                "n_total_aligns": 4,
                "recall": 0.21666666666666667,
                "precision": 0.09090909090909091,
                "pseudo_jaccard": 0.07075320512820513,
                "specificity_more": 1.0,
                "specificity_less": 0.0,
                "specificity_same": 0.0
            }
        },
        "metrics_for_reviews": {
            "all": [
                {
                    "recall": 0.5,
                    "precision": 0.18181818181818182,
                    "pseudo_jaccard": 0.15384615384615385,
                    "n_real": 4
                },
                {
                    "recall": 0.16666666666666666,
                    "precision": 0.09090909090909091,
                    "pseudo_jaccard": 0.0625,
                    "n_real": 6
                },
                {
                    "recall": 0.2,
                    "precision": 0.09090909090909091,
                    "pseudo_jaccard": 0.06666666666666667,
                    "n_real": 5
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 3
                }
            ]
        }
    },
    {
        "doc_id": "0NQdxInFWT_",
        "method": "gpt_independent_chunk",
        "reference_comments": [
            [
                "The method is a small extension to the DPS method where the network that selects which rows to samples is conditioned on the existing measurements.",
                "The paper did not compare to any other active sampling strategies. The authors made no effort to replicate existing methods.",
                "The Markov chain example in section 4.1 was hard to follow and more distracting than informative.",
                "The results with active sampling were only marginally better than results with a fixed (learned) sampling strategy.",
                "The method is applicable only to true subsampling problems, not general sensing. That is, one isn't designing the rows of a measurement matrix on the fly but rather selecting which row from an existing matrix (identity in most of the examples) that one would like to sample from.",
                "Because of the nonlinearity in the forward model, equation (9) is not actually proximal gradient descent. There's a sign(F^HD\\circFX) term missing from the (sub) gradient.",
                "The expression A^H(Ax-Y\\circ sign(A(x))) is a subgradient of 1/2|| Y - |A(X)|||^2 but A^H(|Ax|-Y) is not. I would avoid calling (9) projected gradient descent as the 'gradient' isn't really a gradient."
            ],
            [
                "The proposed approach appears to be incremental: ADPS adds a simple sequential update structure (of a context vector) to DPS, which can be described by only two equations (6 and 7). The simplicity of the changes proposed (over DPS) is not a limitation, but it could be accompanied by an in-depth theoretical analysis, a convincing qualitative discussion or extensive experiments demonstrating the practical relevance of the proposed approach.",
                "The paper contributes by extending DPS into an active/sequential learning framework achieving significant performance gains over DPS, mainly on toy problems. However, there is room for more extensive experimental validation, perhaps beyond MRI."
            ],
            [
                "The paper lacks comparison to other active sub-sampling schemes, such as those proposed by Zhang et al., 2019 and Jin et al., 2019. It would be beneficial to see if the proposed method produces better results than these existing methods.",
                "The toy example provided is overly constructed and difficult to understand, which does not improve the quality of the paper.",
                "It is unclear what happens when the MNIST sampling ratio in Figure 3a is further increased. It would be helpful to know if A-DPS consistently outperforms DPS in low sampling ratio regimes."
            ]
        ],
        "generated_comments": {
            "all": [
                "Elaboration on A-DPS Methodology: The paper would be significantly enhanced by a more in-depth explanation of the Active Deep Probabilistic Subsampling (A-DPS) method. A step-by-step walkthrough of the method, supplemented with a flowchart or algorithmic pseudocode, would be beneficial. This would aid readers, particularly those not deeply immersed in the field, to gain a more comprehensive understanding of the method and its implications. This would also provide a solid foundation for readers to fully appreciate the novelty and significance of your work.",
                "Comparative Analysis with Existing Methods: A more exhaustive comparison of A-DPS with other existing methods, particularly those that also employ active acquisition, would be valuable. This could be presented in a tabular format, clearly delineating the strengths and weaknesses of each method. This would help readers to better understand the unique contributions of A-DPS and its position within the broader field. It would also provide a clear context for your work and highlight its novelty.",
                "In-depth Presentation of Experimental Results: A more detailed presentation of the experimental results would enhance the paper. This could include specific performance metrics, visual aids such as graphs or charts, and more granular information about the training process (e.g., number of training iterations, specific training data used). This would provide readers with a clearer understanding of the effectiveness of the A-DPS method and the robustness of your results.",
                "Discussion of Limitations: A more comprehensive discussion of the limitations of the A-DPS method would provide a more balanced view of your work. This could include aspects such as computational complexity, potential challenges in implementation, and any limitations observed during the experiments. This would not only provide a more balanced view of the method but also suggest areas for future research, thereby contributing to the ongoing development of the field.",
                "Potential Real-world Applications: A more detailed discussion of potential real-world applications of the A-DPS method would be beneficial. This could include potential challenges or obstacles that might need to be overcome in order to apply the method in these contexts. A more detailed discussion of these applications will help readers understand the potential impact and practicality of this work. It would also provide a clear indication of the relevance and applicability of your work to real-world scenarios."
            ]
        },
        "alignments": {
            "all": [
                {
                    "reference_id": 1,
                    "predicted_id": 1,
                    "relative_specificity": "more",
                    "relatedness": "high",
                    "pairwise_result": {
                        "relatedness": "high",
                        "relative_specificity": "more",
                        "same_meaning": true
                    },
                    "count": 3,
                    "score": 0.6,
                    "reference_comment": "The paper did not compare to any other active sampling strategies. The authors made no effort to replicate existing methods.",
                    "predicted_comment": "Comparative Analysis with Existing Methods: A more exhaustive comparison of A-DPS with other existing methods, particularly those that also employ active acquisition, would be valuable. This could be presented in a tabular format, clearly delineating the strengths and weaknesses of each method. This would help readers to better understand the unique contributions of A-DPS and its position within the broader field. It would also provide a clear context for your work and highlight its novelty."
                },
                {
                    "reference_id": 0,
                    "predicted_id": 1,
                    "relative_specificity": "more",
                    "relatedness": "high",
                    "pairwise_result": {
                        "relatedness": "high",
                        "relative_specificity": "more",
                        "same_meaning": true
                    },
                    "count": 4,
                    "score": 0.8,
                    "reference_comment": "The paper lacks comparison to other active sub-sampling schemes, such as those proposed by Zhang et al., 2019 and Jin et al., 2019. It would be beneficial to see if the proposed method produces better results than these existing methods.",
                    "predicted_comment": "Comparative Analysis with Existing Methods: A more exhaustive comparison of A-DPS with other existing methods, particularly those that also employ active acquisition, would be valuable. This could be presented in a tabular format, clearly delineating the strengths and weaknesses of each method. This would help readers to better understand the unique contributions of A-DPS and its position within the broader field. It would also provide a clear context for your work and highlight its novelty."
                }
            ]
        },
        "metrics": {
            "all": {
                "n_reference": 12,
                "n_generated": 5,
                "n_total_aligns": 2,
                "recall": 0.15873015873015872,
                "precision": 0.13333333333333333,
                "pseudo_jaccard": 0.07792207792207792,
                "specificity_more": 1.0,
                "specificity_less": 0.0,
                "specificity_same": 0.0
            }
        },
        "metrics_for_reviews": {
            "all": [
                {
                    "recall": 0.14285714285714285,
                    "precision": 0.2,
                    "pseudo_jaccard": 0.09090909090909091,
                    "n_real": 7
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 2
                },
                {
                    "recall": 0.3333333333333333,
                    "precision": 0.2,
                    "pseudo_jaccard": 0.14285714285714285,
                    "n_real": 3
                }
            ]
        }
    },
    {
        "doc_id": "-spj8FZD4y2",
        "method": "gpt_independent_chunk",
        "reference_comments": [
            [
                "The paper lacks a complete theoretical analysis, such as the upper bound/lower bound on the regret of the algorithm.",
                "The algorithm should be explicitly written out with its pseudocode.",
                "The paper states that the communication is one-way from the decision-maker towards the controller, but it is strange not to consider the realization history observed by the decision-maker as communication. The goal of this work and how it differs from existing papers is unclear.",
                "The problem setup is unclear: it is not specified whether the state is i.i.d. sampled from the distribution $P_S$ or not.",
                "The relation between the constraint quantities $(\\rho,R)$ and the discussions in Section 3 is unclear.",
                "The constraints seem to be placed in the posterior probabilities involved in the TS algorithms. It is not clear what would happen if we consider UCB-class algorithms.",
                "The definitions of $D_\\alpha$ and reverse KL divergence $D_{KL}$ are missing. Usually, the original KL divergence is denoted by $D_{KL}$.",
                "In Section 3.3, it states ''If $S$ and $A$ are independent...'', which is not a common assumption in contextual bandits."
            ],
            [
                "There are inconsistencies and imprecisions in the writing, particularly in Section 2, which defines quantities, regrets, and gains that are not analyzed afterwards. Clarification is needed on the definitions and usage of G, \\rho, and R.",
                "The paper does not provide regret bounds. While it may be out of the scope of the paper, some commentary on this would be beneficial.",
                "The algorithm needs to be clearly outlined. While detailed explanations are provided, a pseudo-code would greatly improve readability and understanding.",
                "The paper could be better connected with existing literature on contextual bandit, such as contextual bandits with context uncertainties or Partially Observable MDPs."
            ],
            [
                "The results in the paper are largely adapted from known information-theoretic results, which limits the overall novelty of the work.",
                "The assumption that each agent's state is observed by the decision-maker, but not the agent itself, is unusual. The authors should clarify why they make this assumption.",
                "The practical coding scheme is about sending the state to the corresponding agent, which may not be necessary in practice.",
                "The controller 'decoder' function should have the joint states of all agents as an input to enhance the decoder design."
            ],
            [
                "The paper lacks theoretical performance guarantees for the clustering coding scheme. A characterization of how regret depends on the number of states, the rate constraint, number of actions, etc. would provide a more in depth understanding of the performances of the clustering scheme in various scenarios.",
                "The paper does not discuss how the proposed clustering schemes\u2019 performance decays as the total number of states grows. More states would induce larger clusters and hence larger distortion in the policy defined over the compressed states (compared to the target policy). This is particularly relevant as the paper uses personalized ad placements as a motivating example, where the content owner\u2019s valuation for a user view (i.e. impression) or conversion serves as the 'context' (or state), and may take a wide range of values."
            ]
        ],
        "generated_comments": {
            "all": [
                "To enhance the readability of the paper, consider subdividing dense sections into more manageable parts. Specifically, the 'Rate-Constrained CMAB' and 'The KL-Divergence as Distortion Function' sections could be divided into sub-sections, each focusing on a specific aspect or step of the process.",
                "The introduction would benefit from a more comprehensive explanation of the RC-CMAB problem. Providing a brief overview of key terms and concepts would help readers unfamiliar with the topic to better understand the context and significance of your work. This would also set a solid foundation for the subsequent sections.",
                "To illustrate the real-world relevance of your work, consider including more examples or case studies. This would help readers understand the practical implications and potential applications of your research.",
                "The explanation of the Thompson Sampling method and the implementation of the policy compression problem and the practical coding scheme could be expanded. Providing more details about these methods would help readers understand their role in your research and how they contribute to your results.",
                "To make the paper more accessible to non-experts, consider providing more detailed explanations or examples for each equation. This would help readers understand the mathematical basis of your work and how the equations contribute to your findings.",
                "Including more visual aids, such as diagrams or flowcharts, could help to illustrate your proposed method and the experimental setup. Visual aids can provide a quick overview of complex processes and help readers understand the flow of your work.",
                "Ensure that all figures and tables are included, correctly referenced in the text, and have clear, explanatory captions. This would help readers understand the data you are presenting and how it supports your findings.",
                "A results or evaluation section that demonstrates the effectiveness of your proposed solution would strengthen your paper. This could include comparisons with other methods, sensitivity analyses, or other relevant evaluations. This would provide concrete evidence of the effectiveness of your method and give readers a basis for comparison with other methods.",
                "A more detailed analysis of the experimental results would be beneficial. Discussing why certain methods performed better than others, and under what conditions the proposed method is expected to perform well or poorly, would provide a deeper understanding of your findings. This would also help readers understand the strengths and weaknesses of your method.",
                "A systematic comparison of the proposed method with other existing methods would strengthen your paper. Consider including a table that summarizes the performance of different methods on a set of benchmark problems. This would provide a clear, concise overview of how your method compares to others in the field.",
                "Discussing the limitations of your proposed method would provide a more balanced view of your work. This could also help to identify areas for future research. Acknowledging the limitations of your work shows that you have a thorough understanding of the field and are aware of the challenges that need to be addressed in future research.",
                "Ensure that all references are relevant and up-to-date. If there are any key pieces of literature that have been missed, including these could strengthen your arguments. References provide the context for your work and show how it builds on previous research.",
                "Providing more details about the experimental setup, including specific parameters used, the software and hardware used, and any other details necessary for another researcher to reproduce the experiments, would enhance the reproducibility of your work. This would also help other researchers build on your work in the future.",
                "Consider integrating the mathematical derivations in the annex section into the main body of the paper, or providing a clearer explanation of how they relate to the main content. This would help readers understand the mathematical basis of your work and how the derivations contribute to your findings."
            ]
        },
        "alignments": {
            "all": [
                {
                    "reference_id": 3,
                    "predicted_id": 9,
                    "relative_specificity": "more",
                    "relatedness": "high",
                    "pairwise_result": {
                        "relatedness": "high",
                        "relative_specificity": "more",
                        "same_meaning": true
                    },
                    "count": 2,
                    "score": 0.4,
                    "reference_comment": "The paper could be better connected with existing literature on contextual bandit, such as contextual bandits with context uncertainties or Partially Observable MDPs.",
                    "predicted_comment": "A systematic comparison of the proposed method with other existing methods would strengthen your paper. Consider including a table that summarizes the performance of different methods on a set of benchmark problems. This would provide a clear, concise overview of how your method compares to others in the field."
                }
            ]
        },
        "metrics": {
            "all": {
                "n_reference": 18,
                "n_generated": 14,
                "n_total_aligns": 1,
                "recall": 0.0625,
                "precision": 0.017857142857142856,
                "pseudo_jaccard": 0.014705882352941176,
                "specificity_more": 1.0,
                "specificity_less": 0.0,
                "specificity_same": 0.0
            }
        },
        "metrics_for_reviews": {
            "all": [
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 8
                },
                {
                    "recall": 0.25,
                    "precision": 0.07142857142857142,
                    "pseudo_jaccard": 0.058823529411764705,
                    "n_real": 4
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 4
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 2
                }
            ]
        }
    },
    {
        "doc_id": "7udZAsEzd60",
        "method": "gpt_independent_chunk",
        "reference_comments": [
            [
                "The implication of Theorem 4.2 is not fully understood. The size(rho, kappa) critically depends on r, the rank of the weight matrix W. But if we decompose W=UV, where U is d*r and V=r*k, it seems like the VC dimension of HANN is still higher than the number of effective parameters, dr+rk. In this case, what benefit do HANN have over ReLU and sigmoid networks?",
                "The role of the binary activation in HANN is unclear. The critical assumption of Theorem 4.2 is that the weight matrix is low-rank. In this case, can't the layer with low-rank weight be reformulated as two layers with a small bottleneck hidden layer of dimensionality r, which has much smaller number of parameters than the equivalent network? If this is the case, the result seems to be only relevant to the low-rank assumption, not the HANN itself."
            ],
            [
                "The title and introduction of the paper suggest that a more general class of Quantized Neural Networks (QNNs) have small VC dimension, but the model studied is essentially a two-layer NN. This raises doubts about whether any non-toy quantized models will have small VC dimension. An experiment similar to Zhang et al 2017 could easily verify this.",
                "The paper's focus on studying the VC dimension of Neural Networks (NNs) is questionable. The authors should clarify what we are aiming to learn from this, as in practice VC dimensions often provide non-meaningful bounds.",
                "The title and introduction of the paper may overstate the significance of the results, and the motivation for the study may not be strong enough."
            ],
            [
                "The bound on the VC dimension for hyperplane augmented neural networks (HANNs) seems quite large: O(k^r). This seems to be a major limitation in the application of the main result of the paper.",
                "The paper could significantly benefit from a discussion on the large bound on the VC dimension, either explaining more cases where the results are useful or clarifying this limitation.",
                "Using the numbers given in the experiments, with a dataset of size 77904 and k=100, and r=3 seems to result in vacuous bounds on generalization again, which questions the effectiveness of the main result."
            ]
        ],
        "generated_comments": {
            "all": [
                "The abstract could be improved by using simpler language and providing a more direct explanation of the main findings and their significance. This would help readers quickly understand the key contributions of your work.",
                "To make your paper more accessible to a broader audience, consider including a brief overview of Vapnik-Chervonenkis (VC) theory, as it is a central concept in your work.",
                "It would be beneficial to elaborate on why Hyperplane Arrangement Neural Networks (HANNs) were chosen as a solution to the generalization puzzle. Discuss how they differ from other potential solutions and why they are particularly suited to this problem.",
                "The paper would benefit from a more detailed presentation of the results from the tests on the panel of 121 UCI datasets. Include specific performance metrics, comparisons to other models, and any insights gained from these experiments to provide a comprehensive view of your empirical findings.",
                "A discussion on the limitations of the proposed approach would provide a more balanced view of the work. Additionally, suggesting directions for future research could stimulate further advancements in this area.",
                "The application of sample compression schemes in the context of HANNs is a complex concept. A more detailed explanation of this process and its effectiveness would be beneficial for readers.",
                "A section discussing the broader impact of your findings, including potential practical applications and implications for the field of machine learning, would provide valuable context for your work.",
                "Some readers may find the mathematical formulas and theorems challenging. Providing more detailed explanations and context could improve comprehension and engagement.",
                "A detailed comparison or discussion of how your work builds on or differs from previous studies would provide valuable context and demonstrate the novelty of your work.",
                "To improve the flow of the paper, consider adding a discussion or conclusion section that summarizes the theoretical findings and introduces the empirical results.",
                "More detailed descriptions of the datasets used and the specific methods applied in the empirical results section would provide valuable context. Consider adding tables or figures to visually represent the results.",
                "A brief introduction or background about the straight-through-estimator (SteSign) and the SwishSign heuristics would help readers understand their relevance and impact on the study.",
                "A more comprehensive discussion of the figures referred to in the text would help readers better understand the data and results.",
                "Providing insights into how you arrived at the specific values of the hyperparameter 'k' used in the experiments would help readers understand the rationale behind your experimental setup.",
                "In addition to making the code publicly available, please discuss the availability of the datasets used in the study to ensure full reproducibility.",
                "A comprehensive conclusion that summarizes the key findings, their implications, and potential future work would provide a valuable summary of your work.",
                "To improve readability, consider separating the sections of mathematical proofs and experimental details more distinctly and providing clear transitions to guide the reader.",
                "More details about the performance comparisons of HANN15 and HANN100, such as the specific metrics used and the statistical significance of the results, would provide a more comprehensive view of your findings.",
                "Providing more context about the references to the No-Free-Lunch Theorem and other cited works, and discussing how they relate to your findings, would enhance the discussion section.",
                "More details about the mentioned figures and tables, such as what they represent and how they support your conclusions, would enhance the reader's understanding.",
                "More details about the process of training HANN15 with a hyperparameter grid of size 3 where only the dropout rate is tuned, such as the specific values used in the grid and how they were chosen, would provide valuable context.",
                "More details about the process of calculating a smoothed validation accuracy, such as the specific formula used and why you chose to use a smoothed accuracy, would provide valuable context."
            ]
        },
        "alignments": {
            "all": []
        },
        "metrics": {
            "all": {
                "n_reference": 8,
                "n_generated": 22,
                "n_total_aligns": 0,
                "recall": 0.0,
                "precision": 0.0,
                "pseudo_jaccard": 0.0,
                "specificity_more": NaN,
                "specificity_less": NaN,
                "specificity_same": NaN
            }
        },
        "metrics_for_reviews": {
            "all": [
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 2
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 3
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 3
                }
            ]
        }
    },
    {
        "doc_id": "QmKblFEgQJ",
        "method": "gpt_independent_chunk",
        "reference_comments": [
            [
                "The empirical performance gains provided by the DIGRAC method are difficult to understand. In many of the ARI graphs on synthetic data, the performance of various methods seems quite close. In the real data, methods overlap in their error bars.",
                "More explanation is needed about when DIGRAC's model for clustering is appropriate for a dataset and when it is not, and how adaptive the model can be in terms of performance despite those considerations."
            ],
            [
                "The practicality of the problem and the method studied in this paper is questionable. The authors mention that 'real data sets with ground-truth flow imbalances are not available to date', so they use normalized imbalance scores to evaluate clustering performance. This approach seems to go against the typical order of how machine learning models are developed.",
                "The experiments in Section 4 do not demonstrate the practical importance of clustering with respect to flow imbalances. As this is an empirical paper, it is necessary to provide solid empirical evidence that showcases the need for clustering with respect to flow imbalances.",
                "The authors use 80% of all nodes for training in their empirical evaluations. This percentage seems too high and it is suggested to consider using a smaller percentage, such as 5%, of all nodes for training."
            ],
            [
                "The theoretical properties of the loss function defined in Eq. (2) and (3) are not clear. The paper should provide a theoretical characterization for this loss and discuss cases where it could lead to degenerate solutions.",
                "The constraints of the optimization problem need to be clearly presented.",
                "The paper should examine how the loss behaves in terms of convergence.",
                "The novelty of the DIMPA algorithm is unclear. The paper should clarify what are the novel parts of this model with respect to previous works.",
                "The baseline models used for comparison could be enhanced. The paper should consider adding models that capture information flow, including algorithms that rely on stochastic blockmodels and a model that is based on directed modularity.",
                "The paper lacks scalability experiments with the running time of the algorithm and its comparison to baseline models."
            ]
        ],
        "generated_comments": {
            "all": [
                "Expand on the explanation of the DIGRAC method and the 'SELF-SUPERVISED LOSS FOR CLUSTERING' method. Include a step-by-step walkthrough of the methods using a simple example. Specifically, clarify how the imbalance score is calculated and its role in the overall clustering process. Also, elucidate how the DIGRAC model constructs the input feature matrix using the eigenvectors of the Hermitian matrix.",
                "Each equation in the paper should be accompanied by a detailed explanation. This should include the meaning of each variable and how the equation contributes to the overall methodology.",
                "Add a section that directly compares DIGRAC to other methods for node clustering in directed networks. Use quantitative metrics to demonstrate the performance of DIGRAC. This should include a comprehensive comparison with other models or methods in the field, explaining the similarities and differences between the methods and why the proposed method is superior.",
                "Include a section that describes the experimental setup, the datasets used, and the results of the experiments. Provide more details about the synthetic and real-world datasets used, the specific metrics used to evaluate performance, and the rationale behind the choice of these metrics.",
                "Elaborate on the process of using seed nodes with a supervised loss function to enhance performance. Explain how the seed nodes are selected and how they contribute to the model's performance.",
                "Include a section that discusses the limitations of DIGRAC, such as situations where it might not perform well, or potential improvements that could be made in future work. Provide more specific plans or ideas for the mentioned future experiments, such as potential methodologies or resources you plan to use.",
                "Provide preliminary insights or hypotheses on how you plan to improve performance in the sparse regime.",
                "Discuss potential challenges and solutions for scaling up the model to extremely large networks.",
                "Consider including more visual aids, such as diagrams or flowcharts, to help explain the methodology.",
                "Provide detailed instructions for reproducing the experiments, including any necessary software or hardware requirements, and any parameters used in the experiments. Provide more details about the implementation of your method, including any hyperparameters used. If possible, also make your code and data available to the research community."
            ]
        },
        "alignments": {
            "all": [
                {
                    "reference_id": 1,
                    "predicted_id": 5,
                    "relative_specificity": "more",
                    "relatedness": "medium",
                    "pairwise_result": {
                        "relatedness": "medium",
                        "relative_specificity": "more",
                        "same_meaning": true
                    },
                    "count": 3,
                    "score": 0.6,
                    "reference_comment": "More explanation is needed about when DIGRAC's model for clustering is appropriate for a dataset and when it is not, and how adaptive the model can be in terms of performance despite those considerations.",
                    "predicted_comment": "Include a section that discusses the limitations of DIGRAC, such as situations where it might not perform well, or potential improvements that could be made in future work. Provide more specific plans or ideas for the mentioned future experiments, such as potential methodologies or resources you plan to use."
                },
                {
                    "reference_id": 5,
                    "predicted_id": 7,
                    "relative_specificity": "same",
                    "relatedness": "medium",
                    "pairwise_result": {
                        "relatedness": "medium",
                        "relative_specificity": "same",
                        "same_meaning": true
                    },
                    "count": 4,
                    "score": 0.8,
                    "reference_comment": "The paper lacks scalability experiments with the running time of the algorithm and its comparison to baseline models.",
                    "predicted_comment": "Discuss potential challenges and solutions for scaling up the model to extremely large networks."
                }
            ]
        },
        "metrics": {
            "all": {
                "n_reference": 11,
                "n_generated": 10,
                "n_total_aligns": 2,
                "recall": 0.2222222222222222,
                "precision": 0.06666666666666667,
                "pseudo_jaccard": 0.05252525252525253,
                "specificity_more": 0.5,
                "specificity_less": 0.0,
                "specificity_same": 0.5
            }
        },
        "metrics_for_reviews": {
            "all": [
                {
                    "recall": 0.5,
                    "precision": 0.1,
                    "pseudo_jaccard": 0.09090909090909091,
                    "n_real": 2
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 3
                },
                {
                    "recall": 0.16666666666666666,
                    "precision": 0.1,
                    "pseudo_jaccard": 0.06666666666666667,
                    "n_real": 6
                }
            ]
        }
    },
    {
        "doc_id": "b-ny3x071E5",
        "method": "gpt_independent_chunk",
        "reference_comments": [
            [
                "The name 'matching function' makes the presentation of the method a little bit harder to digest. Since the function is a pseudometric (i.e., the larger it is, the larger the distance from the target), it should really be called with a name that reminds the reader of this nature (e.g., 'mismatch function').",
                "The theoretical results only deal with targets of specific forms and, especially, with $L=1$ only. Ideally, theoretical result with a dependency on $L$ would shed some light on the benefits and limitations of longer bootstrapping horizons.",
                "The connection between the way the bootstrapping target is formed in the method and traditional temporal difference learning needs to be elaborated on. In particular, the grounding role of that subtracted gradient 'nudging the trajectory in a descent direction' is the same as the one of the reward in temporal difference learning; but, while the reward is at the beginning of the trajectory, the grounding is here at the end of the optimization subtrajectory. Is there any mathematical connection beyond the general shared motivation?",
                "When the underlying function is highly nonlinear, there is the risk that the bootstrapping mechanism can lead the optimization process in worse areas of the landscape. For instance, if the function in Figure 1 had a bump/plateaux where $\tilde w$ is, the bootstrapping mechanism would cause more troubles than standard meta-gradients. Why is this not happening in practice?"
            ],
            [
                "The algorithm description in section 3 is very abstract. The paper would benefit from a running example and a dedicated section and pseudo-code describing the algorithm and how it can be instantiated in different experimental settings.",
                "The theoretical analysis is limited to noiseless 1-step target updates.",
                "The experimental evaluation in the multi-task meta-learning setting is limited to only compare with MAML on computer vision applications.",
                "Some engineering / handcrafting is still required by the machine learning practitioner to select what 'target' the meta-learner is going to optimize, as well as the proper 'metric' for the meta-learner to optimize for. Could the authors comment a bit about what heuristics they used when making these decisions? and whether the automation for this process is possible or not?",
                "What would it take to extend the analysis beyond 1-step noiseless target updates?",
                "How does the performance of BMG compare to alternative meta-learning algorithms like R2D2, Meta-OPT-net and prototypical networks? Have the authors experimented with other meta-learning benchmarks beyond image classification?"
            ],
            [
                "Given that you say BMG is compatible with any update function (so long as it is differentiable in the meta-parameters), it would be nice to have some experiments on learned sequence model update rules (e.g. RNN). All current experiments use update rules with a fixed functional form.",
                "I am not putting much weight on section 4 ('Performance Guarantees') given the gap between its assumptions and results vs. what is actually implemented, and the restriction to local optimization."
            ],
            [
                "The paper could benefit from more detailed discussions in certain areas to improve clarity and understanding.",
                "The methodologies of the experiments are difficult to follow, making it hard to link the results back to intuition or interpretation. More detailed descriptions or an algorithm box in the main text could help address this.",
                "The implementation and implications of the experiment on multi-task few-shot learning (Sec 6) are unclear. The authors should clarify the intuition of why a 'hot' expert transforms more information than a 'cold' expert, and why BMG is able to use this to improve performance.",
                "The training procedure for BMG in the multi-task few-shot learning experiment should be formally described in the main text.",
                "The analysis presented in Sec 4 ('Performance Guarantees') is not especially insightful. The conclusion drawn from this section is evident from the experiments themselves."
            ]
        ],
        "generated_comments": {
            "all": [
                "The introduction would benefit from a more comprehensive background, including a clear statement of the problem, the significance of the study, and a brief overview of the existing literature. Additionally, a brief summary of the paper's contributions at the end of the introduction would guide the reader through the paper.",
                "The paper could be revised for clarity and structure. Some sections are dense and could benefit from simpler language or more context. A brief summary of the results at the beginning of each section would help the reader understand the context and significance of the detailed results that follow.",
                "The methodologies used, particularly the Bootstrapped Meta-Gradient (BMG) method, the Actor-Critic and Q-Learning experiments, and the standard convolutional model, could be explained in more detail. A simplified, intuitive explanation or a visual representation of the methods would help readers understand the concept better. Also, the reasons for choosing these specific methods and how they contribute to the overall aim of the study could be elaborated.",
                "A detailed comparison with other meta-learning methods, specifically in terms of computational efficiency, scalability, and robustness, would be beneficial. A detailed comparison of BMG and MG performance against other state-of-the-art methods in the field would provide a comprehensive understanding of the proposed method's strengths and weaknesses.",
                "The performance guarantees mentioned could be explained in more detail, including under what conditions they hold. This would provide a clearer understanding of the robustness and reliability of the proposed method.",
                "The experiments on the Atari ALE benchmark could be described in more detail, such as the specific games tested, the number of trials run, and the comparison with previous state-of-the-art methods. More details about the experimental setup, including specific parameters and any software or tools used, would ensure the reproducibility of the study. Also, more information on the statistical tests used to determine the significance of the results, including the specific p-values obtained, would provide a more comprehensive understanding of the results.",
                "The results section could be enhanced with more visual aids, such as graphs or charts, to illustrate the findings. Clear and concise captions for all figures and tables, explaining what the figure or table shows and how it contributes to the overall aim of the study, would be beneficial.",
                "A more comprehensive discussion of the results obtained from the experiments, including a comparison with other similar studies, an explanation of why the results are significant, and a discussion of any unexpected findings, would provide a more complete understanding of the study's findings. The implications of the results for the field of study could also be discussed in more detail.",
                "A discussion on why certain aspects were not covered in this paper and how they could be addressed in future work would be beneficial. A section on potential future work, including suggestions for how the methods used in this study could be improved or adapted for other applications, and any questions or issues that arose during the study that could be addressed in future research, would provide a roadmap for future studies.",
                "A discussion on potential real-world applications of the proposed method would help readers understand the practical implications and potential impact of the work.",
                "Ensure all references are correctly cited and relevant to the study. Check for missing or incorrectly cited references. Ensure that all references are correctly cited and formatted according to the appropriate style guide.",
                "The paper should be written in clear and concise language, free from grammatical errors and jargon. Please proofread the paper carefully to correct typographical errors.",
                "The proofs could be explained in a more intuitive manner, perhaps with the aid of diagrams or examples, to make them more accessible to readers.",
                "Consider including a glossary or brief explanations of specific terminology used in the text to make the paper more accessible to readers from other disciplines.",
                "To ensure reproducibility, consider providing the code used for the experiments or at least a more detailed description of the implementation details."
            ]
        },
        "alignments": {
            "all": [
                {
                    "reference_id": 2,
                    "predicted_id": 3,
                    "relative_specificity": "more",
                    "relatedness": "high",
                    "pairwise_result": {
                        "relatedness": "high",
                        "relative_specificity": "more",
                        "same_meaning": true
                    },
                    "count": 3,
                    "score": 0.6,
                    "reference_comment": "The experimental evaluation in the multi-task meta-learning setting is limited to only compare with MAML on computer vision applications.",
                    "predicted_comment": "A detailed comparison with other meta-learning methods, specifically in terms of computational efficiency, scalability, and robustness, would be beneficial. A detailed comparison of BMG and MG performance against other state-of-the-art methods in the field would provide a comprehensive understanding of the proposed method's strengths and weaknesses."
                },
                {
                    "reference_id": 5,
                    "predicted_id": 3,
                    "relative_specificity": "more",
                    "relatedness": "medium",
                    "pairwise_result": {
                        "relatedness": "medium",
                        "relative_specificity": "more",
                        "same_meaning": true
                    },
                    "count": 3,
                    "score": 0.6,
                    "reference_comment": "How does the performance of BMG compare to alternative meta-learning algorithms like R2D2, Meta-OPT-net and prototypical networks? Have the authors experimented with other meta-learning benchmarks beyond image classification?",
                    "predicted_comment": "A detailed comparison with other meta-learning methods, specifically in terms of computational efficiency, scalability, and robustness, would be beneficial. A detailed comparison of BMG and MG performance against other state-of-the-art methods in the field would provide a comprehensive understanding of the proposed method's strengths and weaknesses."
                },
                {
                    "reference_id": 1,
                    "predicted_id": 4,
                    "relative_specificity": "same",
                    "relatedness": "medium",
                    "pairwise_result": {
                        "relatedness": "medium",
                        "relative_specificity": "same",
                        "same_meaning": true
                    },
                    "count": 2,
                    "score": 0.4,
                    "reference_comment": "The theoretical analysis is limited to noiseless 1-step target updates.",
                    "predicted_comment": "The performance guarantees mentioned could be explained in more detail, including under what conditions they hold. This would provide a clearer understanding of the robustness and reliability of the proposed method."
                },
                {
                    "reference_id": 0,
                    "predicted_id": 1,
                    "relative_specificity": "more",
                    "relatedness": "high",
                    "pairwise_result": {
                        "relatedness": "high",
                        "relative_specificity": "more",
                        "same_meaning": true
                    },
                    "count": 5,
                    "score": 1.0,
                    "reference_comment": "The paper could benefit from more detailed discussions in certain areas to improve clarity and understanding.",
                    "predicted_comment": "The paper could be revised for clarity and structure. Some sections are dense and could benefit from simpler language or more context. A brief summary of the results at the beginning of each section would help the reader understand the context and significance of the detailed results that follow."
                },
                {
                    "reference_id": 1,
                    "predicted_id": 5,
                    "relative_specificity": "more",
                    "relatedness": "high",
                    "pairwise_result": {
                        "relatedness": "high",
                        "relative_specificity": "more",
                        "same_meaning": true
                    },
                    "count": 2,
                    "score": 0.4,
                    "reference_comment": "The methodologies of the experiments are difficult to follow, making it hard to link the results back to intuition or interpretation. More detailed descriptions or an algorithm box in the main text could help address this.",
                    "predicted_comment": "The experiments on the Atari ALE benchmark could be described in more detail, such as the specific games tested, the number of trials run, and the comparison with previous state-of-the-art methods. More details about the experimental setup, including specific parameters and any software or tools used, would ensure the reproducibility of the study. Also, more information on the statistical tests used to determine the significance of the results, including the specific p-values obtained, would provide a more comprehensive understanding of the results."
                },
                {
                    "reference_id": 1,
                    "predicted_id": 2,
                    "relative_specificity": "more",
                    "relatedness": "high",
                    "pairwise_result": {
                        "relatedness": "high",
                        "relative_specificity": "more",
                        "same_meaning": true
                    },
                    "count": 2,
                    "score": 0.4,
                    "reference_comment": "The methodologies of the experiments are difficult to follow, making it hard to link the results back to intuition or interpretation. More detailed descriptions or an algorithm box in the main text could help address this.",
                    "predicted_comment": "The methodologies used, particularly the Bootstrapped Meta-Gradient (BMG) method, the Actor-Critic and Q-Learning experiments, and the standard convolutional model, could be explained in more detail. A simplified, intuitive explanation or a visual representation of the methods would help readers understand the concept better. Also, the reasons for choosing these specific methods and how they contribute to the overall aim of the study could be elaborated."
                }
            ]
        },
        "metrics": {
            "all": {
                "n_reference": 17,
                "n_generated": 15,
                "n_total_aligns": 6,
                "recall": 0.225,
                "precision": 0.08333333333333334,
                "pseudo_jaccard": 0.0694980694980695,
                "specificity_more": 0.8333333333333334,
                "specificity_less": 0.0,
                "specificity_same": 0.16666666666666666
            }
        },
        "metrics_for_reviews": {
            "all": [
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 4
                },
                {
                    "recall": 0.5,
                    "precision": 0.13333333333333333,
                    "pseudo_jaccard": 0.13513513513513514,
                    "n_real": 6
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 2
                },
                {
                    "recall": 0.4,
                    "precision": 0.2,
                    "pseudo_jaccard": 0.14285714285714285,
                    "n_real": 5
                }
            ]
        }
    },
    {
        "doc_id": "uB12zutkXJR",
        "method": "gpt_independent_chunk",
        "reference_comments": [
            [
                "The paper does not convincingly demonstrate model novelty or significant improvement to the state-of-the-art on the provided baseline.",
                "The model architecture seems very closely based on the HOPPITY baseline, with the primary change being to the multi-head graph encoder. This does not introduce a fundamentally new idea.",
                "Quantitative evaluations show only marginal improvement at best in comparison to the large pre-trained models.",
                "The evaluation omits a comparison to the closely related Yao 2021 model that is cited throughout the paper.",
                "The pre-training regime, which is presented as a contribution of this paper, does not seem to produce markedly stronger results. It might be valid to apply the same pre-training regime to some of the other models for a fair comparison.",
                "The qualitative evaluation does not yield clear conclusions. It would be beneficial to provide evidence that 'GRAPHIX demonstrates strong inductive biases in learning complex bug-fix patterns' or some conclusion on the kinds of bugs that GRAPHIX tends to fix.",
                "The pre-training regime is not particularly novel. The authors suggest deleting elements of subtrees from existing code and reconstructing them, which is not sufficiently novel."
            ],
            [
                "The paper does not clearly explain the relevance of the presented work despite not beating the state of the art. A discussion on this topic is missing.",
                "The anecdotal examples are not compared to the results other approaches give, making it unclear what to make of them.",
                "The claim that the model is more than 10x smaller than 'current large scale sequence models' is misleading as only one of the evaluated baselines, 'BART', is that much larger. The presented approach is even outperformed by CodeT5-small, which is less than 2x as large.",
                "The paper lacks a discussion on the accuracy of detecting bug fixes by filtering for 'fix', 'bug', 'error', and 'exception'.",
                "The reasoning behind having exactly 600 nodes is not explained."
            ],
            [
                "The pre-training task, while claimed to be novel, is not particularly innovative. It involves 'masking sub-trees' on AST, which essentially asks the model to do 'missing code prediction', covering only a small subset of general program repair samples. The pre-training task could be more innovative if more thought was put into generating the pre-training dataset, such as how to generate data for pre-training other edits like copy, remove, and update.",
                "Pre-training is costly and does not provide a significant performance gain (<2%). This issue is more pronounced with medium-sized data. The reviewer suggests two questions for consideration: 1) Why is pre-training only done on 'sub-trees between 2 and 6 descendants'? Could the size be increased to cover longer edit sequences during pre-training? Is it possible to add such an experiment? 2) Could the lack of performance gain be due to the pre-training task only asking the model to predict a sequence of addition operations? Could more diverse tasks be added to allow the model to predict a variety of edits?",
                "The multi-head graph encoder does not seem particularly novel.",
                "The paper does not mention related works such as 'TFix: Learning to Fix Coding Errors with a Text-to-Text Transformer' and 'Learning semantic program embeddings with graph interval neural network'.",
                "The last paragraph in Section 4.1 mentions a single-head 'base' model, which is not mentioned in any experiment in the main paper. The reviewer suggests moving this description into the Appendix or including the 'base' model and its performance in Table 1/2.",
                "In Listing 2 Top, the code is not valid if the highlighted green part is removed. The reviewer asks for clarification on the before and after of that code snippet.",
                "The paper claims 'these observations suggest that the code abstraction may not be necessary'. The reviewer finds this argument weak and disagrees with the initial premise that 'code abstraction is necessary'."
            ],
            [
                "The paper lacks a comprehensive comparison with prior work, making the contributions over previous work hard to assess.",
                "The efficacy of the proposed multihead Graph Neural Network (GNN) scheme is not adequately ablated. The paper needs to include ablations with models of the same size.",
                "There are concerns about the scalability of the model given the need to encode the entire tree at each intermediate step.",
                "The paper needs to provide equal comparisons of Hoppity and one or more deeper non-multihead Graphix models in the 32M parameter domain.",
                "The contribution of pretraining seems quite slim; performance only increases a little on the Small dataset and actually decreases on the Medium data. This needs more analysis.",
                "The paper needs to analyze and discuss the potential scalability problems of reinstantiating and encoding the program graph on every edit, especially on longer chains of edits.",
                "The paper needs to clarify whether the ensemble-of-graphs model is meant to be a contribution in general or just for source code.",
                "The paper needs to provide a more detailed analysis of the ASDL-guided decoder, especially in comparison with a small instantiation of Hoppity."
            ]
        ],
        "generated_comments": {
            "all": [
                "To enhance the readability of the paper, consider providing a high-level overview of the GRAPHIX model before delving into the technical details. This will make the paper more accessible to a broader audience, including those who may not be experts in the field. Additionally, some sentences could be rephrased for better clarity and comprehension. For example, the explanation of the multi-head architecture in paragraph 48 could be simplified.",
                "The paper would benefit from a more explicit, step-by-step breakdown of the GRAPHIX model's operation. This should include a detailed explanation of the multi-head architecture and the grammar-based tree decoder. Providing this level of detail will not only help readers better understand the process but also facilitate replication of the work. For instance, the explanation of the LSTM-based tree decoder in paragraph 66 could be expanded to include more details about the LSTM's operation and its role in the model.",
                "The paper should provide a more detailed comparison with other models such as CodeBERT, BART, and LSTM. This comparison should discuss why and how GRAPHIX performs better, including the specific strengths and weaknesses of each model. This will provide a more comprehensive understanding of the model's performance relative to existing methods. For example, the comparison with HOPPITY in paragraph 54 could be expanded to include more models and a more detailed analysis of the differences in performance.",
                "The inclusion of more visual aids, such as diagrams, flowcharts, graphs, or charts, would greatly enhance the paper. These could illustrate the operation of the GRAPHIX model, the pre-training strategy, and the results and comparisons with other models. Visual aids can significantly improve reader comprehension of complex concepts and results. For instance, a flowchart illustrating the operation of the GRAPHIX model would be particularly helpful.",
                "The paper should include a more explicit discussion of the limitations of the GRAPHIX model and potential areas for future work. Additional experiments, such as testing the model on different datasets or using different pre-training techniques, could further validate the model. Discussing potential solutions or improvements to address issues like incorrect fixes suggested by GRAPHIX, as mentioned in paragraph 68, would also be beneficial.",
                "The paper could provide more examples of real-world applications of the GRAPHIX model. A thorough discussion of the practical implications and potential applications of your research will help to demonstrate the practical value of the research and its potential impact on the field of automated program repair. For example, the paper could discuss how GRAPHIX could be used in software development and maintenance.",
                "Please clarify whether the data and the code for the GRAPHIX model used in the study will be made available to other researchers. This would facilitate replication of the study and further research in this area. If the data and code are not available, please provide a justification.",
                "More details about the performance metrics used to evaluate the GRAPHIX model would be helpful. This would allow readers to better understand the results and how they compare to those of other models. For example, the paper could provide more information about how the accuracy metric was calculated and why it was chosen as the primary performance metric.",
                "Please ensure that all references are correctly cited and formatted. There are some references that are not properly formatted, which could lead to confusion or difficulty in locating the original sources. For example, the references in paragraph 61 could be formatted according to the citation style of the journal.",
                "The equations mentioned in paragraphs 47 and 48 need more context. Providing the actual equations or a detailed explanation will help readers understand the mathematical basis of the model. For example, the paper could provide a detailed explanation of the equations used to calculate the network weights and the node embeddings."
            ]
        },
        "alignments": {
            "all": [
                {
                    "reference_id": 0,
                    "predicted_id": 2,
                    "relative_specificity": "more",
                    "relatedness": "high",
                    "pairwise_result": {
                        "relatedness": "high",
                        "relative_specificity": "more",
                        "same_meaning": true
                    },
                    "count": 4,
                    "score": 0.8,
                    "reference_comment": "The paper lacks a comprehensive comparison with prior work, making the contributions over previous work hard to assess.",
                    "predicted_comment": "The paper should provide a more detailed comparison with other models such as CodeBERT, BART, and LSTM. This comparison should discuss why and how GRAPHIX performs better, including the specific strengths and weaknesses of each model. This will provide a more comprehensive understanding of the model's performance relative to existing methods. For example, the comparison with HOPPITY in paragraph 54 could be expanded to include more models and a more detailed analysis of the differences in performance."
                }
            ]
        },
        "metrics": {
            "all": {
                "n_reference": 27,
                "n_generated": 10,
                "n_total_aligns": 1,
                "recall": 0.03125,
                "precision": 0.025,
                "pseudo_jaccard": 0.014705882352941176,
                "specificity_more": 1.0,
                "specificity_less": 0.0,
                "specificity_same": 0.0
            }
        },
        "metrics_for_reviews": {
            "all": [
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 7
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 5
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 7
                },
                {
                    "recall": 0.125,
                    "precision": 0.1,
                    "pseudo_jaccard": 0.058823529411764705,
                    "n_real": 8
                }
            ]
        }
    },
    {
        "doc_id": "nLb60uXd6Np",
        "method": "gpt_independent_chunk",
        "reference_comments": [
            [
                "The quantitative results are good, but not revolutionary. The model does well on the crystal classification task, but this setting is described as 'not difficult'. It performs slightly worse than GemNet on molecular force regression. On the backmapping task, it is only compared against a naive transformer, as opposed to another rotation invariant model. Another instance of the proposed model outperforming a strong baseline on a difficult task would significantly improve the case the paper is making.",
                "While one of the advantages of the proposed method is scaling to arbitrary rank, the experiments are all limited to pairwise attention (not counting the current key element). It would be interesting to demonstrate the effect of scaling up the rank, especially as this is noted as a potential advantage of the GemNet baseline.",
                "Group representation-based approaches have not been compared against."
            ],
            [
                "The details of the four functions that make up the attention mechanism are vague. More elaboration on the technical details, such as what are rotation-invariant geometric quantities for tuples, is needed to improve readability.",
                "The paper lacks a mathematical proof of rotational equivariance.",
                "The paper does not provide information on the efficiency of the proposed method, especially when compared with other works.",
                "The paper does not include experiments testing rotation equivariance. It is recommended to have an experimental test for the rotation equivariance by comparing with other works, such as rotation equivariance achieved via data augmentation.",
                "The paper does not clarify whether the proposed method can be extended to larger point clouds. It is also unclear what the definition of 'small point clouds' is. An experiment on 3D point cloud classification, such as the popularly used Modelnet 40, is recommended."
            ],
            [
                "In Table 1, the proposed model performs worse than the baseline GemNet-Q. The authors should consider adjusting their method to incorporate properties such as the use of quadruplets atoms, the incorporation of energy, or a better architecture, in order to perform a fair comparison with this baseline."
            ],
            [
                "The authors do not clearly describe how the geometric product helps to achieve the rotation-invariant attributes. This should be explained in the main manuscript since this is one of the main contributions.",
                "Geometric products do not appear in both model architectures and appendix B. The authors need to explicitly describe how it is implemented.",
                "The interpretation of the linear combination in geometric algebra is not trivial. The paper lacks the interpretation, justification, and discussion about the attention mechanism in geometric algebra.",
                "The proposed architecture is limited to 'small point clouds' without clear explanation. If the statement about the computational complexity is the reason, the connection to it should be clarified.",
                "The authors defined four functions, V, M, J, and S. However, another function R is defined later. Why do the authors distinguish R from the others? Are the four functions cover everything sufficiently? Justification is required.",
                "The authors stated that GemNets can operate on quadruplets of atoms but the proposed network worked only in pairs of bonds from the central atom. If this is the limitation of the proposed network, clear statement and discussion are required. Moreover, a discussion is appreciated whether the proposed network has technical difficulties to include the force label."
            ]
        ],
        "generated_comments": {
            "all": [
                "The abstract could be simplified to provide a more straightforward explanation of the main contributions of the paper. This would help readers quickly understand the key points of your research. For instance, you could break down the main contributions into bullet points for easier comprehension.",
                "It would be beneficial to include a brief introduction or a simplified explanation of geometric algebra. This would make the paper more accessible to readers who are not familiar with this concept. You could also include a few references for readers who wish to delve deeper into this topic.",
                "Please provide more justification for the choice of geometric algebra and attention mechanisms. Discussing the advantages of this approach over other potential methods would strengthen your argument. For instance, you could discuss how these methods improve the interpretability of the models or enhance their performance on the tasks at hand.",
                "A more detailed comparison of your work with existing methods would be beneficial. Discussing the strengths and weaknesses of your approach and why it is preferable would provide a more comprehensive understanding of your research. This could include a comparison table summarizing the key differences between your method and existing ones.",
                "More detailed presentation of the experimental results would be beneficial. Providing more information about the datasets used, the experimental setup, and the evaluation metrics would give a more comprehensive view of your research. Also, comparing your results with state-of-the-art methods would provide a benchmark for your work. This could be presented in the form of tables or graphs for easier comprehension.",
                "Consider conducting additional experiments on other scientific problems involving complex geometric data. This would further validate the versatility and robustness of the proposed models. For instance, you could test the models on datasets from different scientific disciplines or with different types of geometric data.",
                "Elaborating more on the interpretability aspect of the geometric algebra attention scheme would be beneficial. Providing examples of how this interpretability has helped in gaining insights from the trained models would strengthen your argument. This could include case studies or specific examples from your experiments.",
                "Including additional performance metrics such as precision, recall, and F1-score would provide a more comprehensive evaluation of the models. This would give readers a more complete understanding of the models' performance across different aspects.",
                "Making the Python code available on a public repository, such as GitHub, would facilitate reproducibility and further development of your work. This would also allow other researchers to build upon your work and potentially improve the models.",
                "Including a discussion on the limitations of the proposed method and the potential challenges encountered during the study would provide a more balanced view and suggest directions for future work. This could include limitations related to the model architectures, the datasets used, or the evaluation metrics.",
                "Discussing potential future directions for this research in the conclusion section would be beneficial. This could include possible improvements to the models, new applications, or plans to integrate these models with other machine learning techniques.",
                "Including more visual aids, such as diagrams or flowcharts, would help explain the proposed method and the experimental setup. This would make the paper more engaging and easier to understand, especially for readers who are not familiar with the technical details of the methods.",
                "Providing a brief description or context for the PDB entries used in the coarse-graining task would help readers understand their relevance to the study. This could include information about the proteins these entries represent and why they were chosen for this study.",
                "In the discussion of symmetry of functions and operations, consider providing a practical example or illustration to aid reader comprehension. This could include a diagram or a case study from your experiments.",
                "Elaborate on why the potential extensions mentioned were not explored in the current study and how they could potentially improve the results. This could include a discussion of the potential benefits and challenges of these extensions, and how they could be implemented in future work.",
                "Provide more details on the architecture that generates output distributions, and explain why it would be better suited for systems at nonzero temperature. This could include a discussion of the benefits of this architecture and how it improves the performance of the models.",
                "Justify the choice of using the training set error to characterize model performance, and discuss any potential limitations of this approach. This could include a discussion of how this metric reflects the models' performance and why it was chosen over other potential metrics.",
                "In the discussion of the properties of multivectors, consider providing a more detailed explanation or example to help readers understand these concepts. This could include a diagram or a step-by-step explanation of these properties."
            ]
        },
        "alignments": {
            "all": [
                {
                    "reference_id": 2,
                    "predicted_id": 3,
                    "relative_specificity": "more",
                    "relatedness": "high",
                    "pairwise_result": {
                        "relatedness": "high",
                        "relative_specificity": "more",
                        "same_meaning": true
                    },
                    "count": 3,
                    "score": 0.6,
                    "reference_comment": "The paper does not provide information on the efficiency of the proposed method, especially when compared with other works.",
                    "predicted_comment": "A more detailed comparison of your work with existing methods would be beneficial. Discussing the strengths and weaknesses of your approach and why it is preferable would provide a more comprehensive understanding of your research. This could include a comparison table summarizing the key differences between your method and existing ones."
                },
                {
                    "reference_id": 2,
                    "predicted_id": 6,
                    "relative_specificity": "more",
                    "relatedness": "high",
                    "pairwise_result": {
                        "relatedness": "high",
                        "relative_specificity": "more",
                        "same_meaning": true
                    },
                    "count": 3,
                    "score": 0.6,
                    "reference_comment": "The interpretation of the linear combination in geometric algebra is not trivial. The paper lacks the interpretation, justification, and discussion about the attention mechanism in geometric algebra.",
                    "predicted_comment": "Elaborating more on the interpretability aspect of the geometric algebra attention scheme would be beneficial. Providing examples of how this interpretability has helped in gaining insights from the trained models would strengthen your argument. This could include case studies or specific examples from your experiments."
                }
            ]
        },
        "metrics": {
            "all": {
                "n_reference": 15,
                "n_generated": 18,
                "n_total_aligns": 2,
                "recall": 0.09166666666666667,
                "precision": 0.027777777777777776,
                "pseudo_jaccard": 0.022233201581027668,
                "specificity_more": 1.0,
                "specificity_less": 0.0,
                "specificity_same": 0.0
            }
        },
        "metrics_for_reviews": {
            "all": [
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 3
                },
                {
                    "recall": 0.2,
                    "precision": 0.05555555555555555,
                    "pseudo_jaccard": 0.045454545454545456,
                    "n_real": 5
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 1
                },
                {
                    "recall": 0.16666666666666666,
                    "precision": 0.05555555555555555,
                    "pseudo_jaccard": 0.043478260869565216,
                    "n_real": 6
                }
            ]
        }
    },
    {
        "doc_id": "cVak2hs06z",
        "method": "gpt_independent_chunk",
        "reference_comments": [
            [
                "The motivation for CnC is centered on the class-conditional alignment loss. There is even a bound on the worst-group loss in terms of the average-group and class-conditional alignment loss. So why not replace step 2, and instead fine-tune the model using L_avg_group + L_alignment? Or even just train models from scratch with this loss. It would be good to compare to these. If CnC is simply more empirically successful than this alternative, then it would be good to see this.",
                "In a related vein to the previous question, how much is CnC buying us as compared to the usual supervised contrastive training? It would be good to see SupCon as a baseline in Table 1. This seems an important baseline, since the main idea of CnC is to pull items from the same class together in feature space, which is also done using SupCon.  The main (even only?) difference is the hard positive/negative sampling approach of CnC."
            ],
            [
                "The observation of aligning representation for improving model robustness is not novel. There are a lot of work with similar ideas in domain generalization/adaptation literature, e.g., [1], [2]. There\u2019s also a recent work [3] that applies contrastive learning for doing so. A more comprehensive discussion for these related work needs to be included.",
                "The assumption of Theorem 3.1 is not well explained and motivated. In particular, the assumption that \u201cthe loss function l(x; y) is 1-Lipschitz in x and bounded from above by one.\u201d seems to be necessary and simplify the proof a lot, but does not hold for typical losses like cross-entropy for classification and MSE for regression.",
                "Using ERM prediction as the group label is not convincing enough, and it is not clear how it would affect the contrastive part. It could be interesting to more extensively analyze how the label prediction affects the improvement given by the contrastive method, probably using a scientific setup where the label prediction is controlled.",
                "For the contrastive part, the current empirical comparison obfuscates the advantage on its own. To decouple it from the effect of wrong group prediction, it is important to compare in the setting where group labels are available, i.e., GDRO vs GDRO + contrastive. Also, there could be a lot of choices of negative selections but only one is used without sufficient explanations, it would be great to include more explanation or compare with some other possible choices as an ablation study.",
                "Though the proposed contrastive method leads to improved worst-group performance, it seems to decrease the average-case performance compared to baselines."
            ],
            [
                "The proof provided in the paper may not be intuitively useful, particularly due to the bound B on the weight matrix. The weight matrix and the representations are learned jointly, and equivalent predictions could be achieved by scaling the weight matrix down and the representations up. Additionally, the Lipschitz and boundedness constraints on the loss functions do not seem to apply in any of the settings explored experimentally.",
                "Section 5.2 is unclear, particularly regarding the role of ERM 'predicting the sensitive attribute'. It is not clear how ERM's predictions of the sensitive attribute play into the CNC algorithm.",
                "Some important training details, such as the clustering-based prediction from the first step ERM model, are buried in the appendix. These details seem crucial to the functioning of the method and should be discussed in the main body, possibly with an ablation study."
            ]
        ],
        "generated_comments": {
            "all": [
                "Consider expanding the explanation of the Correct-N-Contrast (CNC) method. A step-by-step walkthrough or a flowchart could be beneficial for readers to understand the process. Discuss the underlying principles and motivations behind the method to provide context and justification for your approach.",
                "Include a section or appendix that clearly defines all the mathematical notations used in the paper. This will ensure that readers can follow your methodology and results without confusion.",
                "The theoretical analysis of the alignment loss could be simplified or supplemented with a more intuitive explanation. This will help readers who are less familiar with the specific concepts involved to understand your work.",
                "The paper mentions Theorem 3.1 but does not provide a clear statement or proof. Please include a section that clearly states and proves this theorem.",
                "Expand on the description of the four spurious correlation benchmarks used for evaluating CNC. Include their names, the nature of the data they contain, and the reasons for their selection. This will help readers understand the context and relevance of your results.",
                "The paper could benefit from a more detailed discussion on the sensitivity analysis of CNC's robustness to noisy ERM predictions. This will provide readers with a better understanding of the robustness and reliability of your method.",
                "Include a more comprehensive comparison of CNC with other methods like ERM and GDRO. Discuss the strengths and weaknesses of each method in relation to CNC. This will help readers understand the unique contributions of your work.",
                "Provide more details on the training setup, contrastive batch sampling, and pseudocode for CNC's implementation. This will help readers replicate your work and understand the practical aspects of implementing CNC.",
                "Expand on the discussion of the results, explaining why CNC performs better and what specific features of CNC contribute to this improvement. This will help readers understand the implications of your findings.",
                "Include a section discussing the limitations of the CNC method and potential areas for future research. This will provide a balanced view of your work and guide future research in this area.",
                "Discuss the practical implications of the research, including potential real-world applications of CNC and its potential impact on the field of machine learning. This will help readers understand the broader relevance of your work.",
                "Discuss any challenges or considerations related to the reproducibility of the results, including any specific software or hardware requirements. This will help other researchers who wish to replicate or build upon your work.",
                "The paper mentions GradCAM visualizations but does not include them. Including these visualizations will help readers better understand the results and the impact of your method.",
                "Provide a more detailed explanation of the assumptions made in your work, such as | (z, y) \u2212 (z , y)| \u2264 z \u2212 z 2, and why they are necessary for your research. This will help readers understand the theoretical underpinnings of your work.",
                "Consider conducting additional experiments on more datasets or under different conditions to further validate the robustness of your approach. This will strengthen your results and provide a more comprehensive evaluation of CNC.",
                "Provide a more detailed explanation of how the estimated mutual information is calculated and why it is a suitable metric for this study. This will help readers understand the rationale behind your choice of metrics."
            ]
        },
        "alignments": {
            "all": [
                {
                    "reference_id": 1,
                    "predicted_id": 13,
                    "relative_specificity": "same",
                    "relatedness": "medium",
                    "pairwise_result": {
                        "relatedness": "medium",
                        "relative_specificity": "same",
                        "same_meaning": true
                    },
                    "count": 3,
                    "score": 0.6,
                    "reference_comment": "The assumption of Theorem 3.1 is not well explained and motivated. In particular, the assumption that \u201cthe loss function l(x; y) is 1-Lipschitz in x and bounded from above by one.\u201d seems to be necessary and simplify the proof a lot, but does not hold for typical losses like cross-entropy for classification and MSE for regression.",
                    "predicted_comment": "Provide a more detailed explanation of the assumptions made in your work, such as | (z, y) \u2212 (z , y)| \u2264 z \u2212 z 2, and why they are necessary for your research. This will help readers understand the theoretical underpinnings of your work."
                },
                {
                    "reference_id": 2,
                    "predicted_id": 7,
                    "relative_specificity": "more",
                    "relatedness": "medium",
                    "pairwise_result": {
                        "relatedness": "medium",
                        "relative_specificity": "more",
                        "same_meaning": true
                    },
                    "count": 4,
                    "score": 0.8,
                    "reference_comment": "Some important training details, such as the clustering-based prediction from the first step ERM model, are buried in the appendix. These details seem crucial to the functioning of the method and should be discussed in the main body, possibly with an ablation study.",
                    "predicted_comment": "Provide more details on the training setup, contrastive batch sampling, and pseudocode for CNC's implementation. This will help readers replicate your work and understand the practical aspects of implementing CNC."
                }
            ]
        },
        "metrics": {
            "all": {
                "n_reference": 10,
                "n_generated": 16,
                "n_total_aligns": 2,
                "recall": 0.17777777777777778,
                "precision": 0.041666666666666664,
                "pseudo_jaccard": 0.03518518518518519,
                "specificity_more": 0.5,
                "specificity_less": 0.0,
                "specificity_same": 0.5
            }
        },
        "metrics_for_reviews": {
            "all": [
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 2
                },
                {
                    "recall": 0.2,
                    "precision": 0.0625,
                    "pseudo_jaccard": 0.05,
                    "n_real": 5
                },
                {
                    "recall": 0.3333333333333333,
                    "precision": 0.0625,
                    "pseudo_jaccard": 0.05555555555555555,
                    "n_real": 3
                }
            ]
        }
    },
    {
        "doc_id": "2234Pp-9ikZ",
        "method": "gpt_independent_chunk",
        "reference_comments": [
            [
                "The paper lacks conceptual innovation. While the results are solid, there is little insight about the behavior of the method. No ablations are performed beyond the comparison with NAGO, making it hard to assess the importance of the individual components.",
                "The paper does not include results on ImageNet.",
                "The results are compared with models that use other teacher architectures, making it hard to determine if the improvements are due to an improved teacher or a better knowledge distillation method.",
                "The claim that a standard neural architecture search would produce architectures sampled from the same distributions and therefore not be efficient in exploring the space of students is insufficiently explored.",
                "The paper does not provide comparisons with other architecture search algorithms for knowledge distillation or surrogate functions, therefore the introduction of a new framework may not be warranted under the claims of the authors."
            ],
            [
                "The application of knowledge distillation (KD) into network architecture generator optimization (NAGO) appears to be naively done, suggesting that the proposed method is incremental and the contribution is limited.",
                "The differences between the proposed method and existing methods are not clearly highlighted.",
                "The comparison of results in Table 1 is not fair. The KD used in this paper used better teachers following the convention, but the competitor KD-LSR and SKD in the table are self-distillation methods, making the comparison meaningless.",
                "On the CIFAR100 dataset, the paper inaccurately reports that CRD used ShuffleNetV1, which has more parameters, while the original paper used WRN-40-2 as a teacher and trained the student of WRN-16-2.",
                "On the MIT67 dataset, AutoKD used the fine-tuned teacher, which is much beneficial to KD in terms of performance, while VID used an ImageNet-pretrained model for transfer learning.",
                "On the CIFAR10 dataset, the compared models have fewer parameters than that of NAGO for AutoKD, making it hard to say that AutoKD outperforms them.",
                "The experimental results are unconvincing. For example, as weight is zero in Figure 2, the accuracies in the table should show consistent performance but are deviated with respect to temperature.",
                "The accuracies of NAGO in Figure 4 appear low compared to the other results in the paper, which needs clarification.",
                "The use of KD on NAS introduces additional computational cost, but this is not clearly compared quantitatively."
            ],
            [
                "The paper's main difference from existing KD-NAS approaches is the search for a family of architectures, which mainly takes advantage of the generator in NAGO. This reduces the novelty and contribution of the work.",
                "The purpose of some experiments is unclear. It would be more beneficial to compare AutoKD with earlier KD-NAS approaches instead of NAGO to show the impact of KD on NAS.",
                "The paper does not clearly articulate how the family of student architectures can benefit knowledge distillation. It is suggested that the performance gains may result from the ensemble of networks.",
                "The comparisons shown in Figure 7 do not seem to make much sense.",
                "The logic and results shown in the visualization of Figure 6 are not clear."
            ]
        ],
        "generated_comments": {
            "all": [
                "Methodology Clarity: The methodology section could be enhanced by providing a more explicit, step-by-step breakdown of the AutoKD process. This would not only aid in understanding but also in potential replication of the methodology. Specifically, a more detailed explanation of the NAS procedure, its role in the AutoKD process, and its significance in the context of the study would be beneficial. This would provide readers with a more comprehensive understanding of the methodological approach.",
                "Comparison with Other Methods: The paper could be strengthened by providing a more comprehensive comparison with other existing methods in the field of Neural Architecture Search and Knowledge Distillation. This would provide a broader context for the performance of AutoKD. Specifically, more detailed information about the metrics used to determine performance, how these comparisons were made, and why AutoKD outperforms other methods would be helpful. This would allow readers to better understand the unique advantages of AutoKD.",
                "Analysis of Experimental Results: The experimental results section could provide a more detailed analysis, discussing why certain architectures performed better than others and how the choice of hyperparameters affected the results. This would provide readers with a deeper understanding of the factors influencing the performance of AutoKD. Additionally, it would be beneficial to discuss any unexpected results and their potential implications.",
                "Inclusion of Visual Aids: The paper could benefit from the inclusion of more visual aids, such as diagrams or flowcharts, to illustrate the proposed method and the experimental setup. This would make the paper more accessible to readers who are not deeply familiar with the field and would aid in the understanding of complex concepts and processes.",
                "Discussion on Real-world Applications: A discussion of potential real-world applications of the AutoKD method would demonstrate its practical relevance and appeal to a broader audience. This would help readers understand the real-world implications, benefits, and potential use-cases of AutoKD. It would be particularly interesting to discuss how AutoKD could be applied in resource-constrained environments given its efficiency in emulating large models with smaller students.",
                "Limitations and Future Work: A section discussing the limitations of the proposed method and potential directions for future work would provide a more balanced view of the research and guide future research in this area. This should include any potential drawbacks or limitations of the AutoKD method, such as scenarios where it may not perform as expected, and more specific details about what future work might entail and how it would build on the current research. This would provide a more comprehensive view of the research and its potential future trajectory."
            ]
        },
        "alignments": {
            "all": [
                {
                    "reference_id": 2,
                    "predicted_id": 1,
                    "relative_specificity": "more",
                    "relatedness": "medium",
                    "pairwise_result": {
                        "relatedness": "medium",
                        "relative_specificity": "more",
                        "same_meaning": true
                    },
                    "count": 3,
                    "score": 0.6,
                    "reference_comment": "The results are compared with models that use other teacher architectures, making it hard to determine if the improvements are due to an improved teacher or a better knowledge distillation method.",
                    "predicted_comment": "Comparison with Other Methods: The paper could be strengthened by providing a more comprehensive comparison with other existing methods in the field of Neural Architecture Search and Knowledge Distillation. This would provide a broader context for the performance of AutoKD. Specifically, more detailed information about the metrics used to determine performance, how these comparisons were made, and why AutoKD outperforms other methods would be helpful. This would allow readers to better understand the unique advantages of AutoKD."
                },
                {
                    "reference_id": 4,
                    "predicted_id": 1,
                    "relative_specificity": "more",
                    "relatedness": "high",
                    "pairwise_result": {
                        "relatedness": "high",
                        "relative_specificity": "more",
                        "same_meaning": true
                    },
                    "count": 2,
                    "score": 0.4,
                    "reference_comment": "The paper does not provide comparisons with other architecture search algorithms for knowledge distillation or surrogate functions, therefore the introduction of a new framework may not be warranted under the claims of the authors.",
                    "predicted_comment": "Comparison with Other Methods: The paper could be strengthened by providing a more comprehensive comparison with other existing methods in the field of Neural Architecture Search and Knowledge Distillation. This would provide a broader context for the performance of AutoKD. Specifically, more detailed information about the metrics used to determine performance, how these comparisons were made, and why AutoKD outperforms other methods would be helpful. This would allow readers to better understand the unique advantages of AutoKD."
                },
                {
                    "reference_id": 0,
                    "predicted_id": 2,
                    "relative_specificity": "more",
                    "relatedness": "medium",
                    "pairwise_result": {
                        "relatedness": "medium",
                        "relative_specificity": "more",
                        "same_meaning": true
                    },
                    "count": 2,
                    "score": 0.4,
                    "reference_comment": "The paper lacks conceptual innovation. While the results are solid, there is little insight about the behavior of the method. No ablations are performed beyond the comparison with NAGO, making it hard to assess the importance of the individual components.",
                    "predicted_comment": "Analysis of Experimental Results: The experimental results section could provide a more detailed analysis, discussing why certain architectures performed better than others and how the choice of hyperparameters affected the results. This would provide readers with a deeper understanding of the factors influencing the performance of AutoKD. Additionally, it would be beneficial to discuss any unexpected results and their potential implications."
                },
                {
                    "reference_id": 1,
                    "predicted_id": 1,
                    "relative_specificity": "more",
                    "relatedness": "medium",
                    "pairwise_result": {
                        "relatedness": "medium",
                        "relative_specificity": "more",
                        "same_meaning": true
                    },
                    "count": 3,
                    "score": 0.6,
                    "reference_comment": "The purpose of some experiments is unclear. It would be more beneficial to compare AutoKD with earlier KD-NAS approaches instead of NAGO to show the impact of KD on NAS.",
                    "predicted_comment": "Comparison with Other Methods: The paper could be strengthened by providing a more comprehensive comparison with other existing methods in the field of Neural Architecture Search and Knowledge Distillation. This would provide a broader context for the performance of AutoKD. Specifically, more detailed information about the metrics used to determine performance, how these comparisons were made, and why AutoKD outperforms other methods would be helpful. This would allow readers to better understand the unique advantages of AutoKD."
                }
            ]
        },
        "metrics": {
            "all": {
                "n_reference": 19,
                "n_generated": 6,
                "n_total_aligns": 4,
                "recall": 0.26666666666666666,
                "precision": 0.16666666666666666,
                "pseudo_jaccard": 0.13137254901960785,
                "specificity_more": 1.0,
                "specificity_less": 0.0,
                "specificity_same": 0.0
            }
        },
        "metrics_for_reviews": {
            "all": [
                {
                    "recall": 0.6,
                    "precision": 0.3333333333333333,
                    "pseudo_jaccard": 0.29411764705882354,
                    "n_real": 5
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 9
                },
                {
                    "recall": 0.2,
                    "precision": 0.16666666666666666,
                    "pseudo_jaccard": 0.1,
                    "n_real": 5
                }
            ]
        }
    },
    {
        "doc_id": "KPEFXR1HdIo",
        "method": "gpt_independent_chunk",
        "reference_comments": [
            [
                "The authors should report the wall clock time to demonstrate the time performance of the fine-grained model.",
                "The authors should clarify the biggest time step the simulation can deal with, as the current time step is relatively small (0.001s).",
                "The authors should demonstrate how this method can scale to more complex topologies. All the experiments are currently on one square sheet, but it would be beneficial to see if the method can simulate something like a T-shirt or dress, which is more relevant to design and fabrication."
            ],
            [
                "The paper should include a discussion comparing this work and the latest work on differentiable cloth simulation in a mesh-based view, as mentioned in reference [1].",
                "The statement 'Previous research (Liang et al., 2019; Du et al., 2021) suffers from this problem, which unfortunately leads to learning implausible parameter values' is technically inaccurate. Leveraging prior knowledge for physical parameters is now a necessary step for system identification tasks.",
                "The motivation for using a yarn-level simulator is unclear. The experiments are too coarse to show the advantages of more accurate collision handling and detailed presentation, which are the reasons for proposing a yarn-level simulation. A more valid explanation for motivation or a set of better results that are more complex than 25*25 is expected.",
                "The manuscript should clarify why the authors chose the yarn-based method, how they plan to use this simulator, and where they see the simulator fits in. The motivation for using yarn-level, which is originally designed for fine details but applied on over-simplified models, is not convincing."
            ],
            [
                "The authors identify a major shortcoming of previous simulation models, namely the use of discontinuous force terms, and engineer alternative models that approximate the terms from domain literature but have the added benefit of being smooth everywhere.",
                "The paper raises a question about the non-linear stick-slip force term leading to oscillatory behavior, which could potentially lead to free energy being trapped in entropy and therefore thermal loss.",
                "The paper raises a question about why differences between inter/intra parameters (Table 2) and ground truth increase as the grid size increases.",
                "In the Comparison video, it is difficult to spot any significant difference between the different weaves, which is a weakness of the paper.",
                "The paper lacks real-world experiments, and the range of simulated experiments is not very wide, making it difficult to judge the expressivity / gamut of the model.",
                "The paper acknowledges that neither the specific problem nor the general idea of differentiable simulation is new, and it is unclear whether the specific solutions introduced in the paper generalize to other problems."
            ],
            [
                "The paper does not comment on the computational cost and comparisons to baseline methods. It would be beneficial to provide such information in the main paper, especially when compared with non-differentiable simulator [Cirio et al., 2014] and prior work on differentiable cloth simulation [Liang et al., In NeurIPS 2019].",
                "The quantitative results need to be presented in a clearer manner. For example, it would be good to show the material prediction error in percentage in Table 2-4 (rather than the absolute value). It would be beneficial to include the algorithm (refer to Section 3.1 in [Liang et al. 2019]) in the main paper.",
                "It is unclear whether the proposed differentiable simulation is deterministic or not? Whether the material estimation is sensitive to initialization? In this case, please consider reporting the standard deviation for multiple runs of the same setting.",
                "It is unclear what happens if the parameter prior was not provided to the proposed method in the control learning experiment. It would be beneficial to provide such ablation studies and discuss the results in the rebuttal."
            ],
            [
                "The design process of the model is heuristic and lacks analysis or ablation study to justify the design choices made.",
                "The paper does not discuss how the method performs as a function of the magnitude of the forces. Additional experiments should be conducted to illustrate this.",
                "There is a discrepancy between the claim in paragraph-2 of section 4.2.1 and the data presented in Fig-6 and Table-4. The paper claims that the error reduces by around 100 times when the training data increase from 5 frames to 25 frames, but the figures show only a 10-fold reduction.",
                "The experiments focus only on simulated woven cloth, and the models are heavily designed. This raises questions about the generalizability of the proposed method to other materials and weaving structures."
            ]
        ],
        "generated_comments": {
            "all": [
                "To enhance the structure of the paper, consider providing a brief introduction or summary at the beginning of each section. This will guide the reader through the transitions between different topics and help them understand the purpose and relevance of the derivations and arguments.",
                "The abstract contains technical jargon which might make it less accessible to a broader audience. Consider simplifying the language and reducing the use of technical terms in the abstract to make it more reader-friendly.",
                "The introduction of Differentiable Physics Models (DPMs) could be more detailed. Explain how DPMs improve model explicability and why this is important. This will provide the reader with a better understanding of the significance of your work.",
                "In the methodology section, provide more context or background information to help the reader understand the context and significance of the mathematical equations and derivations. Also, consider breaking down complex concepts to make them more understandable.",
                "Consider including a diagram or flowchart to visually represent the proposed model and its components. This would aid reader comprehension. Also, consider providing a more intuitive, non-mathematical explanation of the model and its components.",
                "Justify the choice of force models more thoroughly. Explain how these specific models contribute to the overall performance of the proposed model. This will help the reader understand the rationale behind your choices.",
                "Provide more details about the evaluation metrics used in the model comparison. Also, consider comparing the model with more recent works to demonstrate its relevance and superiority.",
                "Enhance the reproducibility of your work by providing more details on the experimental setup, including the selection of parameters for the Stochastic Gradient Descent and the determination of epochs.",
                "Support the claim of high data efficiency with a more quantitative analysis. For example, you could compare the performance of the model with varying amounts of training data.",
                "Discuss potential real-world applications of the proposed model to demonstrate its practical relevance. Also, consider discussing potential challenges and ways to address them.",
                "Include a section discussing the limitations of the proposed model and potential avenues for future research to provide a balanced view of the work.",
                "Revise some phrases for clarity. A thorough proofreading of the paper would help correct minor errors and improve readability.",
                "Ensure that all references are correctly cited. If you are using established methods or theories, please cite relevant sources. If the methods are novel, provide more explanation and possibly compare with existing methods.",
                "Provide definitions or explanations for the technical terms and symbols used in the paper to aid reader comprehension."
            ]
        },
        "alignments": {
            "all": [
                {
                    "reference_id": 0,
                    "predicted_id": 5,
                    "relative_specificity": "more",
                    "relatedness": "medium",
                    "pairwise_result": {
                        "relatedness": "medium",
                        "relative_specificity": "more",
                        "same_meaning": true
                    },
                    "count": 3,
                    "score": 0.6,
                    "reference_comment": "The design process of the model is heuristic and lacks analysis or ablation study to justify the design choices made.",
                    "predicted_comment": "Justify the choice of force models more thoroughly. Explain how these specific models contribute to the overall performance of the proposed model. This will help the reader understand the rationale behind your choices."
                }
            ]
        },
        "metrics": {
            "all": {
                "n_reference": 21,
                "n_generated": 14,
                "n_total_aligns": 1,
                "recall": 0.05,
                "precision": 0.014285714285714285,
                "pseudo_jaccard": 0.011764705882352941,
                "specificity_more": 1.0,
                "specificity_less": 0.0,
                "specificity_same": 0.0
            }
        },
        "metrics_for_reviews": {
            "all": [
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 3
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 4
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 6
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 4
                },
                {
                    "recall": 0.25,
                    "precision": 0.07142857142857142,
                    "pseudo_jaccard": 0.058823529411764705,
                    "n_real": 4
                }
            ]
        }
    },
    {
        "doc_id": "HyxLRTVKPH",
        "method": "gpt_independent_chunk",
        "reference_comments": [
            [
                "The paper does not clearly demonstrate the advantages of using a linear scaling schedule over other schedules. For example, step-based schedules outperform the proposed method in 2 of the 4 tasks in Table 2, and Poly and Cosine schedules perform better in some budgets in Figure 2.",
                "The comparisons in Figure 2 and Table 2 are not convincing without considering the variance of different trials. It is unclear whether the advantage is due to the learning rate schedule or randomness. The paper should report the mean and variance for multiple trials and ideally perform a significance test.",
                "The paper should include other learning rate schedules in Table 2. As shown in Figure 2, step-based schedule is not among the top three schedules for CIFAR-10.",
                "As shown in Table 3, the proposed method requires waiting until the end of training to get the best performing model, while step-based schedule can find the best model around 90% training. This means early stopping is not possible for linear scaling based schedule, which could be useful when the training budget is large enough and evaluation is cheap.",
                "The paper lacks a deeper understanding of why a linear learning rate schedule might work better. The authors attempt to provide an explanation from the relationship between learning rate and gradient magnitudes, but no clear conclusion is given. The paper should investigate when no weight decay is used and whether there is any correlation between the learning rate and gradient norms.",
                "The paper does not specify the learning rate decay unit for the linear schedule. Is it decaying per epoch or per mini-batch? If epoch-based learning rate decay is used, it is essentially step-based learning rate decay with many steps.",
                "The paper should investigate when the linear schedule starts to outperform step-based decay in terms of epochs or iterations. The difference between two schedules for small batch size at the early stage of training might be less in comparison with large batch training, especially when the number of iterations is enough.",
                "The paper only compares different schedules with a single initial learning rate. Different initial learning rates may result in different behaviors. The paper should consider scenarios where the initial learning rate is small, as there might not be much difference for different schedules in such cases.",
                "The authors' rebuttal did not fully address the concern about the lack of early stopping in the proposed method, which could limit its usage, especially for Hyperparameter Optimization (HPO).",
                "The authors' rebuttal did not fully address the concern about the lack of understanding of why the linear scaling schedule is better."
            ],
            [
                "The paper lacks a sound theory explaining why linear decay or other smooth decay methods work well.",
                "The novelty of the methodology proposed by the authors might be limited, as Mishkin et al. have already experimented with linear decay."
            ],
            [
                "The paper makes unclear claims about the phenomena of gradient magnitude vanishing and its effectiveness. For example, in section 5, the authors state 'We call this \u201cvanishing gradient\u201d phenomenon budgeted convergence. This correlation suggests that decaying schedules to near-zero rates (and using BAC) may be more effective than early stopping.' This claim appears to be an overreach as the paper merely shows gradient magnitude decreasing with learning rate.",
                "The paper does not perform extensive comparisons for commonly used algorithms like Adam, which are key motivating use cases for budget-aware training, such as providing approximations for problems like neural architecture search and hyperparameter tuning."
            ]
        ],
        "generated_comments": {
            "all": [
                "Enhance the clarity and structure of the paper by presenting the information in a logical flow: introduction to the problem, proposed solution, experimental setup, results, and finally discussion and conclusion. Summarize key points in the introduction succinctly to improve readability and comprehension.",
                "Provide a detailed explanation of the methods used, particularly the linear schedule and its implementation, to enhance understanding and replicability. Clearly define terms such as 'budgeted training', 'neural architecture search', and 'learning rate schedule' when first introduced. Elaborate on the implementation of the Budget-Aware Conversion (BAC), specifically how the original schedule is rescaled and the impact on the learning rate.",
                "Provide a thorough theoretical justification for the effectiveness of the linear schedule, including an explanation of the theory behind these methods and the reasons for their selection for comparison, to strengthen your argument and deepen understanding.",
                "Include a detailed comparison of the linear schedule with other learning rate schedules, possibly in a side-by-side format, to provide a comprehensive comparison and highlight performance differences.",
                "Incorporate visual aids, such as graphs or charts, to illustrate the performance of the linear schedule compared to other schedules, making it easier for readers to understand the results.",
                "Include a section discussing the limitations of the proposed approach to provide a balanced view of its applicability and potential drawbacks.",
                "Consider conducting further experiments, such as testing the method on different types of datasets or using different types of neural network architectures, to validate the robustness of the linear schedule across various scenarios.",
                "Discuss the practical implications of the findings, including potential impacts on the field and how practitioners can apply this information in their work, to provide readers with a clear understanding of the real-world applicability of your research.",
                "Ensure that all references are correctly cited and formatted. There are several instances in the text where references are mentioned but not properly cited."
            ]
        },
        "alignments": {
            "all": [
                {
                    "reference_id": 0,
                    "predicted_id": 2,
                    "relative_specificity": "more",
                    "relatedness": "high",
                    "pairwise_result": {
                        "relatedness": "high",
                        "relative_specificity": "more",
                        "same_meaning": true
                    },
                    "count": 4,
                    "score": 0.8,
                    "reference_comment": "The paper lacks a sound theory explaining why linear decay or other smooth decay methods work well.",
                    "predicted_comment": "Provide a thorough theoretical justification for the effectiveness of the linear schedule, including an explanation of the theory behind these methods and the reasons for their selection for comparison, to strengthen your argument and deepen understanding."
                }
            ]
        },
        "metrics": {
            "all": {
                "n_reference": 14,
                "n_generated": 9,
                "n_total_aligns": 1,
                "recall": 0.16666666666666666,
                "precision": 0.037037037037037035,
                "pseudo_jaccard": 0.03333333333333333,
                "specificity_more": 1.0,
                "specificity_less": 0.0,
                "specificity_same": 0.0
            }
        },
        "metrics_for_reviews": {
            "all": [
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 10
                },
                {
                    "recall": 0.5,
                    "precision": 0.1111111111111111,
                    "pseudo_jaccard": 0.1,
                    "n_real": 2
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 2
                }
            ]
        }
    },
    {
        "doc_id": "giit4HdDNa",
        "method": "gpt_independent_chunk",
        "reference_comments": [
            [
                "No theoretical or empirical evidence is presented that confirms that the training speed of N-CODE is significantly lower compared to NODE.",
                "While performance seems generally higher, the limitations of the proposed N-CODE method are not clear.",
                "The claim of better performance in less time is not fully supported by the results."
            ],
            [
                "The supervised classification part of the paper is highly related to the 'Data Controlled Neural ODEs' section in Massaroli et al (2020b), a paper that has been cited in the related work section but not addressed in the main content. The problems tackled and the results are highly related to those of Massaroli et al (2020b). This issue needs to be addressed sufficiently.",
                "The unsupervised section needs more work. The experiments and tables can be described more effectively. For example, it would be preferable to clearly explain which row section 5.3 refers to in Figure 7, and which row corresponds to section 5.4.",
                "The paper claims that the replacement of a linear layer with a Neural CODE improves image reconstruction quality. This should mean that all layers in the encoder can be replaced to give better encoding, taking care of dimensionality (such as in Normalizing Flows). However, this paper uses a typical neural network for image reconstruction and generation. This suggests that the majority of heavy-lifting is done by the decoder, hence the Neural CODE is more amenable to warping the latent space suitable for the decoder. For image generation as well, the latent space has been designed so that the decoder can produce nice images, this is not necessarily a win for the Neural CODE.",
                "To make the case for Neural CODE, especially for images, higher resolution images need to be tackled, since it is in higher dimensions that the success of the advancements in the methods listed in Figure 7 lies."
            ],
            [
                "The authors should investigate how the model performance changes as f grows. Learning the parameters of a neural network via another neural network(s) is a very challenging problem, and it would be beneficial to see this verified or not.",
                "The connection with control theory can be made clearer. There is very little reference to Pontryagin's maximum principle and the link is not visible.",
                "The authors should test vanilla NODE on experiments 5.3 and 5.4. It would be interesting to see if the improvement of N-CODE is significant when NODE is latent."
            ],
            [
                "The paper is closely related to other works that have also focused on making the weights of neural ODEs time dependent. A more thorough discussion of the differences between these models is needed to better understand where the novelty/contribution comes in.",
                "The closed loop model, which is the main innovation, is thoroughly discussed in the paper. However, most experiments are performed with the open loop model, which is very similar to other models already proposed in the literature. This puts into question whether the full closed loop model is actually useful in practice.",
                "There is no evaluation of the number of functions evaluations in the paper. According to the abstract, the model trains faster so it seems important to include this information in the paper.",
                "The authors claim that the model achieves state of the art reconstruction on CIFAR10. However, reconstruction doesn\u2019t really make sense as a task (since the identity function would be optimal in this case). This claim is questionable and should be removed."
            ]
        ],
        "generated_comments": {
            "all": [
                "Clarity of Methodology: The N-CODE methodology and the autonomous differential system are central to your work, but they could be explained in more detail. Consider including a step-by-step walkthrough of the process using a simple example. This would enhance understanding for readers who are not familiar with these concepts and provide a clearer picture of your methodology.",
                "Comparison with Other Methods: A more thorough comparison with other state-of-the-art methods and specific generative techniques in the field would strengthen the paper. This could be achieved either through additional experiments or a more detailed discussion in the text. Also, specify the metrics used for this comparison. This would provide a clearer context for your work and help readers understand how your method compares to existing techniques.",
                "Experimental Details and Setup: More details about the experiments conducted would be beneficial. This includes information about the training process, hyperparameters used, the specific datasets used, and the rationale behind the choice of the number of components in the mixture, the Adam optimizer, and the specific learning rate. This would allow other researchers to replicate your experiments and verify your results.",
                "Discussion of Limitations: A more thorough discussion of the limitations or challenges that remain with the N-CODE method would provide a more balanced view of the work. This would help readers understand the potential challenges in implementing your method and areas where further research is needed.",
                "Results Interpretation: A detailed interpretation of the results is needed. Explain the significance of the decrease of the Frechet Inception Distance and the impact of the structural change in the latent manifold organization on the results. This would help readers understand the implications of your results and their significance in the field.",
                "Visualizations and Visual Aids: More visualizations and visual aids, such as graphs or diagrams, would help illustrate the concepts and results. This could make the paper more accessible to a wider audience and help readers visualize the concepts and results you are discussing.",
                "Future Work: A section on future work, outlining potential improvements to the N-CODE method or other applications where N-CODE could be beneficial, would be a valuable addition. Provide more details on the areas identified for future work, explaining how these areas could be explored and how they could potentially improve the current work. This would give readers a sense of the potential future directions for your research.",
                "Appendix: Consider providing a more detailed explanation of the equations and proofs in the appendix to enhance understanding for readers not familiar with these concepts. This would make your paper more accessible to a wider audience and help readers understand the mathematical foundations of your work."
            ]
        },
        "alignments": {
            "all": [
                {
                    "reference_id": 1,
                    "predicted_id": 3,
                    "relative_specificity": "more",
                    "relatedness": "high",
                    "pairwise_result": {
                        "relatedness": "high",
                        "relative_specificity": "more",
                        "same_meaning": true
                    },
                    "count": 5,
                    "score": 1.0,
                    "reference_comment": "While performance seems generally higher, the limitations of the proposed N-CODE method are not clear.",
                    "predicted_comment": "Discussion of Limitations: A more thorough discussion of the limitations or challenges that remain with the N-CODE method would provide a more balanced view of the work. This would help readers understand the potential challenges in implementing your method and areas where further research is needed."
                }
            ]
        },
        "metrics": {
            "all": {
                "n_reference": 14,
                "n_generated": 8,
                "n_total_aligns": 1,
                "recall": 0.08333333333333333,
                "precision": 0.03125,
                "pseudo_jaccard": 0.025,
                "specificity_more": 1.0,
                "specificity_less": 0.0,
                "specificity_same": 0.0
            }
        },
        "metrics_for_reviews": {
            "all": [
                {
                    "recall": 0.3333333333333333,
                    "precision": 0.125,
                    "pseudo_jaccard": 0.1,
                    "n_real": 3
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 4
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 3
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 4
                }
            ]
        }
    },
    {
        "doc_id": "b7ZRqEFXdQ",
        "method": "gpt_independent_chunk",
        "reference_comments": [
            [
                "The paper lacks novelty as it combines existing procedures such as relativistic discriminator, Gumbel-Softmax approximation for categorical distribution, and features matching to improve upon vanilla sequence generation networks.",
                "The generated sentences by the GAN, especially the lengthy ones, are not semantically meaningful as illustrated in Table 8.",
                "The Mean Distance Alignment (MDA) and the Mean Square alignment (MSA) used for features distribution alignment encode the same matching up to a power 2, and it's unclear why they lead to different empirical results.",
                "The paper should consider aligning the overall distributions of the latent representations by considering metrics such as MMD or Wasserstein distance.",
                "The paper should clarify earlier that the used features are extracted from the discrimination network and from which layer of the discrimination network the features are extracted.",
                "The findings of human evaluation are not unequivocal as MSA and MDA achieve higher scores than the real sentences, and the best model with MSA is not preferred due to a lack of diversity and quality."
            ],
            [
                "The authors claim that the use of Gumbel-softmax in GAN training is under-explored, but this is not clear. There are other methods using Gumbel-softmax, such as Gu et al. 2019, and similar softmax with temperature annealing. The authors need to clearly distinguish between using Gumbel-softmax and other smoothed softmax methods.",
                "The authors missed some related work, such as DialogWAE (Gu et al. 2019) and ARAML (Ke et al. 2019). In particular, DialogWAE uses GAN and Gumbel-softmax for text generation, even though it focuses on dialog generation.",
                "To verify mode collapse issues, the authors should consider using Self-BLUE in addition to BLUE scores as a metric to evaluate the diversity.",
                "The novelty of the paper might be incremental. It seems that the novelty comes from using feature statistics alignment. To emphasize the contribution of feature statistics, the authors should consider comparing between the latent feature visualization with and without FSA, in addition to the ablation study."
            ],
            [
                "Although the proposed model is thoroughly evaluated and empirically effective, it is not very different from existing methods, except for the Feature Statistics Alignment (FSA). The application of FSA in this context might be novel; however, the proposed approach seems to be a simple combination of two existing approaches. Therefore, the novelty of the model is limited."
            ],
            [
                "In Table 2, the LSTM model gets NLL lower than the real data, which is a clear evidence of overfitting.",
                "In Table 2, the NLL_{gen} metric, used in SAL (Zhou et. al, 2020) to evaluate the diversity of the generator, is missing without explanation.",
                "In Table 3, the BLEU metric used is the BLEU(F) metric from SAL (Zhou et. al, 2020), which evaluates the generated sentences using the test set as a reference and thus cannot show the diversity of examples.",
                "In Table 3, the BLEU(B) metric from SAL (Zhou et. al, 2020) is missing. This metric evaluates the test set using the generated sentences as a reference, so it can detect mode collapse of a generative model.",
                "The evaluation metrics used in the paper prefer overfitted models, i.e., if the model can remember one example from the training set and repeat that sentence, it can get a very high score.",
                "The authors need to provide more evidence on the diversity of the generated sentences, for example by showing the NLL_{gen} metric on the synthetic dataset, and BLEU(B) metric on real datasets."
            ]
        ],
        "generated_comments": {
            "all": [
                "Expand the introduction to provide a more comprehensive explanation of the adversarial training framework, Gumbel-Softmax relaxation, and the Feature Statistics Alignment (FSA) paradigm. This will enhance the reader's understanding of these concepts and their implementation in the GAN framework.",
                "Incorporate diagrams or flowcharts to illustrate the proposed architecture and the adversarial training process. Visual aids can make the methodology more accessible and easier to understand.",
                "Include a detailed comparison with other methods used for sequence generation in the 'Related Work' section. Highlight the advantages and disadvantages of each, and discuss why your model outperforms these other models and under what conditions.",
                "Elaborate on the experimental setup section by providing more details about the specific synthetic and real benchmark datasets used and the evaluation metrics used for the quantitative evaluation. Specifically, provide more information about the performance metrics used (NLL oracle, BLEU score, etc.) and how these metrics were calculated.",
                "Provide a more in-depth discussion in the results section. Explain why the proposed approach outperforms others and under what conditions it might not.",
                "Discuss the limitations of your model and method in a separate section. This could include situations where your model might not perform as well, or potential improvements that could be made.",
                "Include a section discussing potential areas for future work, such as extending the model to conditional text generation, such as text style transfer. Provide more details about how this could be achieved and what the potential benefits might be.",
                "Enhance the conclusion to provide a more detailed summary of your findings and their implications for the field. This should include a discussion of the practical applications of your model and method.",
                "Ensure that each sentence logically follows from the previous one and contributes to the overall argument or point being made.",
                "Provide more background information and explain the relevance of the issues being discussed.",
                "Clarify unclear references or provide necessary citations.",
                "Thoroughly proofread the paper and correct grammatical and syntax errors.",
                "Structure the paper into clear sections with headings and subheadings to guide the reader.",
                "Clearly state the objective of the paper at the beginning and provide a conclusion summarizing the main points at the end.",
                "Maintain an objective, third-person perspective throughout the paper, avoiding the use of personal pronouns such as 'I' and 'we'.",
                "Ensure that all information is properly cited to maintain academic integrity."
            ]
        },
        "alignments": {
            "all": []
        },
        "metrics": {
            "all": {
                "n_reference": 17,
                "n_generated": 16,
                "n_total_aligns": 0,
                "recall": 0.0,
                "precision": 0.0,
                "pseudo_jaccard": 0.0,
                "specificity_more": NaN,
                "specificity_less": NaN,
                "specificity_same": NaN
            }
        },
        "metrics_for_reviews": {
            "all": [
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 6
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 4
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 1
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 6
                }
            ]
        }
    },
    {
        "doc_id": "zCu1BZYCueE",
        "method": "gpt_independent_chunk",
        "reference_comments": [
            [
                "The experiments focus only on selecting a single initial learning rate, which is less interesting because normally a learning rate scheduler that changes over time is used. The experiment does not consider different types of learning rate schedulers for comparisons.",
                "The learning rate is just a scalar, so a simple grid search could be used to coarsely find a good learning rate and then refine it. This makes the focus on learning rate less impactful.",
                "The work would be more impactful if it demonstrated improvement in other hyper-parameter optimizations such as weight decay and convolution filter size and channels."
            ],
            [
                "The paper lacks comparisons to baseline hyperparameter tuning setups. For example, in Figure 3, the best final validation and/or test accuracies achieved by autoHyper and by random search for the same number of trials are not shown.",
                "The paper does not compare the proposed algorithm to existing state-of-the-art methods, which would be useful for a solid paper.",
                "The suggested initial learning rates (LRs) seem problematic to compare to. It would be useful to highlight how the suggested initial LRs were tuned.",
                "The suggested initial LRs were tuned using less trials than the proposed algorithm, and using a grid search algorithm that may be worse than random search.",
                "The suggested initial LRs were for a different model than the models considered in the experiments here, which means they could serve as a poor baseline.",
                "The ranges of values tuned over in Wilson 2017 seem to be quite close to several of the values proposed by autoHyper, meaning that perhaps repeating the same grid search could be competitive.",
                "In the cases where the autoHyper values are not close, they are sometimes outside the range considered by Wilson 2017, which could bias the results towards the proposed algorithm.",
                "Several recent works have shown that when tuning optimizers one needs to be careful to report the ranges used, as changing the hyperparameter ranges can drastically affect experimental results.",
                "Figure 1a would be much more informative if you showed the entire training trajectory, including past the first 5 epochs, to see if the selected learning rates actually generalize noticeably better.",
                "In your conclusion you discuss that you could extend your tuning algorithm to multiple hyperparameters, and I believe in order to truly demonstrate its capabilities this would be required."
            ],
            [
                "The algorithm has an implicit assumption that the response function is monotonously decreasing. The paper should clarify what happens if the response function does not decrease, and how the range of the search area is chosen in such cases.",
                "The algorithm introduces new hyperparameters, such as alpha and the 'rate of change plateaus'. The paper should explain how these hyperparameters are chosen and how they influence the result.",
                "The paper should provide a reasonable explanation for why the initial learning rate influences the testing accuracy, not just the convergence rate for training loss.",
                "The paper only compares the algorithm with the baseline. The authors should discuss if there are any other works about tuning the initial learning rate, or if this paper is the first of its kind.",
                "The reviewer suggests that it may be more convincing if the whole parameters are chosen together, not just the initial learning rate."
            ]
        ],
        "generated_comments": {
            "all": [
                "To enhance the reader's understanding of the autoHyper algorithm, please provide a more comprehensive, step-by-step explanation in the main text. A flowchart or a step-by-step breakdown could be beneficial in visualizing the process.",
                "To further validate the generalizability of your method, consider testing it on a broader range of datasets and models. This would provide a more robust validation of your method's applicability across different scenarios.",
                "To highlight the advantages of your proposed method, include a detailed comparison of results with existing methods. Presenting this comparison in a table or graph format would allow for a more straightforward interpretation of the differences and advantages.",
                "Please include a section discussing the limitations of your proposed method and potential future work to address these limitations. A more in-depth discussion on the implications of your findings, such as the 'blind spots' in HPO and why they might have been overlooked, would provide valuable context and insight.",
                "To ensure reproducibility and transparency, consider providing the code used in your experiments or a more detailed description of the implementation details. This would allow other researchers to replicate your work more easily and build upon it.",
                "Please elaborate more on the potential impact and real-world applications of your work. This would help readers understand its practical implications and the potential benefits of your method in real-world scenarios.",
                "Consider restructuring the results section for better clarity. Grouping results based on the datasets or the optimizers used could make it easier for readers to follow and understand the results.",
                "When referring to tables and figures in the text, please include a brief description of these in the text itself. This would help readers understand the results without having to refer to the tables and figures separately, improving the readability of your paper.",
                "Please expand on the potential future work mentioned, such as the possibility of autoHyper being adapted to simultaneously optimize multiple HPs. Discuss other potential avenues for future research based on the findings of this study. This would provide a roadmap for future research in this area."
            ]
        },
        "alignments": {
            "all": [
                {
                    "reference_id": 9,
                    "predicted_id": 8,
                    "relative_specificity": "more",
                    "relatedness": "medium",
                    "pairwise_result": {
                        "relatedness": "medium",
                        "relative_specificity": "more",
                        "same_meaning": true
                    },
                    "count": 3,
                    "score": 0.6,
                    "reference_comment": "In your conclusion you discuss that you could extend your tuning algorithm to multiple hyperparameters, and I believe in order to truly demonstrate its capabilities this would be required.",
                    "predicted_comment": "Please expand on the potential future work mentioned, such as the possibility of autoHyper being adapted to simultaneously optimize multiple HPs. Discuss other potential avenues for future research based on the findings of this study. This would provide a roadmap for future research in this area."
                }
            ]
        },
        "metrics": {
            "all": {
                "n_reference": 18,
                "n_generated": 9,
                "n_total_aligns": 1,
                "recall": 0.03333333333333333,
                "precision": 0.037037037037037035,
                "pseudo_jaccard": 0.018518518518518517,
                "specificity_more": 1.0,
                "specificity_less": 0.0,
                "specificity_same": 0.0
            }
        },
        "metrics_for_reviews": {
            "all": [
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 3
                },
                {
                    "recall": 0.1,
                    "precision": 0.1111111111111111,
                    "pseudo_jaccard": 0.05555555555555555,
                    "n_real": 10
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 5
                }
            ]
        }
    },
    {
        "doc_id": "rrWeE9ZDw_",
        "method": "gpt_independent_chunk",
        "reference_comments": [
            [
                "The paper claims that the learned object-centric abstraction can be transferred to a new task with the same object type, but it does not define how 'same' is with respect to the same object type in the new task. For example, an apple on a table and an apple on a tree are semantically the same but have different preconditions for the 'pick' action. This suggests that the object-centric abstractions are still more task-specific, even for semantically identical objects.",
                "The paper suggests using Problem-Specific Instantiation to solve the problem of same-type objects having different preconditions in different scenarios. However, this process is similar to manually adjusting the planning domain to adapt to a different scenario, which does not solve the fundamental limitation of the human-defined planning domain.",
                "The learned symbolic predicates of specific object types are not general enough to be applied across different tasks. The proposed object-centric abstraction only groups similar conditions it observed, but does not abstract the preconditions of why an action could be performed. For example, if an apple is placed at different heights, the proposed method will lead to different apple object types as they have different preconditions. If the apple is placed even higher--a condition out of the previously seen cases, the proposed method cannot solve this problem as it does not abstract the 'reachable' concept for the picking action."
            ],
            [
                "The paper claims that the proposed method results in being able to obtain a successful agent for long-term planning with considerably fewer environment interactions, but does not provide a quantitative evaluation against a baseline to demonstrate this reduction in environment interactions.",
                "The paper's comparison with prior works like Kaiser et al. (2020) and Hafner et al. (2021) may not be fair, as the presented method assumes that environment observations are pre-factored and pre-processed into object components, which is a non-trivial task that might explain the sample inefficiency of earlier methods.",
                "The paper should either significantly reduce the prominence of the sample efficiency claims or provide a fair experimental comparison against a baseline that has access to the same factored, pre-processed observations and abstract options as the presented technique."
            ],
            [
                "The paper should clarify why a grouping based on effect distributions alone is preferred over one that also considers the pre-condition.",
                "The paper should provide more details on how it is determined what objects/operators require grounding.",
                "The paper should explain how the clustering proceeds for X, including how X is partitioned and how the result from clustering X is connected to clustering S.",
                "The paper should clarify how much domain knowledge is injected in the method for integrating task-specific information in the learned representations.",
                "The paper should provide more details on the steps needed to achieve the result in the Craft environment experiment, including how the need for having identities is identified, how it is determined which objects require ids, and how the id is connected to the object.",
                "The paper should discuss the limitations of the approach, including the assumptions made such as the frame assumption, that options only affect the object they act upon, and that the world comes pre-segmented according to objects.",
                "The paper should clarify how the grounding is achieved and what knowledge is assumed to arrive at the presented results."
            ]
        ],
        "generated_comments": {
            "all": [
                "The section on generating a lifted, typed model could benefit from a more detailed explanation of the steps involved, including the specific algorithms or techniques used. This should include a comprehensive explanation of the preprocessing steps used to reduce the dimensionality of the state space, the principal component analysis, and the rationale behind selecting the top 40 principal components. Additionally, it would be beneficial to provide more clarity on how the precondition classifiers and effect estimators are trained and validated, including any cross-validation or other techniques used to prevent overfitting.",
                "Ensure that Figure 1, which summarizes the proposed approach, is clear, well-labelled, and effectively aids in understanding the proposed methodology. Consider including more visual aids, such as diagrams or flowcharts, to help readers better understand the proposed method and the experimental setup. These visual aids should be accompanied by detailed captions that explain the key elements and steps.",
                "To make the paper more accessible to a broader audience, provide brief explanations or references for technical terms and acronyms used in the paper, such as 'object-centric MDPs', 'propositional PDDL', 'DBSCAN', 'SVM', etc. This includes a detailed explanation of the symbols used in the abstract operators, which will help readers understand the mathematical notation and the logic behind the operators.",
                "The experimental setup section could be expanded to include more information about the specific tasks, the configuration of the environment, and the metrics used to evaluate performance. This should include more details about the parameters used in DBSCAN for partitioning and SVM for precondition learning, and the rationale behind these choices. This will help readers understand the experimental design and the reasons for your methodological choices.",
                "A direct comparison of your method with other existing methods in terms of performance, efficiency, and applicability would strengthen the paper. This should include a detailed comparison between your method and the framework proposed by Konidaris et al. (2018) and the work of Asai & Muise (2020). Specifically, discuss the limitations of the previous methods and how your proposed method overcomes them. This will help readers understand the novelty and significance of your work.",
                "The results section could be enhanced with a more detailed analysis. Discuss why you obtained these results, what they imply, and how they compare with previous studies. Include a more thorough evaluation of the results and consider including additional metrics or benchmarks to demonstrate the effectiveness of your approach. This will provide readers with a deeper understanding of the significance and implications of your findings.",
                "A discussion on the limitations of the proposed method would provide a more balanced view and open avenues for future work. This should include information about how often errors occur and how they impact the overall performance of the agent. Discuss potential drawbacks or limitations of your approach and suggest possible future work to address these issues. This will help readers understand the potential challenges and areas for improvement in your method.",
                "Discuss potential real-world applications of the proposed method to demonstrate the broader impact of the research. Broaden the discussion on the potential applications of the proposed method. Discuss how it could be applied to other problems or domains beyond the specific tasks demonstrated in the paper. This will help readers understand the practical implications and potential uses of your work.",
                "Elaborate on how your method handles data scarcity and what makes it efficient in learning from limited data. Discuss the strategies or techniques used to maximize learning from limited data and how these contribute to the efficiency of your method. This will help readers understand the scalability and robustness of your method in different data scenarios.",
                "Expand on the future work mentioned in the conclusion section. Discuss potential improvements or extensions that could be made to the proposed method and the challenges that might be encountered in this future work. Discuss potential solutions or future work to address the errors and limitations identified. This will give readers a sense of the potential evolution and growth of your research.",
                "To ensure reproducibility and foster open science, consider providing access to the code, models, and datasets used in the experiments. This could be done through a public repository or supplementary materials. This will allow other researchers to replicate your experiments, validate your results, and potentially build upon your work.",
                "Provide more context around the Blocks World domain. Including more information about why this domain was chosen and how it is representative of the broader problem the authors are trying to solve would give readers a better understanding of the relevance and applicability of the research. This will help readers understand the choice of this specific domain and its significance in the context of your research."
            ]
        },
        "alignments": {
            "all": [
                {
                    "reference_id": 6,
                    "predicted_id": 0,
                    "relative_specificity": "more",
                    "relatedness": "medium",
                    "pairwise_result": {
                        "relatedness": "medium",
                        "relative_specificity": "more",
                        "same_meaning": true
                    },
                    "count": 2,
                    "score": 0.4,
                    "reference_comment": "The paper should clarify how the grounding is achieved and what knowledge is assumed to arrive at the presented results.",
                    "predicted_comment": "The section on generating a lifted, typed model could benefit from a more detailed explanation of the steps involved, including the specific algorithms or techniques used. This should include a comprehensive explanation of the preprocessing steps used to reduce the dimensionality of the state space, the principal component analysis, and the rationale behind selecting the top 40 principal components. Additionally, it would be beneficial to provide more clarity on how the precondition classifiers and effect estimators are trained and validated, including any cross-validation or other techniques used to prevent overfitting."
                }
            ]
        },
        "metrics": {
            "all": {
                "n_reference": 13,
                "n_generated": 12,
                "n_total_aligns": 1,
                "recall": 0.047619047619047616,
                "precision": 0.027777777777777776,
                "pseudo_jaccard": 0.018518518518518517,
                "specificity_more": 1.0,
                "specificity_less": 0.0,
                "specificity_same": 0.0
            }
        },
        "metrics_for_reviews": {
            "all": [
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 3
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 3
                },
                {
                    "recall": 0.14285714285714285,
                    "precision": 0.08333333333333333,
                    "pseudo_jaccard": 0.05555555555555555,
                    "n_real": 7
                }
            ]
        }
    },
    {
        "doc_id": "EG5Pgd7-MY",
        "method": "gpt_independent_chunk",
        "reference_comments": [
            [
                "The contributions of the paper are not clearly stated in the introduction section, making it difficult to identify the main contributions.",
                "The proposed framework, which connects membership inference attacks with binary hypothesis testing, lacks novelty as it has been previously proposed in other works.",
                "The paper heavily relies on the assumption introduced in equation (1) to characterize the outcome of the algorithm obtained via SGD training, but no valid proof or formal justification for this assumption is provided.",
                "The paper lacks numerical results and comparisons with competing methods for building attacks in the literature.",
                "The tradeoffs between Type I and Type II error are not always reported.",
                "There is a lack of diverse datasets and relevant architectures to validate the results."
            ],
            [
                "The paper does not clearly explain how having multiple specific forms of attacks can provide a comprehensive picture of whether an algorithm is private or not.",
                "The paper does not provide any justification as to why their set of attacks are 'complete'.",
                "The paper's plans are cryptic and each page has many ambiguous sentences with unclear goals.",
                "The paper does not clearly justify why they pick certain criteria and focus on them.",
                "The paper's definition of privacy is an 'average case, computational, indistinguishability-based' variation of DP, which is not standard DP.",
                "The first attack writes probabilities P(theta|D) as if we are aware of the learning algorithm, which is an assumption that needs to be clarified.",
                "The paper's assertion that 'The population data used for constructing the attack algorithm, and evaluating the inference game, need to be similar, in distribution, to the training data' needs proof.",
                "The paper's claim that 'By violating this principle, we might overestimate the privacy loss' is incorrect as the whole point of DP is that the adversary might have arbitrary auxiliary information.",
                "The paper's statement 'The adversary knows the underlying data distribution' is unclear.",
                "The paper's use of pi(z) in Equation (4) is questionable as z should be independent of theta and D in that case.",
                "The paper does not specify the learner in the experiments of the main body.",
                "The paper needs a much more detailed and justified approach, arguing for 'complete' attacks that at least 'capture known attack techniques so far'.",
                "The paper needs to be much clearer in its criteria that it proposes (in addition to the success rate of the attacks) to be part of the 'report' on privacy."
            ],
            [
                "Many of the attacks proposed could still be inefficient for auditing purposes as one might need to train 1000 reference models to perform the attacks. The numbers are also only high for models that are extremely overfitting. The paper should discuss how to audit models that are well-generalized.",
                "The comparison and difference between this work and prior work is vaguely discussed. There is no detailed comparison with [1], which also formalized MIA with an indistinguishability based framework. The hypothesis testing framework in this work is very similar to the threshold adversary in [1]. The authors should discuss the differences in detail. There is also no comparison to white-box models (e.g. [2]). The authors should discuss how this compares to the proposed framework.",
                "No connection is made between this work and differential privacy, although the indistinguishability setup is highly related. The authors should discuss how the framework translates to privacy loss in DP."
            ]
        ],
        "generated_comments": {
            "all": [
                "To enhance the readability of the paper, consider breaking down complex sections into smaller, more digestible parts. Ensure that transitions between different sections and ideas are clear and logical. This will improve the paper's accessibility and help readers follow your arguments more easily.",
                "The paper would benefit from a more detailed, step-by-step explanation of the hypothesis testing framework and the construction of membership inference attacks. Before delving into the technical details, consider providing an intuitive explanation or a simplified overview. This will help readers, especially those unfamiliar with the topic, to better understand your methodology.",
                "Consider incorporating more visual aids, such as diagrams or flowcharts, to aid understanding of the concepts and processes being discussed. Ensure that all referred figures, tables, and equations are included and properly numbered in the final version of the paper. This will provide readers with a visual representation of your work and can help clarify complex concepts or processes.",
                "The results of the empirical evaluation of your attack strategies should be included, along with a detailed discussion of their implications. Provide more detailed explanations of these results in the text and how they contribute to the overall goals of the study. This will help readers understand the significance of your findings and their impact on the field.",
                "A more detailed comparison of your work with previous studies would be beneficial. Discuss how your approach improves upon or differs from existing methods and highlight the novel contributions of the current study. This will help readers understand the unique value of your work and its place within the existing body of research.",
                "Include a section discussing the limitations of the current study and potential directions for future research. Discuss the limitations of the proposed attacks and potential ways to mitigate these limitations. This will provide a balanced view of your work and indicate areas where further research could be beneficial.",
                "Discuss the practical implications of your work, including how your findings can be used in real-world settings and the potential impact on the field of machine learning and privacy protection. This will help readers understand the real-world relevance of your research and its potential to influence practice.",
                "Provide more information about the datasets (Purchase100, CIFAR100, MNIST), such as their source, their characteristics, and why they were chosen for this study. This will help readers understand the context of your research and the rationale behind your choice of datasets.",
                "Provide more details about the simulation process of the DP adversary, such as the specific steps involved or the rationale behind this approach. This will help readers understand the methodology of your research and the reasoning behind your choices.",
                "Ensure that any external links included in the paper are accompanied by some context or explanation to clarify how these resources are related to the content of the paper. This will help readers understand the relevance of these resources to your work.",
                "Provide a more detailed explanation or a brief overview of how membership inference attacks work. Elaborate on the point about the empirical performance of membership inference attacks providing lower bounds on the privacy guarantees. This will help readers understand the key concepts of your research and the significance of your findings."
            ]
        },
        "alignments": {
            "all": [
                {
                    "reference_id": 3,
                    "predicted_id": 3,
                    "relative_specificity": "more",
                    "relatedness": "medium",
                    "pairwise_result": {
                        "relatedness": "medium",
                        "relative_specificity": "more",
                        "same_meaning": true
                    },
                    "count": 4,
                    "score": 0.8,
                    "reference_comment": "The paper lacks numerical results and comparisons with competing methods for building attacks in the literature.",
                    "predicted_comment": "The results of the empirical evaluation of your attack strategies should be included, along with a detailed discussion of their implications. Provide more detailed explanations of these results in the text and how they contribute to the overall goals of the study. This will help readers understand the significance of your findings and their impact on the field."
                },
                {
                    "reference_id": 0,
                    "predicted_id": 4,
                    "relative_specificity": "more",
                    "relatedness": "medium",
                    "pairwise_result": {
                        "relatedness": "medium",
                        "relative_specificity": "more",
                        "same_meaning": true
                    },
                    "count": 2,
                    "score": 0.4,
                    "reference_comment": "The contributions of the paper are not clearly stated in the introduction section, making it difficult to identify the main contributions.",
                    "predicted_comment": "A more detailed comparison of your work with previous studies would be beneficial. Discuss how your approach improves upon or differs from existing methods and highlight the novel contributions of the current study. This will help readers understand the unique value of your work and its place within the existing body of research."
                },
                {
                    "reference_id": 1,
                    "predicted_id": 4,
                    "relative_specificity": "more",
                    "relatedness": "medium",
                    "pairwise_result": {
                        "relatedness": "medium",
                        "relative_specificity": "more",
                        "same_meaning": true
                    },
                    "count": 2,
                    "score": 0.4,
                    "reference_comment": "The proposed framework, which connects membership inference attacks with binary hypothesis testing, lacks novelty as it has been previously proposed in other works.",
                    "predicted_comment": "A more detailed comparison of your work with previous studies would be beneficial. Discuss how your approach improves upon or differs from existing methods and highlight the novel contributions of the current study. This will help readers understand the unique value of your work and its place within the existing body of research."
                },
                {
                    "reference_id": 2,
                    "predicted_id": 0,
                    "relative_specificity": "more",
                    "relatedness": "medium",
                    "pairwise_result": {
                        "relatedness": "medium",
                        "relative_specificity": "more",
                        "same_meaning": true
                    },
                    "count": 3,
                    "score": 0.6,
                    "reference_comment": "The paper's plans are cryptic and each page has many ambiguous sentences with unclear goals.",
                    "predicted_comment": "To enhance the readability of the paper, consider breaking down complex sections into smaller, more digestible parts. Ensure that transitions between different sections and ideas are clear and logical. This will improve the paper's accessibility and help readers follow your arguments more easily."
                }
            ]
        },
        "metrics": {
            "all": {
                "n_reference": 22,
                "n_generated": 11,
                "n_total_aligns": 4,
                "recall": 0.1923076923076923,
                "precision": 0.0909090909090909,
                "pseudo_jaccard": 0.0719640179910045,
                "specificity_more": 1.0,
                "specificity_less": 0.0,
                "specificity_same": 0.0
            }
        },
        "metrics_for_reviews": {
            "all": [
                {
                    "recall": 0.5,
                    "precision": 0.18181818181818182,
                    "pseudo_jaccard": 0.1724137931034483,
                    "n_real": 6
                },
                {
                    "recall": 0.07692307692307693,
                    "precision": 0.09090909090909091,
                    "pseudo_jaccard": 0.043478260869565216,
                    "n_real": 13
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 3
                }
            ]
        }
    },
    {
        "doc_id": "DILxQP08O3B",
        "method": "gpt_independent_chunk",
        "reference_comments": [
            [
                "The paper doesn't fully address why DETR performs better than FasterRCNN features. It's not clear why DETR is doing better than Faster-RCNN especially when the detection accuracy of DETR is also better than Faster RCNN.",
                "The method for obtaining the appearance features from Faster RCNN based method is not clear. It's not explained how it's different from the approach taken by Bottom-Up, Top-Down paper in which 2048-dim appearance features are extracted for each visual region.",
                "The experimental setup isn't fully reflective of the object goal navigation task. The experiments are conducted in AI2 thor scenes which only contain one room. It's not clear how this method will perform when evaluated on significantly more complicated environments like Matterport / Gibson.",
                "The navigation task is simplified by discretizing into a grid. Single room environments and discrete grids simplify a lot of navigation-related challenges and the authors don't discuss how the proposed architecture will generalize to more complex object navigation tasks.",
                "The use of spatial embeddings as well as appearance embedding isn't all that surprising. Existing work including Du et al. uses bounding box coordinates to help learn spatial associations between objects.",
                "It's not clear how the agent learns long-term associations between objects across multiple frames. The proposed architecture puts all the burden of learning these long-term object relationships across multiple frames on the LSTM policy since the VT only learns association within a single frame."
            ],
            [
                "The paper adopts the Transformer and adapts it for the navigation problem, but does not propose a new architecture or model.",
                "A similar usage of the Transformer has already been demonstrated in the vision-and-language navigation task. The referenced paper also shows that pre-training of navigation tasks using Transformers can help to boost performance."
            ],
            [
                "The writing in the approach section isn't very clear. It would be better to define clear notations for all the features/descriptors and use such notations in the figure. The current writing uses various terms like 'instance feature', 'global feature', 'positional-global', 'spatial feature', 'spatial-enhanced', which are confusing.",
                "The details in Fig.2 are not sufficient and it is not as informative as the detailed version (Fig.4) in Appendix. These two figures are not consistent, for example, the 'add' symbol for positional enhancement is missing in Fig.4.",
                "In Sec.4.2, it is not clear how the reduction of the channel dimension of a high-level activation map from D to a smaller dimension d is done.",
                "The terms $h$, 'w', and $L$ are used inconsistently in the paper, causing confusion.",
                "The statement in Sec.4.1 about Faster RCNN being blamed for scale-sensitive is not fully convincing. It is unclear what scale-sensitive means here and why DETR doesn't suffer from it.",
                "The statement about 'early stopping' in Sec.4.4 is not fully convincing. It is unclear why the transformer-based representation learner suffers from 'early stopping'.",
                "The SPL formulation in Sec.5.1 seems to be incorrect. The success indicator seems to be missing.",
                "It is unclear why global features are not also added into the transformer encoder."
            ],
            [
                "The introduction of the paper is difficult to understand as it discusses details such as the difference between DETR and Faster RCNN or difficulty of training the transformers without providing a high-level overview of the proposed method.",
                "The paper does not provide a satisfactory explanation for why nothing is learned without the imitation pre-training.",
                "The paper should run the method on other frameworks which include slightly larger scenes, such as RoboTHOR, to test if the method generalizes to those as well."
            ]
        ],
        "generated_comments": {
            "all": [
                "To provide a more comprehensive context for your work, consider expanding the introduction with a detailed overview of the current state of visual navigation. This would help readers understand the problem you are addressing and the significance of your work in the broader field.",
                "The methodology section, specifically the explanation of the Visual Transformer Network (VTNet), could be more detailed. A step-by-step walkthrough of the VTNet and its components, including the spatial-enhanced local object descriptor and positional global descriptor, would be beneficial. A diagram or flowchart could be a valuable addition to visually represent the process and help readers understand the architecture and functioning of VTNet.",
                "The section on the pre-training scheme could benefit from a more in-depth discussion. Specifically, it would be helpful to understand why imitation learning was chosen over other potential methods and how it contributes to the overall system. Addressing any potential limitations or drawbacks of this approach would also provide a more balanced view of the methodology.",
                "A section that directly compares the VTNet with other state-of-the-art methods would be beneficial. This should include a brief overview of each method, an explanation of why these specific methods were chosen for comparison, and a discussion on why the VTNet performs better and under what conditions. This would provide a clearer understanding of the unique advantages of VTNet.",
                "The experimental results section could provide more detailed information about the experimental setup and the results obtained. Specifically, it would be helpful to understand more about the evaluation metrics used, such as the success rate and Success Weighted by Path Length (SPL), and why these metrics were chosen. This would provide readers with a clearer understanding of how the performance of VTNet was evaluated and why these metrics are appropriate.",
                "To ensure the reproducibility of the results, it would be helpful to provide more details about the experimental setup. This should include the specific parameters used, the hardware and software environment, and any other necessary details. This would allow other researchers to replicate your experiments and validate your findings.",
                "A section discussing potential limitations of the VTNet and suggestions for future work would provide a more balanced view of the work. This could include limitations in the current design of VTNet, potential challenges in different scenarios, and areas where VTNet could be further improved or extended.",
                "The conclusion could provide a more detailed summary of your findings and their implications. Discuss potential future research directions based on your findings to help readers understand the significance of your work and its potential impact on the field of visual navigation. This would provide a clear takeaway message and highlight the future potential of your work."
            ]
        },
        "alignments": {
            "all": [
                {
                    "reference_id": 1,
                    "predicted_id": 2,
                    "relative_specificity": "more",
                    "relatedness": "high",
                    "pairwise_result": {
                        "relatedness": "high",
                        "relative_specificity": "more",
                        "same_meaning": true
                    },
                    "count": 5,
                    "score": 1.0,
                    "reference_comment": "The paper does not provide a satisfactory explanation for why nothing is learned without the imitation pre-training.",
                    "predicted_comment": "The section on the pre-training scheme could benefit from a more in-depth discussion. Specifically, it would be helpful to understand why imitation learning was chosen over other potential methods and how it contributes to the overall system. Addressing any potential limitations or drawbacks of this approach would also provide a more balanced view of the methodology."
                }
            ]
        },
        "metrics": {
            "all": {
                "n_reference": 19,
                "n_generated": 8,
                "n_total_aligns": 1,
                "recall": 0.08333333333333333,
                "precision": 0.03125,
                "pseudo_jaccard": 0.025,
                "specificity_more": 1.0,
                "specificity_less": 0.0,
                "specificity_same": 0.0
            }
        },
        "metrics_for_reviews": {
            "all": [
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 6
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 2
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 8
                },
                {
                    "recall": 0.3333333333333333,
                    "precision": 0.125,
                    "pseudo_jaccard": 0.1,
                    "n_real": 3
                }
            ]
        }
    },
    {
        "doc_id": "fmOOI2a3tQP",
        "method": "gpt_independent_chunk",
        "reference_comments": [
            [
                "The paper does not clearly demonstrate if any insight is gained from the theoretical analysis, as the derivation of value and sample complexity bounds for approximate bisimulation was already performed in Gelada et al. 2019.",
                "The empirical gains are modest and it's unclear if they are due to the image representation learning component of the loss or other aspects of the method.",
                "The paper uses a very small number of training tasks - only 4. It's unclear if using more training tasks would improve the generalization of single-task methods like DeepMDP.",
                "There seems to be a missing baseline - a generic multi-task algorithm that conditions on the environment ID but does use the bisimulation loss to help process the image observations.",
                "It's unclear why there's a gap between your method in the multi-task experiments but not in the meta-RL ones.",
                "It's not explained why HiP-BMDP handles the sticky observation setting better than the baselines.",
                "The paper does not convincingly demonstrate that the structural assumptions on the MDP used by the proposed algorithm yield performance improvement."
            ],
            []
        ],
        "generated_comments": {
            "all": [
                "Consider revising the section titles to be more descriptive and indicative of the content within each section. This will enhance the readability and organization of the paper, allowing readers to better navigate through the content and understand the progression of your arguments.",
                "The abstract could benefit from simplification and clarification. Aim to provide a more straightforward explanation of the problem and the proposed solution. This will allow readers to quickly grasp the key points of your research.",
                "The introduction and background sections could be expanded to provide more context to the problem you are addressing. This will help readers unfamiliar with the topic understand the significance of the research and its relevance in the field.",
                "When introducing key concepts and terminologies, such as 'HiP-BMDP', 'Distral-Ensemble', and 'task-embeddings', consider providing brief explanations or definitions. This will make the paper more accessible to a broader audience and ensure that readers are not lost in technical jargon.",
                "The equations, theorems, and algorithms used in the paper could be explained in more detail. Some of the equations are not clearly explained, which may make it difficult for readers to follow your reasoning. Including all relevant equations and providing clear explanations will aid reader understanding and ensure completeness.",
                "In the theoretical analysis section, consider providing more context for the theorem and its implications. More intuitive explanations or examples could help readers understand the complex mathematical proofs and theorems. This will enhance the accessibility of your paper to readers with varying levels of mathematical expertise.",
                "Consider including more visual aids, such as diagrams or flowcharts, to help explain the concepts, methods, and the experimental setup. This will enhance reader understanding and engagement, and provide a visual reference that complements the text.",
                "The experimental setup could be described in more detail, including specific parameters used, how the training was conducted, and how the results were analyzed. For instance, listing the hyperparameters used by PEARL Rakelly et al. (2019) in the paper would enhance completeness and reproducibility.",
                "More details about the results of your research could be included. Consider using more visual aids such as graphs or charts to illustrate the results. Providing specific numbers or statistical tests will strengthen your claim that your proposed approach converges faster in some environments.",
                "A more detailed discussion of the results, their implications, and the limitations of the proposed method would be beneficial. This would help readers understand the significance of the findings, how they contribute to the field, and the potential limitations of the proposed method.",
                "Consider elaborating more on how the proposed method differs from and improves upon existing methods. This will help readers understand the unique contributions of your work.",
                "Potential future directions for this research, including potential applications, modifications, or extensions of the proposed method, could be discussed in more detail. This will provide readers with a sense of the potential impact and future developments of your work.",
                "A conclusion that summarizes the main points of the paper, discusses the implications of the findings, and suggests directions for future research would be beneficial. This will help readers understand the key takeaways from your work.",
                "Ensure that all references are correctly cited and formatted, and that all references in the text have corresponding citations in the reference list. For instance, the full citation for the Rakelly et al., 2019 paper that you refer to multiple times should be provided.",
                "Consider revising the paper for clarity and coherence. Some sentences are difficult to understand due to complex language and long, run-on sentences. Clear and concise language will enhance reader understanding."
            ]
        },
        "alignments": {
            "all": []
        },
        "metrics": {
            "all": {
                "n_reference": 7,
                "n_generated": 15,
                "n_total_aligns": 0,
                "recall": 0.0,
                "precision": 0.0,
                "pseudo_jaccard": 0.0,
                "specificity_more": NaN,
                "specificity_less": NaN,
                "specificity_same": NaN
            }
        },
        "metrics_for_reviews": {
            "all": [
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 7
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 0
                }
            ]
        }
    },
    {
        "doc_id": "hbzCPZEIUU",
        "method": "gpt_independent_chunk",
        "reference_comments": [
            [
                "The comparison in the experiment section is weak without any reference to existing prior arts such as Chen et al., Fine-grained representation learning and recognition by exploiting hierarchical semantic embedding, ACM-MM 2018.",
                "There is a significant performance gap between the proposed method and the latest methods when considering the 5 experiment datasets.",
                "The baseline performance in the experiments shows considerable gaps to standard baseline training without bells and whistles, raising questions about its solidity.",
                "The performance gain of the proposed method diminishes very quickly on bigger datasets such as Tiny ImageNet, and the results on ImageNet are not provided.",
                "The proposed method depends on a pre-defined semantic hierarchical graph rather than a learned one, which potentially limits the technical value of this work.",
                "There is concern about the selection of initial radius $R_0$ and its decay policy, as these parameters should be dataset dependent due to different numbers of categories and the densities of class distributions.",
                "Forcing a fixed radius does not seem as reasonable as allowing a learnable radius with soft regularization."
            ],
            [
                "The empirical evaluation is relatively weak and the evaluation metric does not well reflect the advantages of hierarchically modelling the label space. It would be more informative to incorporate the classification accuracy of the super-classes.",
                "More experiments that analyze the difference in feature distributions between normally trained neural networks and the hierarchically trained neural networks are needed. An intuitive visualization of the feature space would be of great interest.",
                "Important ablation studies to justify some heuristic designs are necessary. For example, the effect of the hyperparameter in the radius decay on performance is crucial. Evaluations should be conducted on what happens if no sphericity constraint is applied, or if no radius decay is used.",
                "The empirical evaluation does not convincingly demonstrate the usefulness of modeling the hierarchical label space, especially in experiments on CIFAR-100 and Tiny-ImageNet. More discussions and insights on this issue would be useful.",
                "The usefulness of the hierarchical label structure should be evaluated and verified. A simple way to evaluate it is to use some random assignment or simple K-means assignments for the super-classes. If using the ground truth hierarchical structure consistently outperforms the random or K-means super-class assignment, then it can be argued that incorporating the ground truth hierarchical label structure is indeed useful."
            ],
            [
                "Section 2 needs more specific definitions for terms such as 'classifier' and 'separators'. For example, in equation (2), Wp and Wpi are called classifiers. Are these hyperplanes?",
                "In Definition 1, it would be helpful to provide early examples of P and L to make it easier to interpret the matrix H.",
                "The notation for Delta in equation (8) could be confusing as it may remind an operator on H in equation (9). Consider using a different notation.",
                "In equation (9), it is unclear whether deltas in the same subtree are required or observed to be in roughly the same direction.",
                "In Section 3, the claim that no hyperparameters are added seems incorrect. Initial radius R0, radius decay parameter, and the organization of classes could all be considered additional hyperparameters.",
                "In practice, defining mutually exclusive class partitions to form the required class tree in Figure 1 can be non-trivial or even impossible. The authors should discuss how different class hierarchies affect the classification accuracy, for example, in Table 2."
            ],
            [
                "The third paragraph of Section 1 is unclear about why Euclidean distance is not sufficient for learning with hierarchical regularization.",
                "The paper does not clearly explain whether the whole model follows end-to-end training or stage-wise training.",
                "In Section 2.2, the definition of 'separator' is unclear and the sentence about classifiers identifying dog breeds being similar is confusing.",
                "The paper does not provide a clear rationale or related work for the use of radius decay in Section 3.1.",
                "The optimization method used for learning other layers is not specified.",
                "The paper does not provide a clear explanation or justification for the construction of the spherical fully-connected layer.",
                "The paper does not present the hierarchical structure in a visually appealing or clear way.",
                "The paper does not clearly explain whether images from datasets Dogs and Tiny-Imagenet are part of ImageNet or if the classes in the two datasets are included in the set of ImageNet classes.",
                "The definition of 'plain networks' in Section 4.1 is unclear.",
                "The paper does not justify its claim of 'high efficiency' in Section 4.2.1.",
                "The paper does not formally compare Riemannian gradient and 'projected gradient' in Figure 2 right.",
                "The paper does not discuss how the proposed method may work if classes do not follow a tree hierarchy.",
                "The explanation of why 'Euclidean distance is not sufficient for learning such a hierarchical regularization' in the rebuttal is not intuitive or concrete.",
                "The paper does not clearly explain whether other methods suffer severely from the choice of learning rate and scheduler.",
                "The blue line in Page-2 is confusing and the logic of why diversity reduces over-fitting is unclear.",
                "The tSNE visuals in Figure 5 are not adequately analyzed."
            ]
        ],
        "generated_comments": {
            "all": [
                "The abstract could be enhanced by including the main results or findings. This would provide readers with a clearer understanding of the paper's contributions and impact.",
                "The concept of hierarchical structures, especially in the context of deep neural networks, could be elaborated further. Providing practical examples or use-cases would help readers understand the real-world implications of your work.",
                "A detailed step-by-step walkthrough of the proposed technique would be beneficial for readers. This could be supported by a diagram or flowchart to aid understanding.",
                "The methodology section could be clearer, particularly regarding the spherical constraints and the Riemannian optimization. A simpler example or a more intuitive explanation could be beneficial.",
                "A detailed comparison of the proposed technique with existing methods, such as hyperbolic networks and Poincar\u00e9 networks, would be useful. This could be presented in a table format, outlining the advantages and disadvantages of each method. Additionally, a comparison with other state-of-the-art methods for hierarchical classification would provide a clearer understanding of the proposed method's performance.",
                "More information about the experimental setup, including the datasets used and the training process, would be beneficial.",
                "A dedicated section presenting the experimental results in detail would be helpful. This should include the specific improvements observed and any statistical analysis performed.",
                "A discussion of the proposed technique's limitations and potential areas for future research would provide a more balanced view of the technique and its potential applications.",
                "Including visualizations, such as diagrams or plots, would aid in explaining the method and results.",
                "Making the code available would allow others to reproduce the results and increase the impact of the work.",
                "A conclusion summarizing the main points, reiterating the contributions, and discussing potential future work would provide a clear ending to the paper.",
                "Separating the discussion of the ResNet and DenseNet models into distinct subsections would improve readability.",
                "More details on how the settings for SGD were chosen would be beneficial. Information on whether any parameter tuning was performed would also be useful.",
                "More quantitative results or a graph illustrating the effect of radius decay on the network's accuracy would be helpful.",
                "A discussion on the potential impact of different hierarchy construction methods on the results would be beneficial.",
                "Testing other popular models on the same tasks would provide a more comprehensive evaluation of the proposed method.",
                "Providing the exact version of PyTorch and other key libraries used in the experiments would ensure reproducibility."
            ]
        },
        "alignments": {
            "all": [
                {
                    "reference_id": 0,
                    "predicted_id": 4,
                    "relative_specificity": "more",
                    "relatedness": "medium",
                    "pairwise_result": {
                        "relatedness": "medium",
                        "relative_specificity": "more",
                        "same_meaning": true
                    },
                    "count": 3,
                    "score": 0.6,
                    "reference_comment": "The comparison in the experiment section is weak without any reference to existing prior arts such as Chen et al., Fine-grained representation learning and recognition by exploiting hierarchical semantic embedding, ACM-MM 2018.",
                    "predicted_comment": "A detailed comparison of the proposed technique with existing methods, such as hyperbolic networks and Poincar\u00e9 networks, would be useful. This could be presented in a table format, outlining the advantages and disadvantages of each method. Additionally, a comparison with other state-of-the-art methods for hierarchical classification would provide a clearer understanding of the proposed method's performance."
                },
                {
                    "reference_id": 4,
                    "predicted_id": 14,
                    "relative_specificity": "more",
                    "relatedness": "medium",
                    "pairwise_result": {
                        "relatedness": "medium",
                        "relative_specificity": "more",
                        "same_meaning": true
                    },
                    "count": 2,
                    "score": 0.4,
                    "reference_comment": "The proposed method depends on a pre-defined semantic hierarchical graph rather than a learned one, which potentially limits the technical value of this work.",
                    "predicted_comment": "A discussion on the potential impact of different hierarchy construction methods on the results would be beneficial."
                }
            ]
        },
        "metrics": {
            "all": {
                "n_reference": 34,
                "n_generated": 17,
                "n_total_aligns": 2,
                "recall": 0.07142857142857142,
                "precision": 0.029411764705882353,
                "pseudo_jaccard": 0.022727272727272728,
                "specificity_more": 1.0,
                "specificity_less": 0.0,
                "specificity_same": 0.0
            }
        },
        "metrics_for_reviews": {
            "all": [
                {
                    "recall": 0.2857142857142857,
                    "precision": 0.11764705882352941,
                    "pseudo_jaccard": 0.09090909090909091,
                    "n_real": 7
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 5
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 6
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 16
                }
            ]
        }
    },
    {
        "doc_id": "ab7lBP7Fb60",
        "method": "gpt_independent_chunk",
        "reference_comments": [
            [
                "The proposed method is not compatible with federated averaging, which is a significant limitation in federated learning due to the communication bottleneck characteristic of federated settings.",
                "The paper does not compare the proposed method to prior work on group fairness in the centralized setting, such as the work by Zafar et al., (2017). An in-depth experimental evaluation of this aspect is needed to motivate the proposed approach.",
                "The proposed method may be susceptible to a potential privacy violation, as the statistics shared at every round include the number of individuals per protected attribute for every client. This could be exploited to learn an unfair model with respect to certain sensitive attributes.",
                "The paper incorrectly characterizes prior fair federated learning approaches, such as the work by Li et al. (2019), as individual fairness methods. These methods enforce uniform performance across all devices, which is neither individual nor group fairness, but a novel notion tailored to the federated learning setting."
            ],
            [
                "The paper is missing important literature review, including methods that enforce group fairness in Federated Learning such as 'Fair and Consistent Federated Learning' by Cui et al. 2021. These could have been considered as a baseline for comparing their method.",
                "The paper does not include enough baselines for Fair Federated Learning to compare against. Even if some methods do not satisfy privacy considerations, they should still be included for the reader to understand how the proposed method compares against such methods, especially given that the results are not promising. Some baselines to consider include Cui et al or Tran et al.",
                "The authors need to justify some of the incompatibility results shown in previous work between fairness and privacy.",
                "Algorithm 1 needs improvement. It is unclear what the clients do, what 'UpdateMultiplier', 'UpdateParameters', and 'Calculate noiseScale' mean.",
                "The results are not promising for predictive parity among groups. There is also a reduction in accuracy. The authors should discuss why this is the case. Including the suggested baselines could provide a sense of what other methods achieve in terms of loss in accuracy, etc.",
                "The results for the central setting should be included in Table 2."
            ]
        ],
        "generated_comments": {
            "all": [
                "To enhance reader comprehension, consider adding a brief summary at the end of each section to reinforce the key points and findings. This will help readers to better understand and remember the content of each section.",
                "The FPFL algorithm could be better explained by providing details about its computational complexity and scalability. A pseudocode representation could also aid in understanding. Furthermore, a brief explanation or a reference to a source about the MMDM algorithm would be beneficial for readers unfamiliar with it.",
                "Ensure that all referred equations are included in the text and properly numbered for clarity and continuity. This will help readers follow your methodology more easily.",
                "A more comprehensive review of existing methods for enforcing fairness in machine learning models, especially those in the federated learning setting, would be beneficial. This should include a detailed comparison with other state-of-the-art methods in the field, to provide a broader context for your work.",
                "More details about the experimental setup would facilitate reproducibility. This includes the specific metrics used to evaluate the performance of the algorithm, the baseline methods for comparison, model architecture, training procedure, and hyperparameters. Testing the algorithm on more diverse datasets would also demonstrate its robustness and generalizability.",
                "More detailed results of your experiments would be beneficial, including specific numbers or comparisons for the accuracy of the models when trained with FPFL, especially for the under-represented group. Visualizations, such as graphs or charts, could better illustrate the results of the experiments.",
                "A discussion on the potential applications and implications of your work in real-world scenarios would be valuable. This should include a discussion on the limitations of the proposed method, including situations where the method might not perform as expected, assumptions made by the method, and potential areas for future improvement.",
                "A more detailed explanation or proof of how the proposed algorithm achieves privacy guarantees would be beneficial. Brief explanations of the fairness metrics used in the paper would help readers unfamiliar with them. Using a variety of fairness metrics to evaluate the method would provide a comprehensive understanding of its fairness properties.",
                "Discussing the real-world applicability of the method, including its performance in a real-world federated learning scenario with potentially millions of users, would be valuable. A robustness analysis of the method, testing it under different noise levels or varying the number of users, would also be beneficial.",
                "Ensure that all references are correctly cited and formatted. For instance, the reference to the Gaussian filter implementation from SciPy (Virtanen et al.) appears to be incomplete. Correct citation is crucial for readers who wish to delve deeper into the referenced works."
            ]
        },
        "alignments": {
            "all": [
                {
                    "reference_id": 2,
                    "predicted_id": 7,
                    "relative_specificity": "more",
                    "relatedness": "medium",
                    "pairwise_result": {
                        "relatedness": "medium",
                        "relative_specificity": "more",
                        "same_meaning": true
                    },
                    "count": 2,
                    "score": 0.4,
                    "reference_comment": "The proposed method may be susceptible to a potential privacy violation, as the statistics shared at every round include the number of individuals per protected attribute for every client. This could be exploited to learn an unfair model with respect to certain sensitive attributes.",
                    "predicted_comment": "A more detailed explanation or proof of how the proposed algorithm achieves privacy guarantees would be beneficial. Brief explanations of the fairness metrics used in the paper would help readers unfamiliar with them. Using a variety of fairness metrics to evaluate the method would provide a comprehensive understanding of its fairness properties."
                },
                {
                    "reference_id": 4,
                    "predicted_id": 5,
                    "relative_specificity": "more",
                    "relatedness": "medium",
                    "pairwise_result": {
                        "relatedness": "medium",
                        "relative_specificity": "more",
                        "same_meaning": true
                    },
                    "count": 4,
                    "score": 0.8,
                    "reference_comment": "The results are not promising for predictive parity among groups. There is also a reduction in accuracy. The authors should discuss why this is the case. Including the suggested baselines could provide a sense of what other methods achieve in terms of loss in accuracy, etc.",
                    "predicted_comment": "More detailed results of your experiments would be beneficial, including specific numbers or comparisons for the accuracy of the models when trained with FPFL, especially for the under-represented group. Visualizations, such as graphs or charts, could better illustrate the results of the experiments."
                }
            ]
        },
        "metrics": {
            "all": {
                "n_reference": 10,
                "n_generated": 10,
                "n_total_aligns": 2,
                "recall": 0.20833333333333331,
                "precision": 0.1,
                "pseudo_jaccard": 0.07179487179487179,
                "specificity_more": 1.0,
                "specificity_less": 0.0,
                "specificity_same": 0.0
            }
        },
        "metrics_for_reviews": {
            "all": [
                {
                    "recall": 0.25,
                    "precision": 0.1,
                    "pseudo_jaccard": 0.07692307692307693,
                    "n_real": 4
                },
                {
                    "recall": 0.16666666666666666,
                    "precision": 0.1,
                    "pseudo_jaccard": 0.06666666666666667,
                    "n_real": 6
                }
            ]
        }
    },
    {
        "doc_id": "rsf1z-JSj87",
        "method": "gpt_independent_chunk",
        "reference_comments": [
            [
                "The performance of the proposed model is promising, but still below the baselines.",
                "The claim of the model being end-to-end is misleading as the character-based model is not performing well, and the phoneme-based model is not truly end-to-end, as the grapheme-to-phoneme (g2p) part is not trained jointly.",
                "The reason behind using an adversarial loss is not adequately explained in the paper. A few lines before section 2.1 would help clarify that.",
                "It's not clear which dataset was used in the experiment. If it is a private dataset, please state it clearly."
            ],
            [
                "The paper does not provide a comparison over the computational cost or model size. This is particularly important because the proposed model is non-autoregressive and may be capable of real-time inference.",
                "The paper does not use widely accepted benchmark datasets. A more direct comparison would be beneficial.",
                "The proposed aligner module doesn't seem to be very useful compared with the attention-based aligner as seen in the ablation study (Table 1): there is only a very small improvement from 3.551 to 3.559 MOS. More explanation is needed."
            ],
            [
                "The elegance in the architecture is overshadowed by the complicated training algorithm, making the method look a bit heuristic and harder to reproduce.",
                "The authors should provide brief guidelines for readers trying to reimplement EATS, such as how to tune the hyperparameters.",
                "EATS performs slightly worse than GAN-TTS, which does not quite show the benefit of end-to-end training. It would be worthwhile to expand the discussion a bit by showing further experiments that demonstrate the potential benefit of end-to-end training.",
                "Without a clearly interpretable hidden representation, it is harder to have direct control over prosody. The authors should discuss how prosody control would be possible under the end-to-end framework."
            ],
            [
                "The paper lacks a comparison with Tacotron 2 in Table 1. This would be informative as all the baselines are trained on aligned data while Tacotron is a legitimate contender for EATS as it can be trained on the same data.",
                "The authors claim that their method is simpler because the training is in one stage. However, given the large number of losses and components in their model, with their respective hyper-parameters to tune, the simplicity argument is not entirely convincing.",
                "The performance of the transformer attention is surprisingly poor, particularly in the audio samples where the output for this model is garbage towards the end of the signal. The authors should provide an explanation for this."
            ]
        ],
        "generated_comments": {
            "all": [
                "The EATS model, particularly the aligner and decoder components, could benefit from a more detailed explanation. Consider including a section that provides a comprehensive description of the EATS model, including its architecture, training process, and unique features.",
                "To aid in understanding the model's structure and the flow of information, consider including a diagram illustrating the architecture of the EATS model. Additionally, consider including graphs or charts to visually represent the performance of the model.",
                "A detailed comparison with state-of-the-art models would be valuable. Discuss the advantages and disadvantages of your approach in comparison to these existing models. A separate section or table that clearly outlines the differences and advantages of the EATS model over other models would be helpful.",
                "Additional experiments, such as testing on different datasets or using different evaluation metrics, could further validate your model. Please provide more detailed results of these experiments.",
                "A section discussing the limitations of the proposed model would provide valuable insights for future research. Discuss any limitations or potential drawbacks of the EATS model.",
                "Making your code and models available would increase the reproducibility of the results and allow other researchers to replicate your results and further build upon your work.",
                "A section on potential future work, including potential improvements to the model or other applications of the model that could be explored, would be beneficial.",
                "The missing equation in the 'ALIGNER LENGTH LOSS' section should be included to provide a complete understanding of the length loss calculation. Consider including the pseudocode or a brief overview of the soft DTW procedure in the main body of the paper.",
                "More information about the dataset used for training the models, including how it was collected, any preprocessing steps, and the rationale behind choosing this specific dataset, would be helpful.",
                "A discussion on how the specific hyperparameters were chosen and if any hyperparameter tuning was performed would provide more insight into the model's performance.",
                "A rationale for the choice of the spectrogram discriminator and a discussion of its advantages over other potential discriminators would be beneficial.",
                "More information on the choice of the phonemizer tool for text preprocessing and a discussion of its advantages over other potential text preprocessing tools would be helpful."
            ]
        },
        "alignments": {
            "all": [
                {
                    "reference_id": 3,
                    "predicted_id": 8,
                    "relative_specificity": "more",
                    "relatedness": "medium",
                    "pairwise_result": {
                        "relatedness": "medium",
                        "relative_specificity": "more",
                        "same_meaning": true
                    },
                    "count": 3,
                    "score": 0.6,
                    "reference_comment": "It's not clear which dataset was used in the experiment. If it is a private dataset, please state it clearly.",
                    "predicted_comment": "More information about the dataset used for training the models, including how it was collected, any preprocessing steps, and the rationale behind choosing this specific dataset, would be helpful."
                },
                {
                    "reference_id": 0,
                    "predicted_id": 2,
                    "relative_specificity": "more",
                    "relatedness": "medium",
                    "pairwise_result": {
                        "relatedness": "medium",
                        "relative_specificity": "more",
                        "same_meaning": true
                    },
                    "count": 2,
                    "score": 0.4,
                    "reference_comment": "The performance of the proposed model is promising, but still below the baselines.",
                    "predicted_comment": "A detailed comparison with state-of-the-art models would be valuable. Discuss the advantages and disadvantages of your approach in comparison to these existing models. A separate section or table that clearly outlines the differences and advantages of the EATS model over other models would be helpful."
                },
                {
                    "reference_id": 2,
                    "predicted_id": 2,
                    "relative_specificity": "more",
                    "relatedness": "medium",
                    "pairwise_result": {
                        "relatedness": "medium",
                        "relative_specificity": "more",
                        "same_meaning": true
                    },
                    "count": 3,
                    "score": 0.6,
                    "reference_comment": "EATS performs slightly worse than GAN-TTS, which does not quite show the benefit of end-to-end training. It would be worthwhile to expand the discussion a bit by showing further experiments that demonstrate the potential benefit of end-to-end training.",
                    "predicted_comment": "A detailed comparison with state-of-the-art models would be valuable. Discuss the advantages and disadvantages of your approach in comparison to these existing models. A separate section or table that clearly outlines the differences and advantages of the EATS model over other models would be helpful."
                }
            ]
        },
        "metrics": {
            "all": {
                "n_reference": 14,
                "n_generated": 12,
                "n_total_aligns": 3,
                "recall": 0.1875,
                "precision": 0.0625,
                "pseudo_jaccard": 0.052380952380952375,
                "specificity_more": 1.0,
                "specificity_less": 0.0,
                "specificity_same": 0.0
            }
        },
        "metrics_for_reviews": {
            "all": [
                {
                    "recall": 0.5,
                    "precision": 0.16666666666666666,
                    "pseudo_jaccard": 0.14285714285714285,
                    "n_real": 4
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 3
                },
                {
                    "recall": 0.25,
                    "precision": 0.08333333333333333,
                    "pseudo_jaccard": 0.06666666666666667,
                    "n_real": 4
                },
                {
                    "recall": 0.0,
                    "precision": 0.0,
                    "pseudo_jaccard": 0.0,
                    "n_real": 3
                }
            ]
        }
    }
]